{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import time\n",
    "import memory_profiler\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.1+cu121'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from text_embeddings_src.model_stuff import train_loop\n",
    "from text_embeddings_src.data_stuff import (\n",
    "    MultOverlappingSentencesPairDataset,\n",
    ")\n",
    "from text_embeddings_src.metrics import knn_accuracy\n",
    "from text_embeddings_src.embeddings import generate_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(line_length=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_path = Path(\"../results/variables\")\n",
    "figures_path = Path(\"../results/figures\")\n",
    "data_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"matplotlib_style.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "issubclass() arg 1 must be a class",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/.pyenv/versions/miniconda3-latest/lib/python3.11/site-packages/pandas/io/pickle.py:206\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    205\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mWarning\u001b[39;00m)\n\u001b[0;32m--> 206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n",
      "File \u001b[0;32m/.pyenv/versions/miniconda3-latest/lib/python3.11/site-packages/pandas/core/internals/blocks.py:2400\u001b[0m, in \u001b[0;36mnew_block\u001b[0;34m(values, placement, ndim, refs)\u001b[0m\n\u001b[1;32m   2399\u001b[0m klass \u001b[38;5;241m=\u001b[39m get_block_type(values\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m-> 2400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplacement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'placement' has incorrect type (expected pandas._libs.internals.BlockPlacement, got slice)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/.pyenv/versions/miniconda3-latest/lib/python3.11/site-packages/pandas/compat/pickle_compat.py:35\u001b[0m, in \u001b[0;36mload_reduce\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m     stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/.pyenv/versions/miniconda3-latest/lib/python3.11/site-packages/pandas/core/internals/blocks.py:2400\u001b[0m, in \u001b[0;36mnew_block\u001b[0;34m(values, placement, ndim, refs)\u001b[0m\n\u001b[1;32m   2399\u001b[0m klass \u001b[38;5;241m=\u001b[39m get_block_type(values\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m-> 2400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplacement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'placement' has incorrect type (expected pandas._libs.internals.BlockPlacement, got slice)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:3\u001b[0m\n",
      "File \u001b[0;32m/.pyenv/versions/miniconda3-latest/lib/python3.11/site-packages/pandas/io/pickle.py:211\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pc\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/.pyenv/versions/miniconda3-latest/lib/python3.11/site-packages/pandas/compat/pickle_compat.py:225\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# \"Unpickler\" has no attribute \"is_verbose\"  [attr-defined]\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     up\u001b[38;5;241m.\u001b[39mis_verbose \u001b[38;5;241m=\u001b[39m is_verbose  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/.pyenv/versions/miniconda3-latest/lib/python3.11/pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1213\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m/.pyenv/versions/miniconda3-latest/lib/python3.11/site-packages/pandas/compat/pickle_compat.py:55\u001b[0m, in \u001b[0;36mload_reduce\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m     stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43missubclass\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPeriodArray\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     57\u001b[0m     stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m NDArrayBacked\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[0;31mTypeError\u001b[0m: issubclass() arg 1 must be a class"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "compression_opts = dict(method=\"zip\", archive_name=\"iclr.pickle.csv\")\n",
    "\n",
    "iclr = pd.read_pickle(\n",
    "    data_path / \"iclr.pickle.zip\",\n",
    "    # index_col=False,\n",
    "    compression=compression_opts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iclr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43miclr\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'iclr' is not defined"
     ]
    }
   ],
   "source": [
    "iclr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iclr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m titles_abstracts_together \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 2\u001b[0m     iclr\u001b[38;5;241m.\u001b[39mtitle[i] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m iclr\u001b[38;5;241m.\u001b[39mabstract[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43miclr\u001b[49m))\n\u001b[1;32m      3\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'iclr' is not defined"
     ]
    }
   ],
   "source": [
    "titles_abstracts_together = [\n",
    "    iclr.title[i] + \" \" + iclr.abstract[i] for i in range(len(iclr))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16536\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(len(titles_abstracts_together))\n",
    "print(type(titles_abstracts_together))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16536\n",
      "8964\n",
      "6849\n"
     ]
    }
   ],
   "source": [
    "# iclr = pd.read_pickle(\"iclr.pickle.zip\")\n",
    "\n",
    "keywords = [\n",
    "    \"network\",\n",
    "    \"graph\",\n",
    "    \"reinforcement\",\n",
    "    \"language\",\n",
    "    \"adversarial\",\n",
    "    \"federated\",\n",
    "    \"contrastive\",\n",
    "    \"domain\",\n",
    "    \"diffusion\",\n",
    "    \"out-of-dis\",\n",
    "    \"continual\",\n",
    "    \"distillation\",\n",
    "    \"architecture\",\n",
    "    \"privacy\",\n",
    "    \"protein\",\n",
    "    \"fair\",\n",
    "    \"attention\",\n",
    "    \"video\",\n",
    "    \"meta-learning\",\n",
    "    \"generative adv\",\n",
    "    \"autoencoder\",\n",
    "    \"game\",\n",
    "    \"semi-sup\",\n",
    "    \"pruning\",\n",
    "    \"physics\",\n",
    "    \"3d\",\n",
    "    \"translation\",\n",
    "    \"optimization\",\n",
    "    \"recurrent\",\n",
    "    \"word\",\n",
    "    \"bayesian\",\n",
    "]\n",
    "keywords = np.array(keywords)\n",
    "\n",
    "y = np.zeros(iclr.shape[0]) * np.nan\n",
    "\n",
    "for num, keyword in enumerate(keywords):\n",
    "    mask = [keyword.lower() in t.lower() for t in iclr.title]\n",
    "    y[mask & ~np.isnan(y)] = -1\n",
    "    y[mask & np.isnan(y)] = num\n",
    "\n",
    "print(y.size)\n",
    "print(np.sum(~np.isnan(y)))\n",
    "print(np.sum(y >= 0))\n",
    "\n",
    "labeled = y >= 0\n",
    "\n",
    "iclr_labeled = iclr[labeled].reset_index(drop=True)\n",
    "y_labeled = y[labeled].astype(int)\n",
    "iclr_labeled[\"y\"] = y_labeled\n",
    "iclr_labeled[\"label\"] = keywords[y_labeled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"BERT\",\n",
    "    \"MPNet\",\n",
    "    \"SBERT\",\n",
    "    \"SciBERT\",\n",
    "    \"SPECTER\",\n",
    "    \"SciNCL\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"bert-base-uncased\",\n",
    "    \"microsoft/mpnet-base\",\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    \"allenai/scibert_scivocab_uncased\",\n",
    "    \"allenai/specter\",\n",
    "    \"malteos/scincl\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A train and test set are embedded with the provided model. The train set embeddings are used to train a logistic regression classifier with 100 maximum iterations, which is scored on the test set. \n",
    "\n",
    "The main metric is:\n",
    "- accuracy\n",
    "\n",
    "other:\n",
    "- average precision \n",
    "- f1 additionally provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def logistic_accuracy(\n",
    "    embeddings, true_labels, test_size=0.1, rs=42, set_numpy=True\n",
    "):\n",
    "    \"\"\"Calculates logistic accuracy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embeddings : list\n",
    "        List with the different datasets for which to calculate the kNN accuracy.\n",
    "    true_labels : array-like\n",
    "        Array with labels (colors).\n",
    "    test_size : float\n",
    "        Fraction of the data to take as test set.\n",
    "    rs : int, default=42\n",
    "        Random seed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    accuracy : float\n",
    "        Accuracy of the logistic classifier in the test set.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    random_state = np.random.seed(rs)\n",
    "\n",
    "    if type(embeddings) == list:\n",
    "        accuracy = []\n",
    "        for embed in embeddings:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                embed,\n",
    "                true_labels,\n",
    "                test_size=test_size,\n",
    "                random_state=random_state,\n",
    "            )\n",
    "            lr = make_pipeline(\n",
    "                StandardScaler(),\n",
    "                LogisticRegression(\n",
    "                    penalty=\"none\",\n",
    "                    solver=\"saga\",\n",
    "                    tol=1e-2,\n",
    "                    random_state=random_state,\n",
    "                    n_jobs=-1,\n",
    "                    max_iter=1000,\n",
    "                ),\n",
    "            )\n",
    "            # clf = LogisticRegressionCV(\n",
    "            #     cv=5,\n",
    "            #     multi_class=\"multinomial\",\n",
    "            #     solver=\"sag\",\n",
    "            #     max_iter=100,\n",
    "            #     n_jobs=-1,\n",
    "            #     random_state=random_state,\n",
    "            # )\n",
    "\n",
    "            lr.fit(X_train, y_train)\n",
    "            accuracy.append(lr.score(X_test, y_test))\n",
    "        if set_numpy == True:\n",
    "            accuracy = np.array(accuracy)\n",
    "\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            embeddings,\n",
    "            true_labels,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        lr = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            LogisticRegression(\n",
    "                penalty=\"none\",\n",
    "                solver=\"saga\",\n",
    "                tol=1e-2,\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1,\n",
    "                max_iter=1000,\n",
    "            ),\n",
    "        )\n",
    "        # clf = LogisticRegressionCV(\n",
    "        #     cv=5,\n",
    "        #     multi_class=\"multinomial\",\n",
    "        #     solver=\"sag\",\n",
    "        #     max_iter=100,\n",
    "        #     n_jobs=-1,\n",
    "        #     random_state=random_state,\n",
    "        # )\n",
    "        lr.fit(X_train, y_train)\n",
    "        accuracy = lr.score(X_test, y_test)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN accuracy     [AVG]    [CLS]   [SEP]\n",
      "BERT: [79.12408759 73.28467153 77.22627737]\n",
      "MPNet: [79.8540146  80.72992701 72.99270073]\n",
      "SBERT: [88.02919708 90.94890511 81.16788321]\n",
      "SciBERT: [78.97810219 69.19708029 68.32116788]\n",
      "SPECTER: [83.35766423 85.25547445 82.33576642]\n",
      "SciNCL: [84.96350365 88.46715328 85.69343066]\n",
      "CPU times: user 8min 33s, sys: 1min 5s, total: 9min 38s\n",
      "Wall time: 8min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"kNN accuracy     [AVG]    [CLS]   [SEP]\")\n",
    "for i, model_name in enumerate(model_names):\n",
    "    # load\n",
    "    saving_path = Path(\"embeddings_\" + model_name.lower())\n",
    "\n",
    "    embedding_av = np.load(variables_path / saving_path / \"embedding_av.npy\")\n",
    "    embedding_cls = np.load(variables_path / saving_path / \"embedding_cls.npy\")\n",
    "    embedding_sep = np.load(variables_path / saving_path / \"embedding_sep.npy\")\n",
    "\n",
    "    # metric\n",
    "    accuracy = logistic_accuracy(\n",
    "        [\n",
    "            embedding_av[labeled],\n",
    "            embedding_cls[labeled],\n",
    "            embedding_sep[labeled],\n",
    "        ],\n",
    "        iclr_labeled[\"y\"].to_numpy(),\n",
    "    )\n",
    "    print(f\"{model_name}: {np.array(accuracy)*100}\")\n",
    "\n",
    "    # save\n",
    "    np.save(variables_path / saving_path / \"logistic_accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
