{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a4170199-7901-42dd-b434-270b268fc8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import time\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import time\n",
    "\n",
    "import memory_profiler\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8eb75c4d-f7cc-4e24-a9cc-d847c74babba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(line_length=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "82cdefbf-dbd6-4c62-886f-bc0b0e06388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_path = Path(\"../old_variables\")\n",
    "data_path = Path(\"../data\")\n",
    "# berenslab_data_path = Path(\"/gpfs01/berens/data/data/GPT_wiki_intro\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32e365bc-8d5f-4bfc-beff-fa71ae05bb91",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e62e742-881f-48bf-8941-bcac8a4cd2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 185 ms, sys: 18.1 ms, total: 203 ms\n",
      "Wall time: 203 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "compression_opts = dict(method=\"zip\", archive_name=\"iclr.pickle.csv\")\n",
    "\n",
    "iclr = pd.read_pickle(\n",
    "    data_path / \"iclr.pickle.zip\",\n",
    "    # index_col=False,\n",
    "    compression=compression_opts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92afb400-740a-4237-89b7-0a3111f5e5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>decision</th>\n",
       "      <th>scores</th>\n",
       "      <th>keywords</th>\n",
       "      <th>gender-first</th>\n",
       "      <th>gender-last</th>\n",
       "      <th>t-SNE x</th>\n",
       "      <th>t-SNE y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>ryBnUWb0b</td>\n",
       "      <td>Predicting Floor-Level for 911 Calls with Neur...</td>\n",
       "      <td>In cities with tall buildings, emergency respo...</td>\n",
       "      <td>William Falcon, Henning Schulzrinne</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[7, 6, 6]</td>\n",
       "      <td>[recurrent neural networks, rnn, lstm, mobile ...</td>\n",
       "      <td>male</td>\n",
       "      <td>None</td>\n",
       "      <td>2.536470</td>\n",
       "      <td>0.739367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>Skk3Jm96W</td>\n",
       "      <td>Some Considerations on Learning to Explore via...</td>\n",
       "      <td>We consider the problem of exploration in meta...</td>\n",
       "      <td>Bradly Stadie, Ge Yang, Rein Houthooft, Xi Che...</td>\n",
       "      <td>Invite to Workshop Track</td>\n",
       "      <td>[7, 4, 6]</td>\n",
       "      <td>[reinforcement learning, rl, exploration, meta...</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>49.831927</td>\n",
       "      <td>-29.813831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>r1RQdCg0W</td>\n",
       "      <td>MACH: Embarrassingly parallel $K$-class classi...</td>\n",
       "      <td>We present Merged-Averaged Classifiers via Has...</td>\n",
       "      <td>Qixuan Huang, Anshumali Shrivastava, Yiqiu Wang</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[6, 6, 6]</td>\n",
       "      <td>[extreme classification, large-scale learning,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-22.502752</td>\n",
       "      <td>9.577367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>rJ3fy0k0Z</td>\n",
       "      <td>Deterministic Policy Imitation Gradient Algorithm</td>\n",
       "      <td>The goal of imitation learning (IL) is to enab...</td>\n",
       "      <td>Fumihiro Sasaki, Atsuo Kawaguchi</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[6, 5, 5]</td>\n",
       "      <td>[imitation learning]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>40.437523</td>\n",
       "      <td>-47.690889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>SkBYYyZRZ</td>\n",
       "      <td>Searching for Activation Functions</td>\n",
       "      <td>The choice of activation functions in deep net...</td>\n",
       "      <td>Prajit Ramachandran, Barret Zoph, Quoc V. Le</td>\n",
       "      <td>Invite to Workshop Track</td>\n",
       "      <td>[5, 4, 7]</td>\n",
       "      <td>[meta learning, activation functions]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-33.260086</td>\n",
       "      <td>-4.038115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16531</th>\n",
       "      <td>2023</td>\n",
       "      <td>w4eQcMZsJa</td>\n",
       "      <td>Text-Driven Generative Domain Adaptation with ...</td>\n",
       "      <td>Combined with the generative prior of pre-trai...</td>\n",
       "      <td>Zhenhuan Liu, Liang Li, Jiayu Xiao, Zhengjun Z...</td>\n",
       "      <td>Desk rejected</td>\n",
       "      <td>[]</td>\n",
       "      <td>[gan, stylegan, clip, domain adaptation, style...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>59.296526</td>\n",
       "      <td>5.206691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16532</th>\n",
       "      <td>2023</td>\n",
       "      <td>SDHSQuBpf2</td>\n",
       "      <td>Laziness, Barren Plateau, and Noises in Machin...</td>\n",
       "      <td>We define \\emph{laziness} to describe a large ...</td>\n",
       "      <td>Zexi Lin, Liang Jiang</td>\n",
       "      <td>Desk rejected</td>\n",
       "      <td>[]</td>\n",
       "      <td>[theoretical issues in deep learning, learning...</td>\n",
       "      <td>None</td>\n",
       "      <td>male</td>\n",
       "      <td>-29.178083</td>\n",
       "      <td>-21.810583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16533</th>\n",
       "      <td>2023</td>\n",
       "      <td>HyIY8u5LVDr</td>\n",
       "      <td>Discovering the Representation Bottleneck of G...</td>\n",
       "      <td>Most graph neural networks (GNNs) rely on the ...</td>\n",
       "      <td>Fang Wu, Siyuan Li, Lirong Wu, Dragomir Radev,...</td>\n",
       "      <td>Desk rejected</td>\n",
       "      <td>[]</td>\n",
       "      <td>[gnn bottleneck, graph rewiring, representatio...</td>\n",
       "      <td>None</td>\n",
       "      <td>male</td>\n",
       "      <td>-7.573978</td>\n",
       "      <td>68.386671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16534</th>\n",
       "      <td>2023</td>\n",
       "      <td>470wZ5Qk4ur</td>\n",
       "      <td>Results for Perfect Classification for Graph A...</td>\n",
       "      <td>We study the ability of one layer Graph Attent...</td>\n",
       "      <td>Kimon Fountoulakis, Amit Levi</td>\n",
       "      <td>Desk rejected</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>male</td>\n",
       "      <td>-7.753593</td>\n",
       "      <td>60.764583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16535</th>\n",
       "      <td>2023</td>\n",
       "      <td>3GDft6lexE</td>\n",
       "      <td>Cooperate or Compete: A New Perspective on Tra...</td>\n",
       "      <td>GANs have two competing modules: the generator...</td>\n",
       "      <td>Sobhan Babu</td>\n",
       "      <td>Desk rejected</td>\n",
       "      <td>[]</td>\n",
       "      <td>[generative adversarial networks, nash equilib...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>38.470326</td>\n",
       "      <td>-1.929707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16536 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year           id                                              title  \\\n",
       "0      2018    ryBnUWb0b  Predicting Floor-Level for 911 Calls with Neur...   \n",
       "1      2018    Skk3Jm96W  Some Considerations on Learning to Explore via...   \n",
       "2      2018    r1RQdCg0W  MACH: Embarrassingly parallel $K$-class classi...   \n",
       "3      2018    rJ3fy0k0Z  Deterministic Policy Imitation Gradient Algorithm   \n",
       "4      2018    SkBYYyZRZ                 Searching for Activation Functions   \n",
       "...     ...          ...                                                ...   \n",
       "16531  2023   w4eQcMZsJa  Text-Driven Generative Domain Adaptation with ...   \n",
       "16532  2023   SDHSQuBpf2  Laziness, Barren Plateau, and Noises in Machin...   \n",
       "16533  2023  HyIY8u5LVDr  Discovering the Representation Bottleneck of G...   \n",
       "16534  2023  470wZ5Qk4ur  Results for Perfect Classification for Graph A...   \n",
       "16535  2023   3GDft6lexE  Cooperate or Compete: A New Perspective on Tra...   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      In cities with tall buildings, emergency respo...   \n",
       "1      We consider the problem of exploration in meta...   \n",
       "2      We present Merged-Averaged Classifiers via Has...   \n",
       "3      The goal of imitation learning (IL) is to enab...   \n",
       "4      The choice of activation functions in deep net...   \n",
       "...                                                  ...   \n",
       "16531  Combined with the generative prior of pre-trai...   \n",
       "16532  We define \\emph{laziness} to describe a large ...   \n",
       "16533  Most graph neural networks (GNNs) rely on the ...   \n",
       "16534  We study the ability of one layer Graph Attent...   \n",
       "16535  GANs have two competing modules: the generator...   \n",
       "\n",
       "                                                 authors  \\\n",
       "0                    William Falcon, Henning Schulzrinne   \n",
       "1      Bradly Stadie, Ge Yang, Rein Houthooft, Xi Che...   \n",
       "2        Qixuan Huang, Anshumali Shrivastava, Yiqiu Wang   \n",
       "3                       Fumihiro Sasaki, Atsuo Kawaguchi   \n",
       "4           Prajit Ramachandran, Barret Zoph, Quoc V. Le   \n",
       "...                                                  ...   \n",
       "16531  Zhenhuan Liu, Liang Li, Jiayu Xiao, Zhengjun Z...   \n",
       "16532                              Zexi Lin, Liang Jiang   \n",
       "16533  Fang Wu, Siyuan Li, Lirong Wu, Dragomir Radev,...   \n",
       "16534                      Kimon Fountoulakis, Amit Levi   \n",
       "16535                                        Sobhan Babu   \n",
       "\n",
       "                       decision     scores  \\\n",
       "0               Accept (Poster)  [7, 6, 6]   \n",
       "1      Invite to Workshop Track  [7, 4, 6]   \n",
       "2                        Reject  [6, 6, 6]   \n",
       "3                        Reject  [6, 5, 5]   \n",
       "4      Invite to Workshop Track  [5, 4, 7]   \n",
       "...                         ...        ...   \n",
       "16531             Desk rejected         []   \n",
       "16532             Desk rejected         []   \n",
       "16533             Desk rejected         []   \n",
       "16534             Desk rejected         []   \n",
       "16535             Desk rejected         []   \n",
       "\n",
       "                                                keywords gender-first  \\\n",
       "0      [recurrent neural networks, rnn, lstm, mobile ...         male   \n",
       "1      [reinforcement learning, rl, exploration, meta...         male   \n",
       "2      [extreme classification, large-scale learning,...         None   \n",
       "3                                   [imitation learning]         None   \n",
       "4                  [meta learning, activation functions]         None   \n",
       "...                                                  ...          ...   \n",
       "16531  [gan, stylegan, clip, domain adaptation, style...         None   \n",
       "16532  [theoretical issues in deep learning, learning...         None   \n",
       "16533  [gnn bottleneck, graph rewiring, representatio...         None   \n",
       "16534                                                 []         None   \n",
       "16535  [generative adversarial networks, nash equilib...         None   \n",
       "\n",
       "      gender-last    t-SNE x    t-SNE y  \n",
       "0            None   2.536470   0.739367  \n",
       "1            male  49.831927 -29.813831  \n",
       "2            None -22.502752   9.577367  \n",
       "3            None  40.437523 -47.690889  \n",
       "4            None -33.260086  -4.038115  \n",
       "...           ...        ...        ...  \n",
       "16531        None  59.296526   5.206691  \n",
       "16532        male -29.178083 -21.810583  \n",
       "16533        male  -7.573978  68.386671  \n",
       "16534        male  -7.753593  60.764583  \n",
       "16535        None  38.470326  -1.929707  \n",
       "\n",
       "[16536 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "243ccb73-5ccd-4317-886b-3dfd13eb666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_abstracts_together = [\n",
    "    iclr.title[i] + \" \" + iclr.abstract[i] for i in range(len(iclr))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5001b966-92b5-4a95-8c4a-d04c415accca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16536\n"
     ]
    }
   ],
   "source": [
    "print(len(titles_abstracts_together))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "abf33654-c58f-4975-9037-ee6e5ff3d816",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7527b216-bd7f-46ba-8718-4811c562f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_embeddings(abstracts, tokenizer, model, device):\n",
    "    \"\"\"Generate embeddings using BERT-based model.\n",
    "    Code from Luca Schmidt.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    abstracts : list\n",
    "        Abstract texts.\n",
    "    tokenizer : transformers.models.bert.tokenization_bert_fast.BertTokenizerFast\n",
    "        Tokenizer.\n",
    "    model : transformers.models.bert.modeling_bert.BertModel\n",
    "        BERT-based model.\n",
    "    device : str, {\"cuda\", \"cpu\"}\n",
    "        \"cuda\" if torch.cuda.is_available() else \"cpu\".\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    embedding_cls : ndarray\n",
    "        [CLS] tokens of the abstracts.\n",
    "    embedding_sep : ndarray\n",
    "        [SEP] tokens of the abstracts.\n",
    "    embedding_av : ndarray\n",
    "        Average of tokens of the abstracts.\n",
    "    \"\"\"\n",
    "    # preprocess the input\n",
    "    inputs = tokenizer(\n",
    "        abstracts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=512,\n",
    "    ).to(device)\n",
    "\n",
    "    # inference\n",
    "    outputs = model(**inputs)[0].cpu().detach() \n",
    "\n",
    "    embedding_av = torch.mean(outputs, [0, 1]).numpy()\n",
    "    embedding_sep = outputs[:, -1, :].numpy()\n",
    "    embedding_cls = outputs[:, 0, :].numpy()\n",
    "\n",
    "    \n",
    "    return embedding_cls, embedding_sep, embedding_av "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da8cbf54-4b4c-4172-82f0-b1a4e9191a71",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Obtain SciBERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0d502b56-13bf-49f3-9e94-ed21b3b460c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "random_state = random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9b12b486-6582-407a-b3d2-723bf20bc97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device: cuda\n"
     ]
    }
   ],
   "source": [
    "# specify & check gpu usage\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")  # put cuda:0 if else not working\n",
    "print(\"running on device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5ed10a80-e70f-4652-9746-6b5fd46253b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: SciBERT uncased\n"
     ]
    }
   ],
   "source": [
    "# load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "\n",
    "print(\"model: SciBERT uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "82ab9d7e-10ab-48da-abff-9b9852ab984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "model = model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e91de32c-84f5-423e-9d41-1f839a44296e",
   "metadata": {},
   "source": [
    "## Tokenizer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "069015eb-d0da-4fb4-8512-513d2999d804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.bert.tokenization_bert_fast.BertTokenizerFast"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eea2eb9-c059-44dd-b4ca-54191a69903e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.bert.modeling_bert.BertModel"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "974f48ab-3964-406e-9e0c-f3c049885e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'very',\n",
       " 'very',\n",
       " 'very',\n",
       " 'long',\n",
       " 'and',\n",
       " 'verb',\n",
       " '##ose',\n",
       " 'abstract',\n",
       " '.',\n",
       " 'a',\n",
       " 'very',\n",
       " 'short',\n",
       " 'abstract',\n",
       " '.']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers = [\"A very very very long and verbose abstract. A very short abstract.\"]\n",
    "tokenizer.tokenize(papers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3723fed-2020-41e1-a182-0b0d552778e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS] a very very very long and verbose abstract. a very short abstract [SEP]']\n"
     ]
    }
   ],
   "source": [
    "papers = [\n",
    "    \"A very very very long and verbose abstract. A very short abstract\",\n",
    "]\n",
    "inputs = tokenizer(\n",
    "    papers,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    "    return_token_type_ids=False,\n",
    "    max_length=512,\n",
    ")\n",
    "print([tokenizer.decode(inputs[\"input_ids\"][i]) for i in range(len(papers))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "585fb498-0e60-4adc-825b-6b6025d5928c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"input_ids\"].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "279a0fee-44dd-4c88-a5c0-7996bb3fb8db",
   "metadata": {},
   "source": [
    "## Test to not pass abstracts individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e51b63e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mean pooling function\n",
    "def sep_pool(model_output, attention_mask):\n",
    "    token_embeds = model_output[0]\n",
    "    ix = attention_mask.sum(1) - 1\n",
    "    ix0 = torch.arange(attention_mask.size(0))\n",
    "    return token_embeds[ix0, ix, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "248b3347-5db6-4f89-b772-6b6fc3634ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[\n",
    "        0\n",
    "    ]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "294c9642-a562-459c-bf8d-d3012dc8a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = [\n",
    "    \"A very very very long and verbose abstract.\",\n",
    "    \"A very short abstract\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "79b48e9b-e5f7-44ec-b451-d7e718b4e511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS] a very very very long and verbose abstract. [SEP]', '[CLS] a very short abstract [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    papers,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    "    return_token_type_ids=False,\n",
    "    max_length=512,\n",
    ")\n",
    "print([tokenizer.decode(inputs[\"input_ids\"][i]) for i in range(len(papers))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4076c831-9f59-4a44-bb45-506a54c2f57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a', 'very', 'very', 'very', 'long', 'and', 'verb', '##ose', 'abstract', '.']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tokenizer.tokenize(papers[0])))\n",
    "tokenizer.tokenize(papers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14049107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "63540ad2-69b6-400b-b4a3-4f29bc5f8956",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(\n",
    "    papers, padding=True, truncation=True, return_tensors=\"pt\", max_length=512\n",
    ").to(device)\n",
    "model_output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3004b166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "bc0e5c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sep = sep_pool(model_output, encoded_input[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4bbe859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d9960-715e-4c5f-8457-34a59b4e1449",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pooling(model_output, encoded_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb39651c-2b78-4152-afc3-6391dfe53130",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings = model_output[\n",
    "    0\n",
    "]  # First element of model_output contains all token embeddings\n",
    "attention_mask = encoded_input[\"attention_mask\"]\n",
    "input_mask_expanded = (\n",
    "    attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ee274b4-2ea9-470c-9005-cdb1b36ef683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff5f9364-6d7e-49c5-b2a6-cdb295b92b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 768])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_mask_expanded.to(torch.bool).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6ebfd01-09be-4197-9999-a87ce3550407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_mask_expanded[1, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "704f2c59-d88e-42dd-b582-f98d53c0faa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed4afeba-a745-4401-80bd-22b04aa20feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 768])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_mask_expanded[1, :, :].to(torch.bool).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "98c3670a-f8bc-44b5-9ad8-d9605794c399",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "torch.sum(attention_mask, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3dd79a50-c2d5-44f6-a177-60c48f3b27b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m token_embeddings[:, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, :]\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "token_embeddings[:, torch.sum(attention_mask, axis=1), :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e55d13d-d140-4633-b2d9-ced7dbddeb17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07850875-4a5c-4f4b-869e-f93532ac949b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1a61934-e2bf-42b7-9ec6-a012e237d7c2",
   "metadata": {},
   "source": [
    "## Abstracts + Titles (Update code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ee1b5c1-659f-4457-b5bb-aa85a768fd22",
   "metadata": {},
   "source": [
    "### With batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "891eb700-1850-406b-be33-125a3ff79a70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8h 18min 2s, sys: 13min, total: 8h 31min 3s\n",
      "Wall time: 27min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embeddings_cls = []\n",
    "embeddings_sep = []\n",
    "embeddings_av = []\n",
    "\n",
    "batch_size = 1e2\n",
    "indeces_batches = np.arange(\n",
    "    0, len(titles_abstracts_together) + batch_size, batch_size, dtype=int\n",
    ")\n",
    "\n",
    "for i in range(len(indeces_batches) - 1):\n",
    "    np.save(variables_path / \"experiment_iter\", i)\n",
    "\n",
    "    batch = titles_abstracts_together[\n",
    "        indeces_batches[i] : indeces_batches[i + 1]\n",
    "    ]\n",
    "\n",
    "    embedding_cls, embedding_sep, embedding_av = generate_embeddings(batch, tokenizer, model, device)\n",
    "\n",
    "    name_embedding_cls = \"embedding_batches/embedding_cls_batch_\" + str(i)\n",
    "    name_embedding_sep = \"embedding_batches/embedding_sep_batch_\" + str(i)\n",
    "    name_embedding_av = \"embedding_batches/embedding_av_batch_\" + str(i)\n",
    "\n",
    "    np.save(\n",
    "        variables_path / name_embedding_cls,\n",
    "        embedding_cls,\n",
    "        allow_pickle=True,\n",
    "        fix_imports=True,\n",
    "    )\n",
    "    np.save(\n",
    "        variables_path / name_embedding_sep,\n",
    "        embedding_sep,\n",
    "        allow_pickle=True,\n",
    "        fix_imports=True,\n",
    "    )\n",
    "    np.save(\n",
    "        variables_path / name_embedding_av,\n",
    "        embedding_av,\n",
    "        allow_pickle=True,\n",
    "        fix_imports=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c3b600a-7e75-4e51-ab90-3dd1d0aa33ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(variables_path / \"verbose_batches.txt\", \"w\") as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea9d3035-1286-40fc-9619-560971595bca",
   "metadata": {},
   "source": [
    "### Join batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7aba0b7-2965-45c5-bb61-bb3944bf61e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 177 ms, sys: 182 ms, total: 359 ms\n",
      "Wall time: 584 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# join different batches\n",
    "\n",
    "embeddings_cls = []\n",
    "embeddings_sep = []\n",
    "embeddings_av = []\n",
    "\n",
    "\n",
    "batch_size = 1e2\n",
    "indeces_batches = np.arange(\n",
    "    0, len(titles_abstracts_together) + batch_size, batch_size, dtype=int\n",
    ")\n",
    "\n",
    "for i in range(len(indeces_batches) - 1):\n",
    "    name_embedding_cls = (\n",
    "        \"embedding_batches/embedding_cls_batch_\" + str(i) + \".npy\"\n",
    "    )\n",
    "    name_embedding_sep = (\n",
    "        \"embedding_batches/embedding_sep_batch_\" + str(i) + \".npy\"\n",
    "    )\n",
    "    name_embedding_av = (\n",
    "        \"embedding_batches/embedding_av_batch_\" + str(i) + \".npy\"\n",
    "    )\n",
    "\n",
    "    embeddings_cls.append(\n",
    "        np.load(\n",
    "            variables_path / name_embedding_cls,\n",
    "            allow_pickle=True,\n",
    "            fix_imports=True,\n",
    "        )\n",
    "    )\n",
    "    embeddings_sep.append(\n",
    "        np.load(\n",
    "            variables_path / name_embedding_sep,\n",
    "            allow_pickle=True,\n",
    "            fix_imports=True,\n",
    "        )\n",
    "    )\n",
    "    embeddings_av.append(\n",
    "        np.load(\n",
    "            variables_path / name_embedding_av,\n",
    "            allow_pickle=True,\n",
    "            fix_imports=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "embeddings_cls = np.vstack(embeddings_cls)\n",
    "embeddings_sep = np.vstack(embeddings_sep)\n",
    "embeddings_av = np.vstack(embeddings_av)\n",
    "\n",
    "np.save(\n",
    "    variables_path / \"embeddings_iclr_cls\",\n",
    "    embeddings_cls,\n",
    "    allow_pickle=True,\n",
    "    fix_imports=True,\n",
    ")\n",
    "np.save(\n",
    "    variables_path / \"embeddings_iclr_sep\",\n",
    "    embeddings_sep,\n",
    "    allow_pickle=True,\n",
    "    fix_imports=True,\n",
    ")\n",
    "np.save(\n",
    "    variables_path / \"embeddings_iclr_av\",\n",
    "    embeddings_av,\n",
    "    allow_pickle=True,\n",
    "    fix_imports=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd540655-a610-489f-88ff-75c69f43d435",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.403848"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(embeddings_cls - embeddings_av)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "480a6e70-2ebe-4247-b1ee-b41177e1de8f",
   "metadata": {},
   "source": [
    "## Only abstracts (Update code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f6c093b-9596-4ec4-88ef-5a47b7cf3277",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = iclr.abstract.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a485c6a-5599-4880-b2a2-5a789850ebb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16536\n"
     ]
    }
   ],
   "source": [
    "print(len(abstracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47470e38-bed1-4872-9769-696816fc6fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "random_state = random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c533c1de-8318-457d-9eaf-3d5c08699eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device: cuda\n"
     ]
    }
   ],
   "source": [
    "# specify & check gpu usage\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")  # put cuda:0 if else not working\n",
    "print(\"running on device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73777d3d-7019-4eba-9f22-26e84d5715fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: SciBERT uncased\n"
     ]
    }
   ],
   "source": [
    "# load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "\n",
    "print(\"model: SciBERT uncased\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93578d2d-8fab-46db-9a3b-00e72cd44822",
   "metadata": {},
   "source": [
    "### With batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00542ba0-b291-461d-b320-5ceb82688ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 1258291200 bytes == 0xb965e000 @ \n",
      "tcmalloc: large alloc 1258291200 bytes == 0x7f145858c000 @ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8h 6min 34s, sys: 13min 55s, total: 8h 20min 30s\n",
      "Wall time: 26min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embeddings_cls = []\n",
    "embeddings_sep = []\n",
    "embeddings_av = []\n",
    "\n",
    "batch_size = 1e2\n",
    "indeces_batches = np.arange(\n",
    "    0, len(abstracts) + batch_size, batch_size, dtype=int\n",
    ")\n",
    "\n",
    "for i in range(len(indeces_batches) - 1):\n",
    "    np.save(variables_path / \"experiment_iter\", i)\n",
    "\n",
    "    batch = abstracts[indeces_batches[i] : indeces_batches[i + 1]]\n",
    "\n",
    "    embedding_cls, embedding_sep, embedding_av = generate_embeddings(batch, tokenizer, model, device)\n",
    "\n",
    "    name_embedding_cls = (\n",
    "        \"embedding_batches_abstract/embedding_cls_batch_\" + str(i)\n",
    "    )\n",
    "    name_embedding_sep = (\n",
    "        \"embedding_batches_abstract/embedding_sep_batch_\" + str(i)\n",
    "    )\n",
    "    name_embedding_av = \"embedding_batches_abstract/embedding_av_batch_\" + str(\n",
    "        i\n",
    "    )\n",
    "\n",
    "    np.save(\n",
    "        variables_path / name_embedding_cls,\n",
    "        embedding_cls,\n",
    "        allow_pickle=True,\n",
    "        fix_imports=True,\n",
    "    )\n",
    "    np.save(\n",
    "        variables_path / name_embedding_sep,\n",
    "        embedding_sep,\n",
    "        allow_pickle=True,\n",
    "        fix_imports=True,\n",
    "    )\n",
    "    np.save(\n",
    "        variables_path / name_embedding_av,\n",
    "        embedding_av,\n",
    "        allow_pickle=True,\n",
    "        fix_imports=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38490e86-9f3f-4767-a9cf-b0f9347c9cf1",
   "metadata": {},
   "source": [
    "### Join batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4cccdb8-0e60-4fa5-bd49-d633d0ea31d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 262 ms, sys: 258 ms, total: 521 ms\n",
      "Wall time: 971 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# join different batches\n",
    "\n",
    "embeddings_cls = []\n",
    "embeddings_sep = []\n",
    "embeddings_av = []\n",
    "\n",
    "\n",
    "batch_size = 1e2\n",
    "indeces_batches = np.arange(\n",
    "    0, len(abstracts) + batch_size, batch_size, dtype=int\n",
    ")\n",
    "\n",
    "for i in range(len(indeces_batches) - 1):\n",
    "    name_embedding_cls = (\n",
    "        \"embedding_batches_abstract/embedding_cls_batch_\" + str(i) + \".npy\"\n",
    "    )\n",
    "    name_embedding_sep = (\n",
    "        \"embedding_batches_abstract/embedding_sep_batch_\" + str(i) + \".npy\"\n",
    "    )\n",
    "    name_embedding_av = (\n",
    "        \"embedding_batches_abstract/embedding_av_batch_\" + str(i) + \".npy\"\n",
    "    )\n",
    "\n",
    "    embeddings_cls.append(\n",
    "        np.load(\n",
    "            variables_path / name_embedding_cls,\n",
    "            allow_pickle=True,\n",
    "            fix_imports=True,\n",
    "        )\n",
    "    )\n",
    "    embeddings_sep.append(\n",
    "        np.load(\n",
    "            variables_path / name_embedding_sep,\n",
    "            allow_pickle=True,\n",
    "            fix_imports=True,\n",
    "        )\n",
    "    )\n",
    "    embeddings_av.append(\n",
    "        np.load(\n",
    "            variables_path / name_embedding_av,\n",
    "            allow_pickle=True,\n",
    "            fix_imports=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "embeddings_cls = np.vstack(embeddings_cls)\n",
    "embeddings_sep = np.vstack(embeddings_sep)\n",
    "embeddings_av = np.vstack(embeddings_av)\n",
    "\n",
    "np.save(\n",
    "    variables_path / \"embeddings_iclr_abstracts_cls\",\n",
    "    embeddings_cls,\n",
    "    allow_pickle=True,\n",
    "    fix_imports=True,\n",
    ")\n",
    "np.save(\n",
    "    variables_path / \"embeddings_iclr_abstracts_sep\",\n",
    "    embeddings_sep,\n",
    "    allow_pickle=True,\n",
    "    fix_imports=True,\n",
    ")\n",
    "np.save(\n",
    "    variables_path / \"embeddings_iclr_abstracts_av\",\n",
    "    embeddings_av,\n",
    "    allow_pickle=True,\n",
    "    fix_imports=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36d5aad8-860f-48d1-9fc9-e6da885d5d64",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Obtain BERT embeddings (Update code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c0c59d9-41b9-435c-957a-709fdd4cfcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "random_state = random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adea4fb1-b9fe-4c86-bb40-ab8d67003d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device: cuda\n"
     ]
    }
   ],
   "source": [
    "# specify & check gpu usage\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")  # put cuda:0 if else not working\n",
    "print(\"running on device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2011f272-62c2-41e0-97c2-f86c1781719a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: BERT uncased\n"
     ]
    }
   ],
   "source": [
    "# load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "print(\"model: BERT uncased\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0cc354f-14a7-448b-83fb-c622927d83f8",
   "metadata": {},
   "source": [
    "### With batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82554c7a-9217-4f52-963c-e02d4663271a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 1209622528 bytes == 0x7f273b870000 @ \n",
      "tcmalloc: large alloc 1209622528 bytes == 0x184082000 @ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8h 43min 37s, sys: 13min 11s, total: 8h 56min 49s\n",
      "Wall time: 28min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embeddings_cls = []\n",
    "embeddings_sep = []\n",
    "embeddings_av = []\n",
    "\n",
    "batch_size = 1e2\n",
    "indeces_batches = np.arange(\n",
    "    0, len(titles_abstracts_together) + batch_size, batch_size, dtype=int\n",
    ")\n",
    "\n",
    "for i in range(len(indeces_batches) - 1):\n",
    "    np.save(variables_path / \"experiment_iter\", i)\n",
    "\n",
    "    batch = titles_abstracts_together[\n",
    "        indeces_batches[i] : indeces_batches[i + 1]\n",
    "    ]\n",
    "\n",
    "    embedding_cls, embedding_sep, embedding_av = generate_embeddings(batch, tokenizer, model, device)\n",
    "\n",
    "    name_embedding_cls = \"embedding_batches_bert/embedding_cls_batch_\" + str(i)\n",
    "    name_embedding_sep = \"embedding_batches_bert/embedding_sep_batch_\" + str(i)\n",
    "    name_embedding_av = \"embedding_batches_bert/embedding_av_batch_\" + str(i)\n",
    "\n",
    "    np.save(\n",
    "        variables_path / name_embedding_cls,\n",
    "        embedding_cls,\n",
    "        allow_pickle=True,\n",
    "        fix_imports=True,\n",
    "    )\n",
    "    np.save(\n",
    "        variables_path / name_embedding_sep,\n",
    "        embedding_sep,\n",
    "        allow_pickle=True,\n",
    "        fix_imports=True,\n",
    "    )\n",
    "    np.save(\n",
    "        variables_path / name_embedding_av,\n",
    "        embedding_av,\n",
    "        allow_pickle=True,\n",
    "        fix_imports=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6053bc0-6877-4994-9ae1-a32e36216e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(variables_path / \"verbose_batches_bert.txt\", \"w\") as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6adf0cce-1ac2-4f6f-b7c0-20805fadb6aa",
   "metadata": {},
   "source": [
    "### Join batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e9465e5-d65d-4632-858b-800a9ef060a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 195 ms, sys: 230 ms, total: 425 ms\n",
      "Wall time: 784 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# join different batches\n",
    "\n",
    "embeddings_cls = []\n",
    "embeddings_sep = []\n",
    "embeddings_av = []\n",
    "\n",
    "\n",
    "batch_size = 1e2\n",
    "indeces_batches = np.arange(\n",
    "    0, len(titles_abstracts_together) + batch_size, batch_size, dtype=int\n",
    ")\n",
    "\n",
    "for i in range(len(indeces_batches) - 1):\n",
    "    name_embedding_cls = (\n",
    "        \"embedding_batches_bert/embedding_cls_batch_\" + str(i) + \".npy\"\n",
    "    )\n",
    "    name_embedding_sep = (\n",
    "        \"embedding_batches_bert/embedding_sep_batch_\" + str(i) + \".npy\"\n",
    "    )\n",
    "    name_embedding_av = (\n",
    "        \"embedding_batches_bert/embedding_av_batch_\" + str(i) + \".npy\"\n",
    "    )\n",
    "\n",
    "    embeddings_cls.append(\n",
    "        np.load(\n",
    "            variables_path / name_embedding_cls,\n",
    "            allow_pickle=True,\n",
    "            fix_imports=True,\n",
    "        )\n",
    "    )\n",
    "    embeddings_sep.append(\n",
    "        np.load(\n",
    "            variables_path / name_embedding_sep,\n",
    "            allow_pickle=True,\n",
    "            fix_imports=True,\n",
    "        )\n",
    "    )\n",
    "    embeddings_av.append(\n",
    "        np.load(\n",
    "            variables_path / name_embedding_av,\n",
    "            allow_pickle=True,\n",
    "            fix_imports=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "embeddings_cls = np.vstack(embeddings_cls)\n",
    "embeddings_sep = np.vstack(embeddings_sep)\n",
    "embeddings_av = np.vstack(embeddings_av)\n",
    "\n",
    "np.save(\n",
    "    variables_path / \"embeddings_iclr_bert_cls\",\n",
    "    embeddings_cls,\n",
    "    allow_pickle=True,\n",
    "    fix_imports=True,\n",
    ")\n",
    "np.save(\n",
    "    variables_path / \"embeddings_iclr_bert_sep\",\n",
    "    embeddings_sep,\n",
    "    allow_pickle=True,\n",
    "    fix_imports=True,\n",
    ")\n",
    "np.save(\n",
    "    variables_path / \"embeddings_iclr_bert_av\",\n",
    "    embeddings_av,\n",
    "    allow_pickle=True,\n",
    "    fix_imports=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7b2ffcc-f32e-48f7-9dbb-4fbbe64d3eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.90858"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(embeddings_av - embeddings_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eaf68f-afd4-4506-82dc-7d2321b84f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
