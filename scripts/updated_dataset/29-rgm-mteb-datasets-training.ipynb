{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 10:39:02.893763: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-06 10:39:02.905536: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733477942.917050   17457 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733477942.920643   17457 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-06 10:39:02.936056: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import BertConfig, BertModel\n",
    "import mteb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset, load_dataset_builder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import memory_profiler\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from pathlib import Path\n",
    "import distro\n",
    "\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0+cu124'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old one '1.8.1+cu111'\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from text_embeddings_src.model_stuff import (\n",
    "    fix_all_seeds,\n",
    "    train_loop,\n",
    "    train_loop_train_test_split,\n",
    "    EmbeddingOnlyModel,\n",
    "    train_loop_embedding_layer,\n",
    ")\n",
    "from text_embeddings_src.data_stuff import (\n",
    "    MultOverlappingSentencesPairDataset,\n",
    "    SameSentencePairDataset,\n",
    ")\n",
    "from text_embeddings_src.embeddings import generate_embeddings, generate_embeddings_embed_layer\n",
    "from text_embeddings_src.metrics import knn_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(line_length=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_path = Path(\"../../results/variables\")\n",
    "figures_path = Path(\"../../results/figures/updated_dataset\")\n",
    "data_path = Path(\"../../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL FIX TO PATH ISSUE FROM VSCODE\n",
    "import text_embeddings_src\n",
    "\n",
    "nb_path = Path(text_embeddings_src.__path__[0]).parents[0] / Path(\n",
    "    \"scripts/updated_dataset\"\n",
    ")\n",
    "assert nb_path.exists(), \"The path does not exist\"\n",
    "\n",
    "variables_path = (nb_path / variables_path).resolve(strict=True)\n",
    "figures_path = (nb_path / figures_path).resolve(strict=True)\n",
    "data_path = (nb_path / data_path).resolve(strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use((nb_path / Path(\"../matplotlib_style.txt\")).resolve(strict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Rita Gonz치lez-M치rquez\n",
      "\n",
      "Last updated: 2024-12-06 10:39:44CET\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.12.4\n",
      "IPython version      : 8.28.0\n",
      "\n",
      "transformers: 4.45.2\n",
      "\n",
      "Compiler    : GCC 11.2.0\n",
      "OS          : Linux\n",
      "Release     : 4.18.0-553.el8_10.x86_64\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 64\n",
      "Architecture: 64bit\n",
      "\n",
      "Hostname: rgonzalesmarquez_GPU0-llm_gber7\n",
      "\n",
      "tqdm                 : 4.66.4\n",
      "torch                : 2.5.0\n",
      "mteb                 : 1.19.9\n",
      "sklearn              : 1.5.2\n",
      "transformers         : 4.45.2\n",
      "matplotlib           : 3.9.2\n",
      "numpy                : 1.26.4\n",
      "jupyter_black        : 0.4.0\n",
      "datasets             : 3.0.1\n",
      "pandas               : 2.2.3\n",
      "sentence_transformers: 3.3.0\n",
      "black                : 24.10.0\n",
      "distro               : 1.9.0\n",
      "scipy                : 1.11.4\n",
      "memory_profiler      : 0.61.0\n",
      "text_embeddings_src  : 0.0.0\n",
      "\n",
      "Watermark: 2.5.0\n",
      "\n",
      "Ubuntu 24.04 LTS\n"
     ]
    }
   ],
   "source": [
    "%watermark -a 'Rita Gonz치lez-M치rquez' -t -d -tz -u -v -iv -w -m -h -p transformers\n",
    "print(distro.name(pretty=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arxiv\n",
    "180 classes (secondary labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"arxiv\"\n",
    "dataset_path = \"mteb/arxiv-clustering-p2p\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"mteb/arxiv-clustering-p2p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['sentences', 'labels'],\n",
       "        num_rows: 31\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(\n",
    "    np.hstack(dataset.data[\"test\"].to_pandas().sentences.to_numpy())\n",
    ")\n",
    "labels_secondary = list(\n",
    "    np.hstack(dataset.data[\"test\"].to_pandas().labels.to_numpy())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_main = [elem.split(\".\")[0] for elem in labels_secondary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples 732723\n",
      "# classes (secondary) 180\n",
      "# classes (main) 39\n"
     ]
    }
   ],
   "source": [
    "print(\"# samples\", len(labels_secondary))\n",
    "print(\"# classes (secondary)\", len(np.unique(labels_secondary)))\n",
    "print(\"# classes (main)\", len(np.unique(labels_main)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acc-phys', 'adap-org', 'alg-geom', 'ao-sci', 'astro-ph',\n",
       "       'atom-ph', 'chao-dyn', 'chem-ph', 'cmp-lg', 'comp-gas', 'cond-mat',\n",
       "       'cs', 'dg-ga', 'econ', 'eess', 'funct-an', 'gr-qc', 'hep',\n",
       "       'hep-ex', 'hep-lat', 'hep-ph', 'hep-th', 'math', 'math-ph',\n",
       "       'mtrl-th', 'nlin', 'nucl-ex', 'nucl-th', 'other', 'patt-sol',\n",
       "       'physics', 'plasm-ph', 'q-alg', 'q-bio', 'q-fin', 'quant-ph',\n",
       "       'solv-int', 'stat', 'supr-con'], dtype='<U8')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "tfidf_features = vectorizer.fit_transform(sentences)\n",
    "print(tfidf_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 6361.34 MiB, increment: 2161.59 MiB\n",
      "CPU times: user 21min 59s, sys: 30min 22s, total: 52min 22s\n",
      "Wall time: 4min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=100, random_state=42, algorithm=\"arpack\")\n",
    "svd_data = svd.fit_transform(tfidf_features)\n",
    "\n",
    "# # save results\n",
    "# np.save(variables_path / \"updated_dataset\" / \"svd_data\", svd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 76265.64 MiB, increment: 0.00 MiB\n",
      "CPU times: user 3d 11h 58min 16s, sys: 7min 27s, total: 3d 12h 5min 43s\n",
      "Wall time: 2h 41min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "knn_accuracies_main = knn_accuracy(\n",
    "    [tfidf_features, svd_data, normalize(svd_data, axis=1)],\n",
    "    labels_main,\n",
    ")\n",
    "np.save(\n",
    "    variables_path\n",
    "    / \"updated_dataset\"\n",
    "    / f\"knn_accuracy_tfidf_svd_l2_{dataset_name}_main\",\n",
    "    knn_accuracies_main,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 7171.77 MiB, increment: 1056.76 MiB\n",
      "CPU times: user 4d 12h 24min 4s, sys: 50.3 s, total: 4d 12h 24min 54s\n",
      "Wall time: 5h 40min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "knn_accuracies_secondary = knn_accuracy(\n",
    "    # [svd_data, normalize(svd_data, axis=1)],\n",
    "    [tfidf_features, svd_data, normalize(svd_data, axis=1)],\n",
    "    labels_secondary,\n",
    ")\n",
    "np.save(\n",
    "    variables_path\n",
    "    / \"updated_dataset\"\n",
    "    / f\"knn_accuracy_tfidf_svd_l2_{dataset_name}_secondary\",\n",
    "    knn_accuracies_secondary,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74496745 0.70559415 0.71711272]\n",
      "[0.44394252 0.39996998 0.4052243 ]\n"
     ]
    }
   ],
   "source": [
    "knn_accuracies_main = np.load(\n",
    "    variables_path\n",
    "    / \"updated_dataset\"\n",
    "    / f\"knn_accuracy_tfidf_svd_l2_{dataset_name}_main.npy\",\n",
    ")\n",
    "\n",
    "print(knn_accuracies_main)\n",
    "print(knn_accuracies_secondary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "    \"SimCSE\",\n",
    "    \"SBERT\",\n",
    "    \"SPECTER\",\n",
    "    \"SciNCL\",\n",
    "]\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "    \"princeton-nlp/unsup-simcse-bert-base-uncased\",\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    \"allenai/specter\",\n",
    "    \"malteos/scincl\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  SciNCL\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ecd499952e042189667b96e84e471bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "for i, model_name in enumerate(model_names):\n",
    "    # fix random seeds\n",
    "    fix_all_seeds()\n",
    "\n",
    "    # set up model\n",
    "    print(\"Model: \", model_names[i])\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Running on device: {}\".format(device))\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "    model = AutoModel.from_pretrained(model_paths[i])\n",
    "\n",
    "    # evaluation\n",
    "    model.to(device)\n",
    "\n",
    "    ## get embeddings\n",
    "    embedding_cls, embedding_sep, embedding_av = generate_embeddings(\n",
    "        sentences,\n",
    "        tokenizer,\n",
    "        model,\n",
    "        device,\n",
    "        batch_size=256,\n",
    "    )\n",
    "\n",
    "    ## run knn\n",
    "    knn_accuracies_baseline_main = knn_accuracy(\n",
    "        [\n",
    "            embedding_av,\n",
    "            embedding_cls,\n",
    "            embedding_sep,\n",
    "        ],\n",
    "        labels_main,\n",
    "    )\n",
    "    print(f\"{model_name}: {knn_accuracies_baseline_main}\")\n",
    "\n",
    "    knn_accuracies_baseline_secondary = knn_accuracy(\n",
    "        [\n",
    "            embedding_av,\n",
    "            embedding_cls,\n",
    "            embedding_sep,\n",
    "        ],\n",
    "        labels_secondary,\n",
    "    )\n",
    "    print(f\"{model_name}: {knn_accuracies_baseline_secondary}\")\n",
    "\n",
    "    # save\n",
    "    saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "        f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    "    )\n",
    "    (variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    np.save(\n",
    "        variables_path / saving_path / \"knn_accuracies_baseline_main\",\n",
    "        knn_accuracies_baseline_main,\n",
    "    )\n",
    "    np.save(\n",
    "        variables_path / saving_path / \"knn_accuracies_baseline_secondary\",\n",
    "        knn_accuracies_baseline_secondary,\n",
    "    )\n",
    "\n",
    "    model = None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune MPNet (crops)\n",
    "Run 1, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f17da622c5f4abdace5582b1d79c1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8131c87c0049e5bde9adba1fb8e05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 9h 31min 46s, sys: 4h 34min 37s, total: 14h 6min 24s\n",
      "Wall time: 5h 40min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "(\n",
    "    losses,\n",
    "    knn_accuracies_main,\n",
    "    embedding_cls,\n",
    "    embedding_sep,\n",
    "    embedding_av,\n",
    ") = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    sentences,\n",
    "    tokenizer,\n",
    "    np.ones(len(sentences), dtype=bool),\n",
    "    labels_acc=labels_main,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    "    return_embeddings=True,\n",
    ")\n",
    "\n",
    "\n",
    "knn_accuracies_secondary = knn_accuracy(\n",
    "    [\n",
    "        embedding_av,\n",
    "        embedding_cls,\n",
    "        embedding_sep,\n",
    "    ],\n",
    "    labels_secondary,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run1\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run1_main\",\n",
    "    knn_accuracies_main,\n",
    ")\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run1_secondary\",\n",
    "    knn_accuracies_secondary,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.74887066, 0.72209409, 0.73523672])]\n",
      "[0.44231845 0.41610143 0.42875275]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies_main)\n",
    "print(knn_accuracies_secondary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set\n",
    "Only MPNet, crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0156b960e3411893a4ff1d8c14a4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15289 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2107ed7882e64e26ab3fc5c17dcb2684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2576 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75d73409cea4634912947d8b943597b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8h 30min 49s, sys: 55min 58s, total: 9h 26min 48s\n",
      "Wall time: 5h 6min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    sentences,\n",
    "    labels_secondary,\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences_train), tokenizer, device, n_cons_sntcs=2, seed=42\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run1_train_test_split\", losses)\n",
    "np.save(\n",
    "    variables_path\n",
    "    / saving_path\n",
    "    / \"knn_accuracies_run1_secondary_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44126758833403845]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune MPNet (dropout)\n",
    "Run 2, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f45a6997eaf4af8a9c70e0036fb9a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b85bda70e74fba8b0cadff375026be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 9h 32min 41s, sys: 4h 42min 47s, total: 14h 15min 28s\n",
      "Wall time: 5h 41min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "training_dataset = SameSentencePairDataset(\n",
    "    pd.Series(sentences),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "(\n",
    "    losses,\n",
    "    knn_accuracies_main,\n",
    "    embedding_cls,\n",
    "    embedding_sep,\n",
    "    embedding_av,\n",
    ") = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    sentences,\n",
    "    tokenizer,\n",
    "    np.ones(len(sentences), dtype=bool),\n",
    "    labels_acc=labels_main,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    "    return_embeddings=True,\n",
    ")\n",
    "\n",
    "\n",
    "knn_accuracies_secondary = knn_accuracy(\n",
    "    [\n",
    "        embedding_av,\n",
    "        embedding_cls,\n",
    "        embedding_sep,\n",
    "    ],\n",
    "    labels_secondary,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run2\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run2_main\",\n",
    "    knn_accuracies_main,\n",
    ")\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run2_secondary\",\n",
    "    knn_accuracies_secondary,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.70425668, 0.70055819, 0.70341053])]\n",
      "[0.39919206 0.40286326 0.39939678]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies_main)\n",
    "print(knn_accuracies_secondary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set\n",
    "Only MPNet, Dropout, eval only for labels secondary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb55c277ebb14db4b0fd321bb1872a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15289 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4160481e2da94c95a21c4ed4040d227d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2576 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61da3996d844a4f84e0d394fc5a9256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8h 39min 50s, sys: 1h 2min 28s, total: 9h 42min 18s\n",
      "Wall time: 5h 7min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    sentences,\n",
    "    labels_secondary,\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = SameSentencePairDataset(\n",
    "    pd.Series(sentences_train),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run2_train_test_split\", losses)\n",
    "np.save(\n",
    "    variables_path\n",
    "    / saving_path\n",
    "    / \"knn_accuracies_run2_secondary_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3891474349351057]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune random BERT (crops)\n",
    "Run 5, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  random_bert\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bac2186e8274c15bdd64b799f748cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7620c87675624b219e04ff9a63ae1cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071adfaf320940769596d3b3a16e3a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347f9dbe03da4ca18954889cd4c52ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e64f232840548989483f5fe3d926d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831b6a08860945c9bf3f900790f6c5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029f9a1876b444aba982c6e1b335b8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "model_name = \"random_bert\"\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "## randomly initialized model\n",
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model = BertModel(configuration)\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "(\n",
    "    losses,\n",
    "    knn_accuracies_main,\n",
    "    embedding_cls,\n",
    "    embedding_sep,\n",
    "    embedding_av,\n",
    ") = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    sentences,\n",
    "    tokenizer,\n",
    "    np.ones(len(sentences), dtype=bool),\n",
    "    labels_acc=labels_main,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=2e-5,\n",
    "    return_embeddings=True,\n",
    ")\n",
    "\n",
    "\n",
    "knn_accuracies_secondary = knn_accuracy(\n",
    "    [\n",
    "        embedding_av,\n",
    "        embedding_cls,\n",
    "        embedding_sep,\n",
    "    ],\n",
    "    labels_secondary,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run5\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run5_main\",\n",
    "    knn_accuracies_main,\n",
    ")\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run5_secondary\",\n",
    "    knn_accuracies_secondary,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.72861764, 0.7220395 , 0.71355069]), array([0.73879874, 0.73306675, 0.7321933 ]), array([0.74343892, 0.73916722, 0.73784341]), array([0.74585454, 0.74252453, 0.74103694]), array([0.7475059 , 0.74270195, 0.74331609]), array([0.74974411, 0.74479003, 0.74536323]), array([0.75184584, 0.74539053, 0.74534958]), array([0.75024907, 0.74756049, 0.7472193 ]), array([0.75180489, 0.74731484, 0.7497714 ]), array([0.75281482, 0.74732848, 0.74897984])]\n",
      "[0.44605789 0.44525269 0.44323284]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies_main)\n",
    "print(knn_accuracies_secondary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set \n",
    "RandomBERT, Crops\n",
    "With modified train loop to only evaluate after the 10 training epochs and not after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  random_bert\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da75148802c412d907f6c069ff09c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f6fc7415414338a80c55e312af51a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9bd9208060450eb81ff1d6c6ad1059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40104e8e2a6a48ba803e2b3d73979094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd25e31b1acb4db0bc76ef423319391f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8258dcaf9f1a47b59161a48a30244235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ba5b4d5ed04ca8856d408a52c23b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "model_name = \"random_bert\"\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "## randomly initialized model\n",
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model = BertModel(configuration)\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    sentences,\n",
    "    labels_secondary,\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences_train), tokenizer, device, n_cons_sntcs=2, seed=42\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split(       # Modified to evaluate only after the 10 training epochs, for runtime reasons\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run5_train_test_split\", losses)\n",
    "np.save(\n",
    "    variables_path\n",
    "    / saving_path\n",
    "    / \"knn_accuracies_run5_secondary_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44734076672171197]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune random embedding layer (not module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 3, crop augmentations 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model_random = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model_random.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "CPU times: user 57.1 ms, sys: 63.1 ms, total: 120 ms\n",
      "Wall time: 392 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Extract the embedding layer\n",
    "embedding_layer = model_random.embeddings.word_embeddings\n",
    "# new model\n",
    "model = EmbeddingOnlyModel(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e4897072354dccb553e1b6042bffed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916c36315c93413fada69cfa88d339cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 5h 1min 24s, sys: 31min 16s, total: 5h 32min 40s\n",
      "Wall time: 25min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "(\n",
    "    losses,\n",
    "    knn_accuracies_main,\n",
    "    embedding_cls,\n",
    "    embedding_sep,\n",
    "    embedding_av,\n",
    ") = train_loop_embedding_layer(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    sentences,\n",
    "    tokenizer,\n",
    "    np.ones(len(sentences), dtype=bool),\n",
    "    labels_acc=labels_main,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    "    return_embeddings=True,\n",
    ")\n",
    "\n",
    "\n",
    "knn_accuracies_secondary = knn_accuracy(\n",
    "    [\n",
    "        embedding_av,\n",
    "        embedding_cls,\n",
    "        embedding_sep,\n",
    "    ],\n",
    "    labels_secondary,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_random_bert\") / Path(\n",
    "    f\"updated_dataset/embedding_layer_experiment/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run3\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run3_main\",\n",
    "    knn_accuracies_main,\n",
    ")\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run3_secondary\",\n",
    "    knn_accuracies_secondary,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.70775047, 0.13441513, 0.17986161])]\n",
      "[0.39923301 0.0050769  0.01225554]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies_main)\n",
    "print(knn_accuracies_secondary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 3, crop augmentations 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model_random = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model_random.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "CPU times: user 58.2 ms, sys: 16.1 ms, total: 74.2 ms\n",
      "Wall time: 318 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Extract the embedding layer\n",
    "embedding_layer = model_random.embeddings.word_embeddings\n",
    "# new model\n",
    "model = EmbeddingOnlyModel(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e9bfe9d7aa42a7954eb0865751594b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39e9e51de554eee8a2641fa2e2d5991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a82f5bcf584233bdda0cce7b1fb262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab487c5952a496bb3cb12a66d7cfd4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec70dcc81d34e58b38de0cdb8ee8f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96c42dd787c4eeeba6a8c919edda646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404dba914cb8420d9f70b5891d0d5f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70c5a81f4b9469eb3b54bffaa8e0360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25278ae52f540ee9087b8dadf926054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459896c4827d4e37aaf011f878dbde95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3941c6226fa246fc982003510c042ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2a777592c44a3880cf7003bbec859b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68ef306eef34afaaed4233e75fa21bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de71379a09a348eb83fd402e3dba5296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11c64a0fd2540588be0528622510a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ad589895f748ea9fdc14400b88c298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2622d51d0d44e53b86ca81335a69f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de494f2b07ed4ab88e2347e5e54d5138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1f9ea797394053b63cd4a90e1985a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0796e0b393dd43d8bc682248637089cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 1d 4h 24min 47s, sys: 2h 38min 13s, total: 1d 7h 3min\n",
      "Wall time: 2h 41min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "(\n",
    "    losses,\n",
    "    knn_accuracies_main,\n",
    "    embedding_cls,\n",
    "    embedding_sep,\n",
    "    embedding_av,\n",
    ") = train_loop_embedding_layer(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    sentences,\n",
    "    tokenizer,\n",
    "    np.ones(len(sentences), dtype=bool),\n",
    "    labels_acc=labels_main,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=2e-5,\n",
    "    return_embeddings=True,\n",
    ")\n",
    "\n",
    "\n",
    "knn_accuracies_secondary = knn_accuracy(\n",
    "    [\n",
    "        embedding_av,\n",
    "        embedding_cls,\n",
    "        embedding_sep,\n",
    "    ],\n",
    "    labels_secondary,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_random_bert\") / Path(\n",
    "    f\"updated_dataset/embedding_layer_experiment/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run3_10_epochs\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run3_10_epochs_main\",\n",
    "    knn_accuracies_main,\n",
    ")\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run3_10_epochs_secondary\",\n",
    "    knn_accuracies_secondary,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74031362 0.13441513 0.17986161]\n",
      "[0.43374777 0.0050769  0.01225554]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies_main[-1])\n",
    "print(knn_accuracies_secondary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set\n",
    "10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model_random = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model_random.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "CPU times: user 51.6 ms, sys: 7.22 ms, total: 58.8 ms\n",
      "Wall time: 175 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# Extract the embedding layer\n",
    "embedding_layer = model_random.embeddings.word_embeddings\n",
    "# new model\n",
    "model = EmbeddingOnlyModel(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cde5560d710484ca158b38e5422b207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ceaf2853b894b2dbd24167b4d62cb17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d786d429e2642a78d4a5fbf2859bd5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabfa990fc08423595752c02541df7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919fb9370b904f16b6013dfc3c43629e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9b3b241b0e46baab90aedcfaedab1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5c3003e43e46f0902854cec8768741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7c5a5056834957aea9ad471fe4a5fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1767aa2c07384548afef5878a0cdab42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352d1bb7f3994f1a89a8e721b174be89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480d110aaf5c4be79b25e31d44b465f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2576 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582df0bf5a8e4927bba2417f9dc30a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 2h 15min 48s, sys: 38min 59s, total: 2h 54min 47s\n",
      "Wall time: 54min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    sentences,\n",
    "    labels_secondary,\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences_train), tokenizer, device, n_cons_sntcs=2, seed=42\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split_embedding_layer(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_random_bert\") / Path(\n",
    "    f\"updated_dataset/embedding_layer_experiment/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(\n",
    "    variables_path / saving_path / \"losses_run3_10_epochs_train_test_split\",\n",
    "    losses,\n",
    ")\n",
    "np.save(\n",
    "    variables_path\n",
    "    / saving_path\n",
    "    / \"knn_accuracies_run3_10_epochs_secondary_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4326559578562363]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune SBERT (crops)\n",
    "Run 1, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"SBERT\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  SBERT\n",
      "Running on device: cuda\n",
      "sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d62ff185c9c4a0a8a5fa5e2c4cc00b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    sentences,\n",
    "    tokenizer,\n",
    "    np.ones(len(sentences), dtype=bool),\n",
    "    labels_acc=labels_secondary,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run1\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run1_secondary\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.45237673, 0.42059149, 0.43271055])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biorxiv\n",
    "26 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"biorxiv\"\n",
    "dataset_path = \"mteb/biorxiv-clustering-p2p\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"mteb/biorxiv-clustering-p2p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['sentences', 'labels'],\n",
       "        num_rows: 53787\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53787, 168265)\n",
      "CPU times: user 6.71 s, sys: 160 ms, total: 6.87 s\n",
      "Wall time: 6.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "tfidf_features = vectorizer.fit_transform(dataset[\"test\"][\"sentences\"])\n",
    "print(tfidf_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1890.98 MiB, increment: 447.24 MiB\n",
      "CPU times: user 6min 26s, sys: 16min 23s, total: 22min 49s\n",
      "Wall time: 25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=100, random_state=42, algorithm=\"arpack\")\n",
    "svd_data = svd.fit_transform(tfidf_features)\n",
    "\n",
    "# # save results\n",
    "# np.save(variables_path / \"updated_dataset\" / \"svd_data\", svd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2105.75 MiB, increment: 125.71 MiB\n",
      "CPU times: user 54min 32s, sys: 5.65 s, total: 54min 37s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "knn_accuracies = knn_accuracy(\n",
    "    [tfidf_features, svd_data, normalize(svd_data, axis=1)],\n",
    "    dataset[\"test\"][\"labels\"],\n",
    ")\n",
    "np.save(\n",
    "    variables_path\n",
    "    / \"updated_dataset\"\n",
    "    / f\"knn_accuracy_tfidf_svd_l2_{dataset_name}\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60661833 0.60959286 0.62502324]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "    \"SimCSE\",\n",
    "    \"SBERT\",\n",
    "    \"SPECTER\",\n",
    "    \"SciNCL\",\n",
    "]\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "    \"princeton-nlp/unsup-simcse-bert-base-uncased\",\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    \"allenai/specter\",\n",
    "    \"malteos/scincl\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  SPECTER\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/.pyenv/versions/miniconda3-latest/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837b12e3dcd142a9b3a4c336a3197d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPECTER: [0.64807585 0.64751813 0.64863358]\n",
      "----------------------------\n",
      "Model:  SciNCL\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469c1992bcdf45e199cdf3d0a1b3533a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SciNCL: [0.66369214 0.64677449 0.65012084]\n",
      "----------------------------\n",
      "CPU times: user 9min 30s, sys: 13min 22s, total: 22min 52s\n",
      "Wall time: 14min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, model_name in enumerate(model_names):\n",
    "    # fix random seeds\n",
    "    fix_all_seeds()\n",
    "\n",
    "    # set up model\n",
    "    print(\"Model: \", model_names[i])\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Running on device: {}\".format(device))\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "    model = AutoModel.from_pretrained(model_paths[i])\n",
    "\n",
    "    # evaluation\n",
    "    model.to(device)\n",
    "\n",
    "    ## get embeddings\n",
    "    embedding_cls, embedding_sep, embedding_av = generate_embeddings(\n",
    "        dataset[\"test\"][\"sentences\"],\n",
    "        tokenizer,\n",
    "        model,\n",
    "        device,\n",
    "        batch_size=256,\n",
    "    )\n",
    "\n",
    "    ## run knn\n",
    "    knn_accuracies_baseline = knn_accuracy(\n",
    "        [\n",
    "            embedding_av,\n",
    "            embedding_cls,\n",
    "            embedding_sep,\n",
    "        ],\n",
    "        dataset[\"test\"][\"labels\"],\n",
    "    )\n",
    "    print(f\"{model_name}: {knn_accuracies_baseline}\")\n",
    "\n",
    "    # save\n",
    "    saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "        f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    "    )\n",
    "    (variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    np.save(\n",
    "        variables_path / saving_path / \"knn_accuracies_baseline\",\n",
    "        knn_accuracies_baseline,\n",
    "    )\n",
    "\n",
    "    model = None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune MPNet (crops)\n",
    "Run 1, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.weight', 'mpnet.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd595f9462042bfa4af51ea6483e1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10ac2bcf1524cceb067940b611c7666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 20min 45s, sys: 16min 37s, total: 37min 22s\n",
      "Wall time: 19min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(dataset[\"test\"][\"sentences\"]),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    tokenizer,\n",
    "    np.ones(len(dataset[\"test\"]), dtype=bool),\n",
    "    labels_acc=dataset[\"test\"][\"labels\"],\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run1\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run1\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.61777282, 0.61256739, 0.60252835])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set\n",
    "Only MPNet, crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d11180ef8db421e80e965f12c4f7114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7422da0fe234af6b897ca68ef03f65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733032adf0f7468e9e9a1d1c184db265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28min 16s, sys: 2min 45s, total: 31min 2s\n",
      "Wall time: 17min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    dataset[\"test\"][\"labels\"],\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences_train), tokenizer, device, n_cons_sntcs=2, seed=42\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run1_train_test_split\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run1_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6160996467744934]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune MPNet (dropout)\n",
    "Run 2, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "training_dataset = SameSentencePairDataset(\n",
    "    pd.Series(dataset[\"test\"][\"sentences\"]),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    tokenizer,\n",
    "    np.ones(len(dataset[\"test\"]), dtype=bool),\n",
    "    labels_acc=dataset[\"test\"][\"labels\"],\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run2\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run2\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.60680424, 0.59843837, 0.59174568])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set\n",
    "Only MPNet, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1bbc5a7e194b7a9d6393ab513c0889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24bc1bf706554862b12a0fdefbbdbee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752fc15aca234e4d9b2d87672a4c08de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28min 14s, sys: 2min 54s, total: 31min 9s\n",
      "Wall time: 17min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    dataset[\"test\"][\"labels\"],\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = SameSentencePairDataset(\n",
    "    pd.Series(sentences_train),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run2_train_test_split\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run2_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6092210448038669]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune random BERT (crops)\n",
    "Run 5, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  random_bert\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258d0bfa057d48af829c8a0115876492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bc7c6303724bf5afae282c2f2dc310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be737e50f2c4ebdb14b988f948c2b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71bfa300c9e4b7bb15c63e98a9e159e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef7d46b7e1946f6be2e0b2a9500ecb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e1561e260a4879994bed848979c514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834c58159fa640d3b3a4ead9883d3ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2fb29e6b8b403085f10996c53c8dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da956588606400fa5b78330ddc53805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4382b9aa1624e0d9cd8bb82b5782fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c8f7de2eda45ac918efbcd860136bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1e75dff56646d7a2284bb568dcffd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3857cc4a61eb4a2192c1b897f6766cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ef1e9063314d97aa0b8b9f80fd36f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4e41ed8fee46dfb1e9ce7822f2e6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c2bcf2eb114da4a876c525e2666f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1055566afafb438181ce46a91a8d2079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8b3c4bc524448ca41c09797a44df40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69643b0e7344c4d9ea15eba157150b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046ea6a909474c30b0cf4fed3a85c627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 1h 31min 3s, sys: 2h 14min 8s, total: 3h 45min 11s\n",
      "Wall time: 2h 49min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "model_name = \"random_bert\"\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "## randomly initialized model\n",
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model = BertModel(configuration)\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(dataset[\"test\"][\"sentences\"]),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    tokenizer,\n",
    "    np.ones(len(dataset[\"test\"]), dtype=bool),\n",
    "    labels_acc=dataset[\"test\"][\"labels\"],\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run5\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run5\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.61777282, 0.61256739, 0.60252835])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set \n",
    "RandomBERT, Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  random_bert\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9770e4cee78045fbb222991fa5edc00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c9308bea1044bebd58c261dfb581c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3641ec59c441bea2f344e3fca7324d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52f15bbbf9f49d68eb7d895341c802c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d86d23b766a4ad19646e8a194b602e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9e92b538dd4ffcab8f209af5e169fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e01d4fc25a841c3886f6ad343f0f2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0647d7144892455ebc11f9270602b241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e8ab2852be41568cf413ee1e7a480f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f64c789e82449be91d9e642b232ed1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12931e434a24e1786bc5036b3408e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e744ec2e979c4ddeb932d3a4149ec41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425785b895b84b9d87831163e10705ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083a860147dd4c6b979c3ac7a9db53fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca92820e93d43509fd0689a9320339a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2dfb1400c3c449ba71cadddb2117b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb56a4bdaf784da58901201212e0da24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6906b7fdbc5a494c8e2fdc89d28c32d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d9eed0e2e543fd828a2ae371cffb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf554be5991049329ee1e6826aa411fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dfbc31877f34d5c866e8347921637d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef484da7cd1476892d27e8ab75ce1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48687aa53154d78be10a72485645f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "model_name = \"random_bert\"\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "## randomly initialized model\n",
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model = BertModel(configuration)\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    dataset[\"test\"][\"labels\"],\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences_train), tokenizer, device, n_cons_sntcs=2, seed=42\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run5_train_test_split\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run5_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5302100762223462, 0.556237218813906, 0.5668339840118981, 0.5746421267893661, 0.5783602900167317, 0.581148912437256, 0.5913738613125116, 0.591002044989775, 0.5919315857966164, 0.5926752184420896]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune random embedding layer (not module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 3, crop augmentations, 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model_random = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model_random.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "CPU times: user 28.1 ms, sys: 31.1 ms, total: 59.2 ms\n",
      "Wall time: 190 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Extract the embedding layer\n",
    "embedding_layer = model_random.embeddings.word_embeddings\n",
    "# new model\n",
    "model = EmbeddingOnlyModel(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b6522d026242a3a226ecb2ddc41a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021f1c0445474e619fcdb79e5e8e7a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 7min 12s, sys: 2min 7s, total: 9min 19s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(dataset[\"test\"][\"sentences\"]),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_embedding_layer(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    tokenizer,\n",
    "    np.ones(len(dataset[\"test\"]), dtype=bool),\n",
    "    labels_acc=dataset[\"test\"][\"labels\"],\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=5e-1,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_random_bert\") / Path(\n",
    "    f\"updated_dataset/embedding_layer_experiment/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run3\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run3\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.59063023, 0.03495073, 0.04182934])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.47276445, 0.03495073, 0.04182934])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 3, crop augmentations, 10 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model_random = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model_random.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "CPU times: user 39.1 ms, sys: 9.3 ms, total: 48.4 ms\n",
      "Wall time: 164 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Extract the embedding layer\n",
    "embedding_layer = model_random.embeddings.word_embeddings\n",
    "# new model\n",
    "model = EmbeddingOnlyModel(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218a76e35c1c4d6e8ed50c4c559a285e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b093293c1041413fb7bfca4fa4edb268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3408c17d946048e5a69ce880ab77d616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3162a5ed5b1d4ece8eb7a2d0f8ab2822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7763e34d2444bbda318873bf93474de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdfcfe03bd14ed28870a310c4a6f167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aef7d10e2134c7db4cf7cb3c357da96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad9b437ef9b4edb848251ce39c9185f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6b541ddbf64f0f924a691f0da6a543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26f1f66a4bc49e9af5df252ba35b0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b98bdea2f74270a132874036b89b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e08207984b34090a18378a73fc43c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f6e8bec61a4813bf29a1fcb1c7b410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d34b49286748fb8d2a494bc0b96a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecdb3b1bc5741b3989df4d30f716e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6ad38f9a19426eba844f63a1140c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252cf10e6c5e4708ad4ddbbb499ced90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784f4dfe0dcc457f97c4718e9ef8d956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e5ce74333647f2b5e28b6520e440af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae4eb6c5d2244efaf11027c1165c718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 43min 52s, sys: 12min 36s, total: 56min 29s\n",
      "Wall time: 11min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(dataset[\"test\"][\"sentences\"]),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_embedding_layer(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    tokenizer,\n",
    "    np.ones(len(dataset[\"test\"]), dtype=bool),\n",
    "    labels_acc=dataset[\"test\"][\"labels\"],\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=5e-1,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_random_bert\") / Path(\n",
    "    f\"updated_dataset/embedding_layer_experiment/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run3_10_epochs\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run3_10_epochs\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracies = np.vstack(knn_accuracies)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(6, 2), dpi=200)\n",
    "n_epochs = 10\n",
    "colormap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "# plot\n",
    "color = \"k\"  \n",
    "\n",
    "axs[0].plot(\n",
    "    np.arange(n_epochs),\n",
    "    np.mean(losses, axis=1),\n",
    "    label=\"Random embedding layer\",\n",
    "    color=color,\n",
    ")\n",
    "axs[0].set_xticks(np.arange(n_epochs))\n",
    "# axs[0].set_ylim(top=0.05)\n",
    "axs[0].set_xlabel(\"Epochs\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(\n",
    "    np.arange(n_epochs),\n",
    "    knn_accuracies[:, 0],\n",
    "    label=f\"({knn_accuracies[0, 0]:.3f}, {knn_accuracies[-1, 0]:.3f})\",\n",
    "    color=color,\n",
    ")\n",
    "\n",
    "axs[1].set_xticks(np.arange(n_epochs))\n",
    "# axs[1].set_ylim(0.2, 0.65)\n",
    "axs[1].set_xlabel(\"Epochs\")\n",
    "axs[1].set_ylabel(\"kNN accuracy [AV]\")\n",
    "axs[1].legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "fig.savefig(\n",
    "    figures_path\n",
    "    / f\"loss_and_knn_accuracy_training_embeddR_run_3_{dataset_name}_v1.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set\n",
    "10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model_random = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model_random.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "CPU times: user 53.2 ms, sys: 3.64 ms, total: 56.9 ms\n",
      "Wall time: 168 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Extract the embedding layer\n",
    "embedding_layer = model_random.embeddings.word_embeddings\n",
    "# new model\n",
    "model = EmbeddingOnlyModel(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce9422301b8419a9b4e186403e080b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2ebaebd6014df29d6529a28f9387b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea192fa9e3e4b5498a5d0d3c14ce3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183365985ee04ba09d2a1dcc0a1d45cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19abeebd18744a094a48751da2883d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ee1ca8f3354b4b83c8440f83f4adfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093dcd667031484d9c57365806180987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5931a9e3cba442be9eed718367280d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95b19f44a9949a2984265048ea792c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b403c1d7e1c400fb85a4ac306519050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513392b20ce941a192c2b5a27779e8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ede9428a72440e79e36bac370670584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4ec3fea45442ad877305207a97a7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed2997a7757459d8037a02d4f8065f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4bc7ccde73a41909f8a19089d0d97d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d5b3c1ba634e2ab996611570ef1f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea33e01a26f4d42a379af982c813f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f985d3ce3c47c8b307b1bc61bb4bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8521b65d19284cdda2846ee75c86b673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00abf49e7ca4d39b874f8c5b546f230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e756110a5de740ca8080a096fcf28843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414e73c59ad1417aad7ac5dfa8383bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4af01f9f660480b85922a40189e192a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9209e3c3cf4d45f592734d6eb7370b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb5915f054f4346bb083c73b46d72b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcbadf1b6994076ab5878c1ae09187d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f72d949e1b41cd88866583885b2dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff1bd059448411ebe7a7fe580e6c99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6fc49997af43728bb0c68a54e87107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a52175a47234796a74b66f3634ec2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 47min 44s, sys: 5min 54s, total: 53min 38s\n",
      "Wall time: 9min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    dataset[\"test\"][\"labels\"],\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences_train), tokenizer, device, n_cons_sntcs=2, seed=42\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split_embedding_layer(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_random_bert\") / Path(\n",
    "    f\"updated_dataset/embedding_layer_experiment/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(\n",
    "    variables_path / saving_path / \"losses_run3_10_epochs_train_test_split\",\n",
    "    losses,\n",
    ")\n",
    "np.save(\n",
    "    variables_path\n",
    "    / saving_path\n",
    "    / \"knn_accuracies_run3_10_epochs_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune SBERT (crops)\n",
    "Run 1, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"SBERT\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  SBERT\n",
      "Running on device: cuda\n",
      "sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d239bff5e3c0401994f5dd25c6741d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ddba436614470096ce06633fd2cbbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 31min 52s, sys: 3min 4s, total: 34min 56s\n",
      "Wall time: 18min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(dataset[\"test\"][\"sentences\"]),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    tokenizer,\n",
    "    np.ones(len(dataset[\"test\"]), dtype=bool),\n",
    "    labels_acc=dataset[\"test\"][\"labels\"],\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run1\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run1\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.64863358, 0.58226436, 0.59602157])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medrxiv\n",
    "51 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"medrxiv\"\n",
    "dataset_path = \"mteb/medrxiv-clustering-p2p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['sentences', 'labels'],\n",
       "        num_rows: 17647\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17647, 78739)\n",
      "CPU times: user 2.47 s, sys: 32.7 ms, total: 2.5 s\n",
      "Wall time: 2.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "tfidf_features = vectorizer.fit_transform(dataset[\"test\"][\"sentences\"])\n",
    "print(tfidf_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2198.69 MiB, increment: 0.00 MiB\n",
      "CPU times: user 8.59 s, sys: 208 ms, total: 8.8 s\n",
      "Wall time: 8.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=100, random_state=42, algorithm=\"arpack\")\n",
    "svd_data = svd.fit_transform(tfidf_features)\n",
    "\n",
    "# # save results\n",
    "# np.save(variables_path / \"updated_dataset\" / \"svd_data\", svd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2197.59 MiB, increment: 3.94 MiB\n",
      "CPU times: user 7min 25s, sys: 4.77 s, total: 7min 30s\n",
      "Wall time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "knn_accuracies = knn_accuracy(\n",
    "    [tfidf_features, svd_data, normalize(svd_data, axis=1)],\n",
    "    dataset[\"test\"][\"labels\"],\n",
    ")\n",
    "np.save(\n",
    "    variables_path\n",
    "    / \"updated_dataset\"\n",
    "    / f\"knn_accuracy_tfidf_svd_l2_{dataset_name}\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52011331 0.4878187  0.5286119 ]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "    \"SimCSE\",\n",
    "    \"SBERT\",\n",
    "    \"SPECTER\",\n",
    "    \"SciNCL\",\n",
    "]\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "    \"princeton-nlp/unsup-simcse-bert-base-uncased\",\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    \"allenai/specter\",\n",
    "    \"malteos/scincl\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e437cba6e93446a0ba3f3233d9935aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNet: [0.43512748 0.44192635 0.4368272 ]\n",
      "----------------------------\n",
      "Model:  SimCSE\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77038f1c8c8d442fbc62f3c6a116c34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimCSE: [0.47195467 0.42549575 0.44985836]\n",
      "----------------------------\n",
      "Model:  SBERT\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e682f7ccc1fa469a97fcb24fa38a6f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT: [0.56770538 0.52294618 0.55184136]\n",
      "----------------------------\n",
      "CPU times: user 6min 28s, sys: 7min 9s, total: 13min 37s\n",
      "Wall time: 7min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, model_name in enumerate(model_names):\n",
    "    # fix random seeds\n",
    "    fix_all_seeds()\n",
    "\n",
    "    # set up model\n",
    "    print(\"Model: \", model_names[i])\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Running on device: {}\".format(device))\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "    model = AutoModel.from_pretrained(model_paths[i])\n",
    "\n",
    "    # evaluation\n",
    "    model.to(device)\n",
    "\n",
    "    ## get embeddings\n",
    "    embedding_cls, embedding_sep, embedding_av = generate_embeddings(\n",
    "        dataset[\"test\"][\"sentences\"],\n",
    "        tokenizer,\n",
    "        model,\n",
    "        device,\n",
    "        batch_size=256,\n",
    "    )\n",
    "\n",
    "    ## run knn\n",
    "    knn_accuracies_baseline = knn_accuracy(\n",
    "        [\n",
    "            embedding_av,\n",
    "            embedding_cls,\n",
    "            embedding_sep,\n",
    "        ],\n",
    "        dataset[\"test\"][\"labels\"],\n",
    "    )\n",
    "    print(f\"{model_name}: {knn_accuracies_baseline}\")\n",
    "\n",
    "    # save\n",
    "    saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "        f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    "    )\n",
    "    (variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    np.save(\n",
    "        variables_path / saving_path / \"knn_accuracies_baseline\",\n",
    "        knn_accuracies_baseline,\n",
    "    )\n",
    "\n",
    "    model = None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune MPNet (crops)\n",
    "Run 1, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03139b3ad90a46f8aab756077f7e49e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef514cf3d9945aea0795f559bb759fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 7min 7s, sys: 6min 21s, total: 13min 29s\n",
      "Wall time: 7min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(dataset[\"test\"][\"sentences\"]),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    tokenizer,\n",
    "    np.ones(len(dataset[\"test\"]), dtype=bool),\n",
    "    labels_acc=dataset[\"test\"][\"labels\"],\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run1\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run1\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.52351275, 0.51784703, 0.50991501])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set\n",
    "Only MPNet, crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40eb67638de4c92aa8b90accc4e2926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3d5b7f62d8442da80f79a53c17416e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c816c68a9ee4b47a2035bc408557b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 31s, sys: 1min 29s, total: 12min 1s\n",
      "Wall time: 6min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    dataset[\"test\"][\"labels\"],\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences_train), tokenizer, device, n_cons_sntcs=2, seed=42\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run1_train_test_split\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run1_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5229461756373938]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune MPNet (dropout)\n",
    "Run 2, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8f0bf96172430bbdaebe09e93adf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15eb8e78925d446bbfc7bf43f91929eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 7min 21s, sys: 6min 16s, total: 13min 37s\n",
      "Wall time: 7min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "training_dataset = SameSentencePairDataset(\n",
    "    pd.Series(dataset[\"test\"][\"sentences\"]),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    tokenizer,\n",
    "    np.ones(len(dataset[\"test\"]), dtype=bool),\n",
    "    labels_acc=dataset[\"test\"][\"labels\"],\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run2\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run2\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.4776204 , 0.50311615, 0.50424929])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set\n",
    "Only MPNet, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382a0b63cb0f437d8d4ded0acead6e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc78ca52218e48568e7898f6119896d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6f231613484bc79358b6317a12d25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 31s, sys: 1min 8s, total: 11min 39s\n",
      "Wall time: 6min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    dataset[\"test\"][\"labels\"],\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = SameSentencePairDataset(\n",
    "    pd.Series(sentences_train),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run2_train_test_split\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run2_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4776203966005666]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune random BERT (crops)\n",
    "Run 5, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  random_bert\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c754fe4d298437c80c59590a2518f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6caff7fb6264070b777d1c34251d5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a676e7fb91044e1abccca0cc6a3925af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bfcb4c7ffc4461930cbce0f5c8c4fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff03a29ac9b54ad8891d7abc669f0ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5374deeeb8a0406e851085793a4d48c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de81c5372fa44297b0b1e95be92c8107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a753a72c37844b283f400cc9b5cd972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8273bf7501a54e0aa3dd94d6300ad4a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ce8eff4c9c4a0cb63843d8eb45f02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bef8ccce5143d8a273782b9d89335e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244e1697b93d464dad95bb6a51ca3f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec5e4be605a4bc5b06942da59d7ca6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6972a7b153488b9aefcb67bf792f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8876ff643f2e43f993b5d274a8654bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f6d92310464b858dce9ae8a2b6620b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777c7c401ceb427ba8265d26346d69a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865b5ae5d2214a798d7790f21f239df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353c0f9ec8df46dfbd71d204040df125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859912375142409d9946de20a77c312b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 30min 14s, sys: 50min 36s, total: 1h 20min 50s\n",
      "Wall time: 1h 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "model_name = \"random_bert\"\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "## randomly initialized model\n",
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model = BertModel(configuration)\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(dataset[\"test\"][\"sentences\"]),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    tokenizer,\n",
    "    np.ones(len(dataset[\"test\"]), dtype=bool),\n",
    "    labels_acc=dataset[\"test\"][\"labels\"],\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run5\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run5\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.61777282, 0.61256739, 0.60252835])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set \n",
    "RandomBERT, Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  random_bert\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421cb63f1896447e93d973d537d5954e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e2dff6aecb4b6d85556b92f9c9d938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7104c94ed734494dbde240b7f7d56ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b22989581394546b6df07e59c9c5d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652beef199b04b92b9a781542fdba63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bc542cc797481bb0432a7249da614d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6ca4d7e6da4bd3b026378304e8398d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0550f038fdd648f29b23d8bec694dd51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a4b1c96f4542c7b867c6f0fa26592a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0405ec565b148e49159477725533e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805b8620a3c148da8baa4a5089a4189a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df66a7dd526b483e8b1ced6fab14945e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2cf4826ce94052b797179b9c91547c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d976f48e104803a23ad6d0c26f80e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97774baa3934434aac61968a8ab7377b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f652326385484e2bb0e942111c118d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "model_name = \"random_bert\"\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "## randomly initialized model\n",
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model = BertModel(configuration)\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    dataset[\"test\"][\"labels\"],\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences_train), tokenizer, device, n_cons_sntcs=2, seed=42\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run5_train_test_split\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run5_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39773371104815863, 0.41076487252124644, 0.41473087818696885, 0.426628895184136, 0.42606232294617563, 0.44079320113314446, 0.4322946175637394, 0.4368271954674221, 0.43626062322946174, 0.4396600566572238]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune random embedding layer (not module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 3, crop augmentation, 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model_random = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model_random.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "CPU times: user 31.6 ms, sys: 10.2 ms, total: 41.8 ms\n",
      "Wall time: 162 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Extract the embedding layer\n",
    "embedding_layer = model_random.embeddings.word_embeddings\n",
    "# new model\n",
    "model = EmbeddingOnlyModel(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abde67a09b16412d883549b4d24ac479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8b3e8ae83544a99969ec19dd65f6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0704beafbdb64b33b0ed3d58a0b140f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625488a3804e40e0a518db89fd371dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6161f811f7d48dda865bb7e665cbd53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d9f014031d436f967371c8f2ac8449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c209d9af13c5428ab4a7861f7c321950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78d14cd0f964602931e091993366479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb253d6920d84b0caf840b841b275bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee7077eac1048c0ac998fff20dddb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651da5c5881445e39415ca6f5e0e08e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616ec988f5dc4a91a93a6a1836ca2b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a3328c428b456580149484463411ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e90a9574c7345de8639e0c8ce8c315d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7a593ac8674f1990fbdb38b3d1419c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8199ea1d374690aafa40cc402e1f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e354dfbd7b244e389ae894295ac6ec22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f0d69618164c3b81c710ad45aeaaf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f10572b0cf4146a6484343dab29849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579652dd8a0e4db4b03898bae3f4f53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 16min 50s, sys: 4min 25s, total: 21min 15s\n",
      "Wall time: 4min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(dataset[\"test\"][\"sentences\"]),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_embedding_layer(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    tokenizer,\n",
    "    np.ones(len(dataset[\"test\"]), dtype=bool),\n",
    "    labels_acc=dataset[\"test\"][\"labels\"],\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=5e-1,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_random_bert\") / Path(\n",
    "    f\"updated_dataset/embedding_layer_experiment/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run3\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run3\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 3, crop augmentation, 10 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model_random = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model_random.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "CPU times: user 31.6 ms, sys: 10.2 ms, total: 41.8 ms\n",
      "Wall time: 162 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Extract the embedding layer\n",
    "embedding_layer = model_random.embeddings.word_embeddings\n",
    "# new model\n",
    "model = EmbeddingOnlyModel(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abde67a09b16412d883549b4d24ac479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8b3e8ae83544a99969ec19dd65f6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0704beafbdb64b33b0ed3d58a0b140f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625488a3804e40e0a518db89fd371dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6161f811f7d48dda865bb7e665cbd53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d9f014031d436f967371c8f2ac8449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c209d9af13c5428ab4a7861f7c321950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78d14cd0f964602931e091993366479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb253d6920d84b0caf840b841b275bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee7077eac1048c0ac998fff20dddb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651da5c5881445e39415ca6f5e0e08e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616ec988f5dc4a91a93a6a1836ca2b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a3328c428b456580149484463411ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e90a9574c7345de8639e0c8ce8c315d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7a593ac8674f1990fbdb38b3d1419c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8199ea1d374690aafa40cc402e1f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e354dfbd7b244e389ae894295ac6ec22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f0d69618164c3b81c710ad45aeaaf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f10572b0cf4146a6484343dab29849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579652dd8a0e4db4b03898bae3f4f53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 16min 50s, sys: 4min 25s, total: 21min 15s\n",
      "Wall time: 4min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(dataset[\"test\"][\"sentences\"]),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_embedding_layer(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    tokenizer,\n",
    "    np.ones(len(dataset[\"test\"]), dtype=bool),\n",
    "    labels_acc=dataset[\"test\"][\"labels\"],\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=5e-1,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_random_bert\") / Path(\n",
    "    f\"updated_dataset/embedding_layer_experiment/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run3_10_epochs\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run3_10_epochs\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracies = np.vstack(knn_accuracies)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABAQAAAGOCAYAAAAAdNH2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAB7CAAAewgFu0HU+AACjiklEQVR4nOzdeVyN6f8/8NcpadOCULIllCxDiCxtSCj7MokizNjGLiFLGUQZyzCYMSXrGJWxE+YcSUr2JTLZt7GmEu337w8/5zt9CtFyn1Ov5+NxPx657uV63c3n0znnfa7ruiWCIAggIiIiIiIionJFRewARERERERERFT6WBAgIiIiIiIiKodYECAiIiIiIiIqh1gQICIiIiIiIiqHWBAgIiIiIiIiKodYECAiIiIiIiIqh1gQICIiIiIiIiqHWBAgIiIiIiIiKodYECAiIiIiIiIqh1gQICIiIiIiIiqHWBAgIiIiIiIiKodYECAiIiIiIiIqh1gQICIiIiIiIiqHWBAgIiIiIiIiKodYECAiIiIiIiIqh1gQICIiIiIiIiqHWBAgIiIiIiIiKodYECAiIiIiIiIqh1gQKIIOHTqIHYGIiIhKEF/riYioLGNBoAiSkpLEjkBERKTQIiIi0KZNG2hpacHExASBgYEQBOGjxycmJkIikeTbmjZt+sXXTUxMhIuLC/T19WFgYICxY8ciJSXli/LztZ6IiMqyCmIHICIiorIpJiYGzs7OGDx4MBYuXIioqCh4eXkhOzsb3t7eBZ5z8eJFAMDx48ehpaUlb//vz4W57uvXr+Hg4ABDQ0OEhITg2bNn8PLywp07d3D48OGSu2kiIiIlwoIAERERlYj58+ejZcuW2LJlCwDAyckJWVlZWLx4MSZNmgRNTc1851y8eBG1atWCg4NDka67bt06vHz5EufPn4eBgQEAoFatWujRowdOnTrFqQBERETglAEiIiIqARkZGZDJZOjbt2+e9gEDBiA1NRVRUVEFnnfx4kW0aNGiyNc9cuQIOnXqJC8GAICjoyN0dHRw8ODBr7wrIiKisoUFASIiIip2t2/fRmZmJho1apSnvUGDBgCAhISEAs+7ePEiUlNT0b59e2hoaMDQ0BDe3t7Iysr6outev3493zGqqqowMTEpsO+MjAykpKTk2z613gEREZGyKxMFgZJasIiIiIi+TnJyMgBAV1c3T7uOjg4AFLi434sXL/Do0SPcuHEDY8aMwZEjR/Ddd99hxYoVGD58+BddNzk5Od8xH44rqO8lS5ZAT08v3/bixYsvuW0iIiKlovRrCJTUgkVERET09XJzcz+5X0Ul/3cS2traiIiIQMOGDVGvXj0AgK2tLdTV1eHj4wMfH59CX/dTxxXU96xZszB16tR87W3btv1kf0RERMpM6QsCJbVgEREREX09PT09AEBqamqe9g/fzn/Y/1+ampro2rVrvvaePXvCx8cHly5dQrNmzQp1XT09vXzHfDjO2Ng4X7u6ujrU1dXztUskkvw3R0REVEYo9ZSBklqwiIiIiIrG1NQUqqqqSExMzNP+4d+NGzfOd84///yDDRs24PXr13na3717BwCoVq1aoa9rZmaW75icnBzcuXOnwL6JiIjKI6UuCJTUgkX/iwsNERERfRkNDQ3Y2NggPDw8z+tlWFgY9PT0YGVlle+cJ0+eYMyYMdi1a1ee9p07d0JXVxetWrUq9HUdHR1x4sQJPH/+XH5MREQE3rx5A0dHx+K+XSIiIqWk1FMGirJgUXZ2NpYtW4a6devi+PHjWLp0KR48eIBt27blO2fJkiXw9fXN1/7fRxkRERFRXj4+PujSpQsGDRoET09PREdHIyAgAP7+/tDS0kJKSgri4+NhamqKatWqoWPHjujcuTOmTZuGd+/ewcLCAgcOHMDq1avx008/QV9fv1DXBYCxY8fi559/RteuXTF//ny8fPkSXl5e6N69O9q3by/ib4WIiEiBCErs1KlTAgDh6NGjedqzsrIEAMKSJUvynfP27VshIiJCuHPnTp72H3/8UQAgxMfH5zsnPT1dSE5OzreZm5sX6/0QERGVNeHh4UKzZs2EihUrCiYmJkJgYKB8n1QqFQAIwcHB8rbk5GRh6tSpQr169QR1dXXBwsJC+O23377ouh9cuXJF6Ny5s6CpqSlUr15d+O6774SUlJQvyt+4ceMvOp6IiEiZKPWUgaIsWPRh9eIPevbsCQC4dOlSvnPU1dWhq6ubbyuPCw3t3bsX169fFzsGUamrV69enseUqqiooEqVKujduzcePHhQov1u2rSpxK5fEjZt2pTvb2xRyGSyT/69XbBgAezs7Eqk7/9Sxv8WiqBv3764fPkyMjIycPv2bUybNk2+z87ODoIgyB8pCLwf9bd8+XLcuXMH6enpuHbtGkaNGvVF1/2gadOmOHbsGN6+fYunT59iw4YN8lGERKS8cnJycP78eaxevRpnzpwROw6RUlPqgkBJLVhEBQsKCkLv3r0xbtw4saMQiWLlypV48uQJnjx5ggcPHmDnzp24evUqPDw8xI5G/9/gwYMRFxcndgwiIipG2dnZiIuLQ2BgIFxcXFC1alW0atUKkydPhp2dHWJiYsSOSKS0lLogUFILFlF+f/31F0aPHo1vvvkGMpkMt27dEjsSUanT09ODoaEhDA0NYWxsjK5du8LPzw9SqVS+pgmJS1NTk4VdIiIll5WVhdjYWCxduhQ9evRAlSpVYGVlhXnz5uHdu3eYNm0aIiMj8erVK7Rq1Qo9e/bEjRs3xI5NpJSUuiAAvF9YKDY2FoMGDcKhQ4cwd+5cBAQEYPbs2fIFi2JiYuSrDP93waLVq1fj2LFjmDJlClavXg1fX1/5gkX0f2QyGb799lsMGDAAJ0+ehI6ODofNEv1/H55brqqqCgCIj49Ht27doKOjAw0NDXTq1Ek+zUYmk6FevXpYt24djI2Noa2tjWHDhiEjI0N+vQ0bNqBOnTrQ1dXFjz/+mKev3NxcBAQEoH79+tDU1IS9vT2uXLki3y+RSLBr1y40btwYWlpacHV1xZ07d+Dg4AAtLS106tQJjx49+ui9bNiwASYmJqhUqRLs7OzyXLtevXoICgpCmzZtoKmpCUdHR9y7dw/9+/eHlpYWWrRogWvXruW53uzZs6GrqwtjY2P8/PPPhe4rJSUFrq6u0NHRQaNGjfJ94x8fH4+OHTtCS0sLDg4OePHihXzff6cMFOb3vW3bNpiamkJLSwtDhgyBq6srFixY8NHf0X8zenp6onr16qhYsSLMzc3x119/AQAWLVqE5s2b5zl++fLl6NSpEwDg9evXGDZsGHR1dVGzZk388MMP8lFqHzKPHTsWenp6WLp06WezEBEpu8zMTERHR2PJkiXo1q0bKleujHbt2sHPzw85OTnw9vbGqVOn8Pr1axw7dgxz585Fp06doK+vj71798LIyAhOTk54/Pix2LdCpHzEXsSgOJTUgkWfUx4WGjp//rygo6MjdOnSRUhPTxcEQRC+++47oXbt2kJ2drbI6YhKT926dfP8HREEQUhMTBQsLS0FJycnQRAEIScnR6hfv77w/fffC4mJicK5c+eEdu3aCS4uLoIgvP97pKamJjg4OAiXL18WDh8+LGhqagq//vqrIAiCcPjwYUFdXV3YvHmzcPXqVaFXr155/n7Nnz9fqF69urBnzx4hPj5e8PDwEGrWrCm8efNGEARBACCYm5sLMTExwt9//y2oqakJhoaGwp9//ilcuHBBMDU1FSZOnFjg/e3du1cwNDQU9u3bJ9y8eVPw8fERqlatKrx69Up+/0ZGRsLRo0eFs2fPCgYGBkLlypWFdevWCVevXhWsra2FXr16CYIgCMHBwQIAoWfPnsLVq1eFTZs2CRUrVhSkUmmh+nJ1dRVatGghnDt3Tjh8+LBQo0YN4cPLVXp6ulCvXj1h2LBhwvXr14W1a9cKFSpUEGxtbeV9161bt1C/75MnTwoVK1YU1q9fL1y/fl0YNWqUIJFIhPnz53/2fwPDhw8X2rdvL1y4cEG4efOmMGrUKKFq1apCRkaGkJiYKAAQEhIS5OdaWVkJa9asEQRBEPr16ye4uLgIly9fFmJjY4W2bdsKnp6e8swAhOHDhwv//POPcO/evQKzUOkpD6/1RKUtPT1dOHnypLBw4UKhS5cugpaWlgBAqFSpkuDk5CT4+/sLp0+fFjIzMwt1vfv37wu1atUSvvnmG+H169clnJ6obCkTBQGxlPU3CTdv3hSqV68utGnTRkhNTZW3x8TECACEI0eOiJiOypK0tDTh3Llzpb6lpaUVOmPdunUFdXV1QVtbW9DW1hbU1dUFHR0dYejQocKLFy8EQRCEN2/eCMuWLZN/QBcEQVi/fr1Qv359QRD+78Pe1atX5fv79u0rjB49WhAEQRgwYID8g6EgCMKLFy8EDQ0NITg4WMjNzRWqVKkibNiwQb4/MzNTqF27trB+/XpBEN4XBP6738rKShg2bJj8315eXoKjo2OB99exY0dh9erVedosLS3lbXXr1hVmzZol3zdo0CChU6dO8n//8ssvQqNGjQRBeP+hXENDQ/57EYT3H6AHDx782b5ev34tqKqqCpGRkfJ9a9eulRcE9u/fL+jo6OT5HQ8cOPCjBYFP/b5dXV3z/H6ysrKE2rVrF6ogEBwcLFy5ckW+78aNGwIA4f79+4IgvP/d//jjj4IgCMLdu3eFChUqCE+fPhUSExMFFRWVPG9YL1++LG/7kPn69esFZqDSV9Zf64lKw7t37wSZTCb4+voK9vb2goaGhgBA0NXVFXr27CksW7ZMOHPmjJCVlfXVfVy9elXQ19cX7O3t5V9iEdHnVSj9MQmkDB4/fgxHR0dUqVIFBw8eRKVKleT7rKysYGFhgaCgIDg6OoqYksqKGzduiLJ+x7lz52BpaVno4/38/NCvXz+kpqZiwYIFuHv3LpYsWYKqVasCALS1tTF27Fhs3rwZZ8+exY0bN3D+/HnUqFEjz3UaNmwo/1lXVxdZWVkA3g+FHzNmjHxf1apVUb9+fQDAs2fP8OrVK7Rt21a+X01NDa1bt87z5I8PxwPv59P/d8V9TU3NPMPl/+v69evw8vLCrFmz5G3p6em4efPmV127fv368t8LAFhaWmLjxo2f7evmzZvIyclBixYt5PvatGkj/zk+Ph4NGzaEtrZ2nv0HDhwo8L6Aj/++L1++jO+//16+r0KFCmjduvVHr/Nf7u7u+Ouvv/Drr7/ixo0bOHfuHID3K18DgKurKzZt2oQ5c+bgzz//hJ2dHapXr44zZ84gNzcXxsbGea6Xm5ubZ4HcknpSAhFRaXj37h1Onz6NEydO4MSJE4iJiUFGRgb09fVhY2ODRYsWwdbWFi1atJBPuSuqJk2aYN++fejSpQvc3d2xY8cOqKgo/exoohLHggDlk5SUhG7duiEnJwcREREwMDDIs18ikcDT0xOzZ8/Gq1evUKVKFZGSUllhbm4u/0BV2v1+ierVq6NBgwYAgF27dqFNmzbo3bs3YmJioKamhjdv3qBNmzYwMDBAr1694Orqihs3biAwMDDPdSpWrJjn38J/FkX978//PVZDQ6PATDk5OfIPocD7D7X/Vdg3Q9nZ2Vi5ciU6d+6cp11XV/errv2/b/Byc3Pl9/Kpvu7duwcg7+/hU7+vgvb/r4+dX6FChXzX+t9/f4y7uzuio6MxbNgwjB07FkZGRrC2tpbvHzx4MKZNm4bExESEhobiu+++A/D+3vX09HD27Nl81zQ2NkZsbCyAj//3JiJSRGlpaTh9+jRkMhlOnDiBM2fOIDMzE1WqVIGNjQ2WLl0KW1tbNGvWrNgKAAXp2LEjduzYgQEDBsDQ0BArV64sl48JJ/oSLAhQHm/fvoWzszOePHmCqKgo1K5du8Djhg4dCm9vb2zfvh0TJkwo5ZRU1mhpaX3RN/WKoGLFiti4cSPatWuHFStWwMvLCzKZDI8fP8aVK1fkH54jIiIK/SGzadOmeRbQS01NlX9rrKenhxo1aiAmJgbffPMNgPerMJ87dw5du3Yt8v2YmZnh4cOH8oIHAIwYMQJ9+/ZFr169vvh6t27dwtu3b6GlpQUAOHPmjLwA86m+7OzsoKamhri4OHnB4MKFC/LjmjZtips3byI5ORl6enr59n+JJk2a5ClE5eTk4OLFi/Lf78ekpKRg+/btiI2NlY9eOHjwIID/KygYGRnBzs4OQUFBuHTpEvr16ye/9+TkZEgkEpiamgIArly5gnnz5iE4OPir7oOIqLS9efMGp06dko8AOHPmDLKzs2FgYABbW1sEBgbCzs4OTZo0KfVv6fv27Yu1a9di7NixMDY2hpeXV6n2T6RsWBAguaysLAwYMACXLl3C33///clvT2vUqAFnZ2cEBQWxIEDlVps2bTBy5EgsXLgQQ4cORdWqVfHmzRv89ddfaN26NY4dO4Y1a9bk+Zb9UyZMmIAuXbrAxsYGnTp1gq+vL96+fSvfP3XqVMybNw81a9ZEgwYNsHTpUqSnp2Pw4MFFvpepU6di1KhRaNSoEdq3b49ff/0Vf/75J2bPnv1V10tPT4eHhwcWLFiAqKgo7Nq1C6dPn/5sX7q6unB3d8cPP/yA4OBgvHv3Ls+q/126dEGdOnXkv/fY2Fjs3Lkzz1SKwpowYQLs7OxgY2ODjh07Ys2aNbh79+5nv03S0NCAtrY2wsLCUK1aNSQkJMj/Dv532oSrqyt++OEHdO3aFZUrVwYANG7cGE5OTnBzc8PPP/8MVVVVjB49GlWqVOFTbohIYaWkpODUqVPyEQBnz55FTk4OqlevDjs7O7i5ucHW1hYWFhYK8Y38mDFj8PjxY8ycOROGhoZwd3cXOxKRwmJBgAC8H847YsQIHDt2DAcPHoSVldVnz/H09ESvXr1w4cIFtGzZshRSEimexYsXIzQ0FF5eXti6dSvmzZuHcePGIT09Hc2bN8fatWsxcuTITz7u74NOnTohODgYPj4+mDJlCkaOHJlnLv20adOQkpKC0aNHIyUlBe3bt4dMJkO1atWKfB+DBw/G06dPMXfuXDx9+lQ+F/O/8++/RIsWLWBsbIy2bdvCwMAAwcHB8nUiPtfXzz//nOeD9MSJEzF9+nQA79dNOHDgAEaNGgVLS0s0b94c48ePL3AI/udYW1tj7dq18PX1xYsXLzBw4EBYW1sXagrC1q1b5Y+vNTExgY+PD3x8fHDhwgV5MbV///4YO3Ysvv322zznb9myBT/88AM6d+6MChUqwMnJKd9jGYmIxPT69WtERUXhxIkTkMlkOH/+PHJzc2FkZARbW1uMGDECtra2MDMzU4gCQEF8fX3x+PFjjBw5EtWrV4eTk5PYkYgUkkQo7FhWysfCwgLx8fFixygyQRAwZcoUrF69Gjt37sTAgQMLdV52djZq166NgQMHYvXq1SWckoioeJ05cwZ6enowMzOTtzVp0gQzZszA8OHDi3z9f/75By1atMDTp0/zLMxKyqWsvNYTFVZISAg8PT3lC6Da2dnB1tYWdnZ2aNCggcIWAAqSnZ2Nvn37QiqVQiqV5lmkloje49KbhMWLF2PVqlX45ZdfCl0MAN4vyOXu7o6tW7ciPT29BBMSERW/06dPo2fPnoiOjsadO3ewePFiPHjwoMjfIqWmpiI0NBTjxo2Dq6sriwFEpDRSU1MxY8YM9OnTB4mJiXjw4AG2bt2K0aNHo2HDhkpVDADev1fduXMnmjVrhp49e+Kff/4ROxKRwmFBoJzbsGEDfHx84Ofnl+dxZ4U1YsQIJCUlYe/evSWQjoio5IwfPx7Ozs7o168fLCwssG/fPhw6dAiGhoZFvvaoUaPw6tUrLFq0qBiSEhGVjuXLlyMlJQUrV66Eqamp0hUACqKlpYX9+/ejSpUq6NatG54+fSp2JCKFwikDRaDswwhDQ0MxaNAgTJgwAatWrfrqP/odOnSAjo4ODh8+XMwJiYiIxKXsr/VEhfX06VOYmppi3LhxWLZsmdhxit29e/dgbW0NIyMjyGQy6OjoiB2JSCFwhEA5dfz4cbi5ucHV1bXIz2j19PREREQEHjx4UIwJiYiIiKi0LFy4EGpqavD29hY7SomoW7cuDh8+jMTERPTv3x+ZmZliRyJSCCwIlENnz55Fnz594ODggODg4CI/H3bQoEHQ1NRESEhIMSUkIiIiotKSmJiIDRs2wNvbG1WqVBE7Tolp3rw59uzZgxMnTsgXTiQq71gQKGdu3LiB7t27o1mzZggNDf3s47UKQ0dHB4MGDUJwcDD/sBIREREpGR8fH9SoUQMTJ04UO0qJs7Ozw5YtW7B9+3bMnDlT7DhEomNBoBx5+PAhHB0dUaNGDezfvx/a2trFdm1PT0/cvn0bkZGRxXZNIiIiIipZ586dw86dO+Hr6wtNTU2x45SKQYMGYdWqVQgMDMRPP/0kdhwiUVUQOwCVjpcvX8LR0REqKio4cuRIsQ8H69ixIxo0aICgoCDY2dkV67WJiIiIqGR4e3ujcePG8PDwEDtKqfrhhx/w+PFjTJs2DUZGRnB1dRU7EpEoOEKgHHjz5g169uyJFy9eICIiAsbGxsXeh0QigaenJ0JDQ5GcnFzs1yciIiKi4nX06FEcO3YMS5YsQYUK5e97wsWLF8Pd3R0eHh44duyY2HGIRMGCQBmXmZmJ/v37Iz4+HocOHUKjRo1KrC93d3dkZGRg586dJdYHERERERVdbm4uZs6cifbt26NXr15ixxGFRCLBxo0b0blzZ/Tt2xcXLlwQOxJRqWNBoAzLycmBu7s7ZDIZ9uzZg1atWpVof8bGxnByckJQUFCJ9kNERERERbNz505cuHABS5cuLdLjp5Wdmpoadu3ahcaNG6N79+64ffu22JGIShULAmWUIAiYOHEidu3ahR07dsDe3r5U+vX09ERsbCyuXbtWKv0RERER0ZfJzMzEnDlz0KtXL3Ts2FHsOKKrVKkSDhw4AB0dHXTr1g3Pnj0TOxJRqWFBoIzy9fXFL7/8gg0bNqBfv36l1q+LiwsMDAwQHBxcan0SERERUeFt2LAB9+7dw+LFi8WOojCqVauGI0eOIDU1Fc7Oznjz5o3YkYhKBQsCZdCaNWvg6+uLJUuWYNSoUaXad8WKFTF06FBs3rwZWVlZpdo3EREREX1aSkoK/Pz8MHz4cDRp0kTsOAqlfv36OHToEG7cuIFBgwbxvSyVCywIlDE7duzAxIkTMXXqVMycOVOUDJ6ennj+/DkOHDggSv9EREREVLDly5fjzZs3WLBggdhRFFLLli0RHh6OY8eOYfTo0RAEQexIRCWKBYEy5MiRI3B3d8ewYcMQEBAg2gIxzZo1Q+vWrbm4IBEREZEC+ffff7F8+XJMnDgRtWvXFjuOwurSpQs2bdqEkJAQzJkzR+w4RCWq/D1wtIyKiYlBv3794OTkhI0bN0JFRdxaj6enJ3744Qc8efIERkZGomYhIiIiImDhwoVQU1ODt7e32FEU3pAhQ/Dvv/9i2rRpMDIywg8//CB2JKISwRECZUB8fDx69uwJS0tL/Pnnn1BTUxM7ElxdXaGmpoYtW7aIHYWIiIio3Pvnn3/w66+/Yvbs2ahcubLYcZTC1KlTMW3aNEyaNAm7du0SOw5RiWBBQMndu3cPjo6OqFWrFvbt2wdNTU2xIwEA9PX10a9fPwQFBXHuFREREZHIfHx8YGhoiAkTJogdRaksW7YMrq6uGDp0KGQymdhxiIodCwJK7Pnz53B0dIS6ujoOHz4MfX19sSPl4enpiYSEBJw+fVrsKERERETlVlxcHP7880/4+voqzJdHykJFRQXBwcGwsbFB7969cfnyZbEjERUrFgSUVGpqKnr06IHk5GREREQo5Dx9e3t71K1bl4sLEhEREYlEEATMnDkTFhYWcHd3FzuOUqpYsSLCw8PRoEEDODk54d69e2JHIio2LAgooYyMDPTp0wc3b97E4cOHYWpqKnakAqmoqGDEiBHYuXMn3rx5I3YcIiIionInIiICUqkUS5YsQYUKXE/8a+no6ODgwYPQ1NREt27d8PLlS7EjERULFgSUTE5ODtzc3BAdHY19+/ahRYsWYkf6pOHDhyMtLQ2hoaFiRyEiIiIqV3JzczFz5kx06NABLi4uYsdRejVq1MDhw4fx6tUrODs74+3bt2JHIioyFgSUiCAIGDt2LP766y/s3LkTNjY2Ykf6rLp166Jz586cNkBEVE5FRESgTZs20NLSgomJCQIDAwu92Gx2djasrKxgZ2eXb9+mTZvQtGlTaGhooH79+vDz80N2dnaeY3x8fCCRSPJtgYGBxXFrRArvjz/+wKVLl7B06VJIJBKx45QJDRs2xIEDB3DlyhV8++23+f7uECkbFgSUiI+PD3777Tds3LgRvXr1EjtOoXl6euLkyZO4efOm2FGIiKgUxcTEwNnZGebm5ggPD4ebmxu8vLywdOnSQp3v7++PuLi4fO2rVq3CiBEj0LhxY+zevRsLFixAUFAQBg8enOe4ixcvws7ODqdPn86zubm5Fcv9ESmyjIwMzJkzB71790aHDh3EjlOmtGnTBqGhoTh06BDGjh3LJ2qRUpMI/F/wV7OwsEB8fHyp9LVy5UpMmTIFAQEBmD59eqn0WVzevXuHmjVrYuzYsVi8eLHYcYiIqJR069YNr1+/RmxsrLxt5syZWLduHZ4+ffrJ1c4vXboEa2tr6OnpwczMTP64r5ycHFSvXh2tWrVCRESE/PirV6+iWbNmiIiIQNeuXQEAtWrVwogRI7Bw4cKvvofSfK0nKk6rV6/GlClTcOXKFVhYWIgdp0zavHkzPDw8MG/ePPj6+oodh+ircISAEtiyZQumTJmCmTNnKl0xAAA0NTUxZMgQhISEcFgVEVE5kZGRAZlMhr59++ZpHzBgAFJTUxEVFfXRczMzM+Hu7o6JEyfCzMwsz76nT5/K5+/+V9OmTWFgYIADBw4AAF68eIFHjx4p/Fo7RCUhJSUFCxcuxIgRI1gMKEHu7u7w9/eHn58f1q9fL3Ycoq/CgoCCO3DgAEaMGIGRI0diyZIlYsf5ap6ennj8+HGeb3OIiKjsun37NjIzM9GoUaM87Q0aNAAAJCQkfPRcPz8/ZGVlFfiNm76+PipUqJDvsV9JSUlISkrC7du3AbyfLgAA+/fvR926daGmpoaWLVvi0KFDBfaZkZGBlJSUfBsHUpIyCgwMxJs3b7BgwQKxo5R5Xl5emDhxIsaPH4/du3eLHYfoi7EgoMBOnTqFgQMHwsXFBevXr1fqxWAsLS3RvHlzLi5IRFROJCcnAwB0dXXztOvo6AB4/w1mQeLi4hAYGIhNmzZBXV09334tLS0MHjwYa9asQVBQEJKSkpCQkABXV1dUqFABaWlpAP6vIPDvv/9i48aN2L17N6pXrw5nZ2ccOXIk33WXLFkCPT29fNuLFy+++ndAJIZ///0Xy5cvx6RJk1CrVi2x45R5EokEK1aswIABA+Dq6vrJ0U9EiogFAQV15coVODs7o23bttixY4fSPzdWIpHA09MTe/fuxfPnz8WOQ0REJSw3N/eT+1VU8r8FSU9Ph4eHByZPngwrK6uPnrt+/XoMHToUo0aNQpUqVdCyZUu0b98erVq1gpaWFgBg0KBB2LdvH/bv34+uXbvC2dkZ+/fvh5mZGebNm5fvmrNmzUJycnK+zcDA4AvvnEhcfn5+UFdXx8yZM8WOUm6oqKhg8+bNsLa2houLC65duyZ2JKJCY0FAAd25cwfdunWDiYkJ9uzZAw0NDbEjFYsPqzpv27ZN5CRERFTS9PT0AACpqal52j+MDPiw/798fHyQm5uLuXPnIjs7G9nZ2RAEAYIgyH8GgEqVKuH3339HSkoKrl69imfPnmHevHl48OABqlSpAgCoU6cOnJ2doaqqKr++mpoaHB0dcenSpXx9q6urQ1dXN9+mzKPzqPy5efMmfv31V8yePRuVK1cWO065oq6ujr/++gt16tSBk5MTHjx4IHYkokJhQUDBPH36FF27doW2tjYOHTqUb6ilMjMwMEDv3r0RFBTEOZlERGWcqakpVFVVkZiYmKf9w78bN26c75zQ0FAkJCSgUqVKUFNTg5qaGiIjIxEZGQk1NTWEhIQAeL8uwKlTp1CpUiU0adIElSpVwrNnz/Dw4UNYWloCAA4ePIiwsLB8fbx79w7VqlUr7tslUgg+Pj6oWbMmJkyYIHaUcklPTw+HDh2CqqoqnJyckJSUJHYkos9iQUCBJCcnw8nJCW/fvsXRo0dRo0YNsSMVO09PT1y5cgXnzp0TOwoREZUgDQ0N2NjYIDw8PE8ROCwsDHp6egVOCdi3bx/i4uLybJaWlrC0tERcXBxcXFwAvJ8y8L9P3Vm5ciVUVVXlTx8IDQ3FiBEj8OrVK/kxaWlpOHDgAOzt7UvilolEdebMGezatQt+fn5lZnSpMqpZsyaOHDmCp0+folevXnj37p3YkYg+SSLwq9qvVpzPJk5PT4eTkxMuXbqEkydPomnTpsVyXUWTk5ODunXrolevXvjll1/EjkNERCXo77//RpcuXdC/f394enoiOjoaixYtgr+/P7y8vJCSkoL4+HiYmpp+9Ft7Ozs7AIBMJpO3RUREoFu3bpg8eTJ69eqF48ePY9GiRZg5cyb8/f0BANevX0ebNm3QpEkTzJ49Gzk5OVi6dClu3ryJ8+fPw8TEpFD3UJyv9UQlRRAEODg44Pnz57h06VKeqTIkjpiYGDg4OMDJyQm7du3ifxNSWBwhoACys7Px7bff4syZMzhw4ECZLQYAgKqqKjw8PLB9+3ZWTImIyjgHBweEhYUhISEBffr0wbZt2xAQEAAvLy8AwPnz52FtbY0DBw580XUdHR2xfft2REREoGfPnggLC8Pq1avlxQDg/ZSEyMhIVK5cGZ6envDw8ICBgQFOnjxZ6GIAkbI4cuQIZDIZ/P39+cFTQbRr1w5//vkn9u7diwkTJnC6LCksjhAoguL61mDmzJn46aefsGfPHvTo0aMYkim2xMRENGzYENu2bcOQIUPEjkNERPRRHCFAii43NxctW7aEnp4eTpw4wYUwFczvv/+OUaNGYeHChfDx8RE7DlE+yv0suzJiwoQJsLa2LhfFAABo0KABbGxsEBQUxIIAERERURFs374dly9fRnR0NIsBCmjkyJF48uQJ5s6dCzU1NXh5efG/EykUFgQUQO3atVG7dm2xY5QqT09PDB8+HHfv3kW9evXEjkNERESkdDIyMuDj44M+ffrA2tpa7Dj0EXPmzEFWVha8vb1x+/ZtrF27FhUq8GMYKQauIUCiGDBgACpVqoRNmzaJHYWIiIhIKa1fvx4PHjzA4sWLxY5CnyCRSODr64vg4GAEBQXB2dkZKSkpYsciAsCCAIlEW1sb3377LYKDg5Gbmyt2HCIiIiKlkpycjIULF8LT0xONGzcWOw4VwvDhw3H48GGcPn0anTp1wsOHD8WORMSCAInH09MT9+/fx99//y12FCIiIiKlEhgYiLS0NCxYsEDsKPQFOnfujOjoaLx+/Rpt27bFxYsXxY5E5RwLAiSadu3awdzcHEFBQWJHISIiIlIaT548wU8//YTJkyfD2NhY7Dj0hZo0aYKYmBgYGRmhU6dOOHTokNiRqBxjQYBEI5FI4OnpifDwcCQlJYkdh4iIiEgp+Pn5QV1dHTNnzhQ7Cn0lIyMjnDhxAvb29nBxccGGDRvEjkTlFAsCJKphw4YhOzsbO3bsEDsKERERkcK7efMmfvvtN8yZMwf6+vpix6Ei0NbWxu7duzFu3DiMGTMGM2fO5NpaVOpYECBRGRoaomfPnpw2QERERFQIc+bMQc2aNTF+/Hixo1AxUFVVxerVq7Fy5UoEBATg22+/xbt378SOReUICwIkOk9PT5w7dw6XL18WOwoRERGRwoqNjUVoaCgWLlwIDQ0NseNQMZo0aRLCw8Oxf/9+dO7cGc+fPxc7EpUTLAiQ6Hr06IHq1asjODhY7ChERERECkkQBMycORNNmzbF0KFDxY5DJaBPnz6QyWS4desWrK2tcfPmTbEjUTnAggCJTk1NDe7u7tiyZQsyMzPFjkNERESkcA4fPowTJ07A398fqqqqYsehEmJlZYWYmBhUrFgR1tbWiIqKEjsSlXEsCJBCGDFiBF6+fIl9+/aJHYWIiIhIoeTk5GDmzJmwsbFBjx49xI5DJczExASnTp1C8+bN0blzZ/zxxx9iR6IyrEwUBCIiItCmTRtoaWnBxMQEgYGBEAShUOdmZ2fDysoKdnZ2JRuSPsnCwgLt2rXj4oJERERE/2P79u24cuUKli5dColEInYcKgWVK1fGkSNHMHjwYLi6umLJkiWF/nxD9CWUviAQExMDZ2dnmJubIzw8HG5ubvDy8sLSpUsLdb6/vz/i4uJKOCUVhqenJw4fPoxHjx6JHYWIiIhIIaSnp8PHxwf9+vVDu3btxI5DpahixYoICQnBggULMHv2bIwePRpZWVlix6IyRiIoeampW7dueP36NWJjY+VtM2fOxLp16/D06VNoamp+9NxLly7B2toaenp6MDMzg0wm+6K+LSwsEB8f/7XR6X+kpKTA0NAQc+fOxaxZs8SOQ0RExNd6Et2KFSswY8YMXLt2DWZmZmLHIZGEhIRg9OjRsLOzQ2hoKHR1dcWORGWEUo8QyMjIgEwmQ9++ffO0DxgwAKmpqZ9chCMzMxPu7u6YOHEi/7gqCF1dXQwcOBBBQUEcEkVERETlXnJyMn788UeMHDmS71fLOQ8PDxw+fBhnzpxBx44d8eDBA7EjURmh1AWB27dvIzMzE40aNcrT3qBBAwBAQkLCR8/18/NDVlYWfH19P9tPRkYGUlJS8m380Fr8PD09kZiYyBVViYiIqNwLCAjAu3fvMH/+fLGjkAJwcHBAdHQ0UlJS0LZtW1y4cEHsSFQGKHVBIDk5GQDyDZnR0dEB8H4IekHi4uIQGBiITZs2QV1d/bP9LFmyBHp6evm2Fy9eFPEO6H/Z2NjA1NSUiwsSERFRufbkyRP89NNPmDx5MmrWrCl2HFIQFhYWiImJQa1atdCpUyccPHhQ7Eik5JS6IJCbm/vJ/Soq+W8vPT0dHh4emDx5MqysrArVz6xZs5CcnJxvMzAw+Krc9HESiQQjRozAn3/+idTUVLHjEBEREYnC19cXmpqa8PLyEjsKKRhDQ0PIZDJ06dIFLi4uWLdundiRSIkpdUFAT08PAPJ9cPwwMuDD/v/y8fFBbm4u5s6di+zsbGRnZ0MQBAiCIP/5f6mrq0NXVzffxse+lAwPDw+8e/cOf/75p9hRiIiIiEpdQkICNm7ciDlz5kBfX1/sOKSAtLS0EBYWhokTJ2LcuHGYMWPGZ78sJSpIBbEDFIWpqSlUVVWRmJiYp/3Dvxs3bpzvnNDQUNy7dw+VKlXKt09NTQ3BwcEYPnx4ieSlwqlVqxa6deuGoKAgjBw5Uuw4RERERKVqzpw5MDY2xrhx48SOQgpMVVUVK1asgImJCSZPnow7d+5gy5Ytn3zKWlmQkZGB/fv3Y/PmzXj48CHq1auHunXrol69enl+LujLYcpPqQsCGhoasLGxQXh4OKZPny7/xj4sLAx6enoFTgnYt28fMjIy8rR9//33AIANGzbAxMSk5IPTZ3l6emLQoEG4ceMGzM3NxY5DREREVCpiYmIQFhaGkJAQaGhoiB2HlMDEiRNRr149uLq6wsHBAXv27EH16tXFjlWsBEFAXFwcQkJCsGPHDiQlJcHKygqWlpa4f/8+Dhw4gHv37uX5nKevr19goeDDpq+vzxHfACSCki+V//fff6NLly7o378/PD09ER0djUWLFsHf3x9eXl5ISUlBfHw8TE1NUa1atQKvYWdnBwCQyWRf1DefTVxyMjIyULNmTYwaNQpLly4VOw4REZVTfK2n0iQIAuzs7JCUlIQLFy5AVVVV7EikRM6ePQtnZ2doa2vj4MGDZeJRlQ8fPsTWrVsREhKCGzduwNjYGMOGDYO7u3u+0eC5ubl49uwZ7t69i7t37+LevXv5fn737p38eB0dnY+OLqhXrx6qVq1aLgoGSl8QAIDdu3dj/vz5SEhIgLGxMcaPH49p06YBeP8h397e/pNTAVgQUEyTJk3Czp078eDBA6ipqYkdh4iIyiG+1lNpOnjwIHr27IkDBw6gR48eYschJXTv3j306NEDT548wV9//QUbGxuxI32xt2/fYvfu3QgJCcGxY8egoaGBfv36wcPDAw4ODl9dKBMEAc+fPy+wUPBhS0tLkx+vpaVVYKHgw8/Vq1cvEwWDMlEQEAvfJJSsS5cuoUWLFti7dy9cXFzEjkNEROUQX+uptOTk5KBly5aoUqUKpFJpmfigQeJ4/fo1+vfvj6ioKAQHB2PIkCFiR/qs3NxcREVFISQkBLt27UJqaio6deqE4cOHY8CAAfkeM18SBEHAq1evPjq64O7du3kea6+hofHR0QV169aFoaFhgU+9UzQsCBQB3ySUvFatWqFOnTrYvXu32FGIiJTa5s2bv/pcd3f3YkyiXPhaT6Vl8+bN8PDwQExMDNq2bSt2HFJymZmZ+P7777Fp0yYsXLgQc+bMUcgi0+3bt7F582Zs3rwZd+7cgYmJCdzd3eHu7o769euLHS+f169f5xlR8L+Fg6SkJPmxFStWRN26deWFAjc3N/nIdEXCgkAR8E1CyVu7di0mT56Mhw8fokaNGmLHISJSWioqKpBIJAU+XvdTJBIJcnJySiiV4uNrPZWG9PR0mJmZoU2bNggNDRU7DpURgiDgxx9/xLx58+Dp6Yn169crxDTclJQU7Nq1CyEhITh58iR0dHQwcOBAeHh4oGPHjkrxrfrHJCcn4969ewWOMJgyZQrc3NzEjpiPUj9lgMo+V1dXTJs2DVu3bpWvC0FERF8nPDwcLVq0KPTx58+fx4ABA0ouEBEBAH755Rc8evQIERERYkehMkQikWDu3LkwMTGBp6cn7t+/j9DQUFEex5eTk4Pjx48jJCQEu3fvRnp6Orp06YKtW7eib9++0NLSKvVMJUFPTw/NmzdH8+bNxY5SaCwIkEKrUqUK+vbti6CgIEydOlUhhzoRESkDY2Nj+bzGwkpKSkLNmjVLMBURvX79GosWLcKoUaPKxKrwpHiGDh2K2rVro0+fPujQoQMOHjyIOnXqlErf169fR0hICLZu3YpHjx7B3Nwc8+bNw9ChQ1GrVq1SyUCfprzjMajc8PT0RHx8PM6cOSN2FCIipbVw4UI0atToi85p0aIFHjx4UEKJiAgAli1bhvT0dMyfP1/sKFSG2draIjo6Gm/fvkXbtm1x7ty5Euvr5cuXWLt2LaysrGBhYYFff/0VvXv3RmxsLOLj4+Ht7c1igAJhQYAUnoODA+rUqYOgoCCxoxARKS1PT08YGRlhzJgxiIuLEzsOEQF49OgRVq5ciSlTpsDIyEjsOFTGNW7cGDExMahTpw5sbGywf//+Yrt2VlYW9u7di/79+8PIyAiTJk2CoaEhQkND8eTJE3mBgKN9FQ8LAqTwVFVVMXz4cOzYsQNv374VOw4RkVKKi4uDu7s7wsPD0a5dOzRv3hyrV6/Gq1evxI5GVG75+vpCS0sLM2bMEDsKlRPVq1eHVCpFt27d0Lt3b6xdu7ZI17t48SImT54MY2Nj9O7dG7dv38ayZcvw+PFjeYFAXV29mNJTSWBBgJTC8OHDkZqairCwMLGjEBEppVatWmH16tV4/PgxwsLC0KBBA3h5ecHY2Bjffvstjh07ViL9RkREoE2bNtDS0oKJiQkCAwML/aSD7OxsWFlZFfiYpk2bNqFp06bQ0NBA/fr14efnh+zs7DzHvHnzBuPHj4ehoSEqVaqEHj16ICEhoThui6jIbty4gaCgIMyZM0eURd6o/NLS0sKuXbswefJkTJgwAVOnTv2ip8n8+++/WL58Ob755hu0bNkSf/zxB4YNG4ZLly7hwoULmDx5MqpXr16Cd0DFiQUBUgomJiawt7fntAEioiKqUKEC+vTpg/DwcDx+/BgBAQG4c+cOHB0dYWJiAj8/v2JbNyAmJgbOzs4wNzdHeHg43Nzc4OXlhaVLlxbqfH9//wKnN6xatQojRoxA48aNsXv3bixYsABBQUEYPHhwnuOGDBmCXbt2wd/fH5s3b8ajR49gb2+f5znRRGKZM2cOatWqhXHjxokdhcohVVVVLF++HGvWrMGqVaswcODAT47ETU9Px59//omePXuiVq1amD17NszMzLB//348fPgQy5cvV6qV9ek/BPpqjRs3FjtCubJlyxYBgJCYmCh2FCKiMufGjRuCn5+fYGpqKlSoUKFYruno6ChYWVnlafPy8hJ0dHSEt2/ffvLcixcvCpqamoKhoaFga2srb8/OzhaqVKkidO3aNc/xV65cEQAIERERgiAIQnR0tABAOHjwoPyYZ8+eCdra2sKPP/5Y6Hvgaz2VhNOnTwsAhM2bN4sdhUjYt2+foKWlJVhZWQn//vuvvD03N1c4ffq0MGbMGEFfX18AILRt21b45ZdfhJcvX4qYmIoTRwiQ0ujXrx90dXWxadMmsaMQEZUpL168wPHjxyGVSnHv3j3Url27yNfMyMiATCZD375987QPGDAAqampiIqK+ui5mZmZcHd3x8SJE/M9hu3p06d49eoVnJ2d87Q3bdoUBgYGOHDgAADgyJEj0NbWhqOjo/yYatWqwdbWFgcPHizq7RF9NUEQ4OXlhebNm2PIkCFixyGCs7MzIiMjcf/+fbRr1w5SqRSLFy+Gubk5rK2tsX//fowdOxY3btxATEwMxo4diypVqogdm4oJCwKkNLS0tODq6opNmzZ90TwnIiLK7+3bt9i+fTt69uwJY2NjTJ8+HUZGRjh8+DBu375d5Ovfvn0bmZmZ+R512KBBAwD45Fx+Pz8/ZGVlwdfXN98+fX19VKhQAffu3cvTnpSUhKSkJHn269evo379+lBVVc3Xf0F9Z2RkICUlJd8mFHK9A6LCOnjwIE6ePAl/f/98//skEkurVq0QGxsLbW1tODg4YNGiRbCyssLRo0dx9+5dLF68OF+BlsqGCmIHIPoSnp6e2LBhA44dO4Zu3bqJHYeISKnk5ubiyJEj2LZtG/bs2YO0tDRYWlpixYoVcHNzK9aFzZKTkwEAurq6edp1dHQAACkpKQWeFxcXh8DAQERGRha4MrWWlhYGDx6MNWvWoEmTJujbty+ePXuGSZMmoUKFCkhLS5P3/799f+i/oL6XLFlSYAHCwMDgM3dKVHg5OTnw9vaGnZ0dnJycxI5DlEedOnUQHR2NU6dOoWPHjvK/11S2sSBASqVNmzZo0qQJgoKCWBAgIvoCP/zwA/7880+8ePEClStXhqenJ0aOHFlii0Dl5uZ+cr+KSv5Biunp6fDw8MDkyZNhZWX10XPXr18PdXV1jBo1CiNHjoSmpia8vb2RmpoKLS2tz/ZfUN+zZs3C1KlT87W3bdv2k/dB9CW2bt2Kq1evIjY2ls9jJ4Wkq6uL7t27ix2DShGnDJBSkUgk8PT0xF9//YWXL1+KHYeISGmsW7dO/niox48fY9WqVQUWAyIjI4tlXvOH0Qapqal52j98O1/QaAQfHx/k5uZi7ty5yM7ORnZ2NgRBgCAI8p8BoFKlSvj999+RkpKCq1ev4tmzZ5g3bx4ePHggn9eqp6eXr+8P/RfUt7q6OnR1dfNt/NBGxSU9PR1z587FgAEDPlnwIiIqTSwIkNIZOnQocnNzsX37drGjEBEpjbt37+Lw4cMYOHAgKlasmGdfcnIyVq1ahSZNmsDOzg5//vlnkfszNTWFqqoqEhMT87R/+Hfjxo3znRMaGoqEhARUqlQJampqUFNTQ2RkJCIjI6GmpoaQkBAAwP79+3Hq1ClUqlQJTZo0QaVKlfDs2TM8fPgQlpaWAAAzMzPcuXMn30iBxMTEAvsmKmlr167F48ePsWjRIrGjEBHJsSBASqd69epwcXFBUFCQ2FGIiJRGrVq18rXFxMRgxIgRqFmzJqZMmYLs7Gz4+fnh1q1bRe5PQ0MDNjY2CA8Pz7MwX1hYGPT09Ar8hnTfvn2Ii4vLs1laWsLS0hJxcXFwcXEB8H7KwPTp0/Ocu3LlSqiqqsqfPuDo6IjU1FQcOXJEfszz588RGRmZ58kDRCUtNTUVwcHBWLRoEUaPHp1voU0iIjFxDQFSSp6ennBxccGFCxfQsmVLseMQESmNN2/eYOvWrdiwYQMuX74MLS0tpKenIzg4GB4eHsXal4+PD7p06YJBgwbB09MT0dHRCAgIgL+/P7S0tJCSkoL4+HiYmpqiWrVqaNasWb5rfFjUqnXr1vK2iRMnolu3bpgyZQp69eqF48ePY8mSJZg5cyZMTU0BADY2NrCzs4ObmxuWLVuGqlWrYsGCBdDX18fYsWOL9T6J/ldOTg6kUilCQkIQHh6Od+/eoWvXrgUuXElEJCaOECCl5OTkBENDQ44SICIqpAsXLuD7779HzZo1MX78eBgYGGDLli24efMmBEGAiYlJsffp4OCAsLAwJCQkoE+fPti2bRsCAgLg5eUFADh//jysra1x4MCBL7quo6Mjtm/fjoiICPTs2RNhYWFYvXo1/P398xwXHh6O3r17Y8aMGRg+fDiMjY1x/PhxVK5cudjukei/EhISMHv2bNSrVw9du3bFmTNnMGfOHNy9exdHjhxB9erVxY5IRJSHROADdr+ahYUF4uPjxY5Rbnl7e+PXX3/F48ePoaGhIXYcIiKFpqKigsaNG8PDwwOurq6oXbs2gPfrB1SuXBkymQw2NjYip1Q8fK2nz0lKSsIff/yBkJAQxMbGQl9fH99++y08PDzQtm1bLkxJRAqNIwRIaY0YMQJJSUnYs2eP2FGIiBRerVq1kJiYiCNHjiAsLAzPnz8XOxKR0srKysL+/fsxcOBAGBoa4ocffoCBgQH+/PNPPHnyBOvWrUO7du1YDCAihceCACktMzMzdOjQgdMGiIgK4d69e9i3bx+qV6+OWbNmwdjYGH369MGePXv4oYWokC5duoSpU6eiVq1acHFxwc2bN7FkyRI8fPhQXiDgqEUiUiZcVJCUmqenJ0aNGoX79++jTp06YschIlJYEokEjo6OcHR0xOvXr7F161Zs2rQJw4cPBwD8/PPPyM7Ohr29PQsERP/x7NkzbNu2DSEhIbh06RKqVasGNzc3eHh4oEWLFmLHIyIqEo4QIKU2cOBAaGlpyZ9NTUREn6evr48JEybg7NmzuHjxIn744QfIZDJ07doVNWvWxKRJk8SOSCSqjIwMhIaGwsXFBTVr1oS3tzcaNGiAvXv34tGjR1ixYgWLAURUJnBRwSLgQkOKwdPTEzKZDImJiVBRYY2LiOhrZGVlYc+ePQgKCsKxY8eQmZkpdiSFwNf68kMQBMTFxWHTpk34448/kJSUBCsrK3h4eODbb79FlSpVxI5IRFTs+OmJlJ6npyfu3LmDEydOiB2FiEhhzZs3D48fP/7ofjU1NQwYMAAHDx7EvXv3AACPHj3CvHnzSisikSgePnwIf39/WFhYoG3btti7dy++//57xMfHIzY2FuPGjWMxgIjKLI4QKAJ+a6AYBEGAmZkZ2rZtiy1btogdh4hIIamqqiImJgZt2rQp9DmxsbFo3749cnJySjCZYuNrfdn09u1bhIeHY/PmzTh27Bg0NDTQr18/eHh4wMHBAaqqqmJHJCIqFVxUkJSeRCKBp6cnfH19sWbNGujp6YkdiYhI4QiCgLFjx0JXV7fQ56SkpJRgIqLSlZubi6ioKISEhGDXrl1ITU2FjY0NNm7ciAEDBnzR/zeIiMoKThmgMsHd3R2ZmZn4448/xI5CRKSQbGxsoKOjA0EQCr3p6OjAxsZG7OhERXL79m0sWLAADRo0gK2tLWQyGaZNm4Zbt27hxIkT8PT0ZDGAiMotThkoAg4jVCzOzs54/vw5YmNjxY5CRERlBF/rlVNKSgp27dqFkJAQnDx5Ejo6Ohg0aBA8PDzQsWNHPlqTiOj/4wgBKjM8PT1x5swZXL16VewoREREVMpycnIQEREBNzc3GBoaYvTo0dDU1MS2bdvw77//YuPGjejUqROLAURE/8GCAJUZzs7OMDAwQHBwsNhRiIiIqJRcv34d3t7eqFu3Lrp164YLFy5g/vz5ePDgAY4cOYIhQ4ZAS0tL7JhERAqJiwpSmVGxYkUMGzYMW7ZswZIlS1CxYkWxIxEREVERCYKAZ8+e4e7du7h37x7u3r0r//nWrVtISEhAlSpV4OrqCg8PD7Ru3ZqjAIiIColrCBQB5xUqnqtXr6JZs2YIDw9H3759xY5DRERKjq/1JS83Nxf//vtvvg/7//05PT1dfryuri7q1auHevXqoW7durCzs0PPnj2hrq4u4l0QESknjhCgMqVp06Zo06YNgoKCWBAgIvqIR48ewdjYWOwYVE7k5OTgyZMnH/2wf+/ePWRmZsqPr1y5svwDf/fu3fN8+K9Xrx709fXFuxkiojKGBQEqczw9PTF+/Hg8efIERkZGYschIlI4devWRdeuXTFixAj06dOHU6yoSLKzs/Ho0aMCP+zfvXsX9+/fR3Z2tvx4AwMD+Yf7Xr165fmwX7duXT4CkIioFHHKQBFwGKFiev36NYyMjODr6wsvLy+x4xARKZytW7di8+bN+Pvvv6GrqwtXV1eMGDECrVu3FjuawuFrPZCVlYWHDx8W+A3/3bt38fDhQ+Tk5MiPr169er5v9T/8XLduXVSqVEnEuyEiov9iQaAI+CZBcQ0dOhRnz57F9evXubAQEdFHPHr0CCEhIdiyZQsSEhJgYWGBESNGYOjQoahRo4bY8RRCeXytP3v2LFavXi3/wP/o0SPk5ubK9xsZGeX7oP/h5zp16nBFfyIiJcKCQBGUxzcJyuLvv/9G586dceDAAfTo0UPsOERECu/8+fOYNm0aIiMjoaqqChcXF3h5eaFt27ZiRxNVeXytHzBgAE6ePImuXbvm++Bfp04daGhoiB2RiIiKCdcQoDLJ3t4eXbp0wejRo3HlyhVUqVJF7EhERAopKioKmzdvxu7du5GUlARHR0f07NkTBw4cQIcOHRAYGIjJkyeLHZNKSW5uLmQyGcaOHYuFCxeKHYeIiEqYitgBiEqCRCJBcHAw3r59i3HjxoEDYYiI/k9iYiLmz58PU1NT2Nra4vjx45g4cSLu3LmDQ4cOYcKECTh06BC+/fZbfigsZ65du4aXL1/C3t5e7ChERFQKOEKAyqxatWph/fr1+Pbbb9GrVy8MGTJE7EhERAqhUaNG0NDQQN++ffHbb7/BwcGhwOPMzc1x8+bNUk5HYpJKpahYsSKsra3FjkJERKWAawgUQXmcV6iM3NzccODAAVy+fBl16tQROw4Rkeh++eUXuLm5QU9PT+woCq+8vdb37dsXr169wokTJ8SOQkREpYBTBqjMW7t2LXR0dDB8+PA8qyQTEZVX48aNw+HDhzFmzBh5W3R0NKysrLBv3z4Rk5GYcnNzceLECU4XICIqR1gQoDJPX18fISEhkEqlWLVqldhxiIhEt3nzZri6uuLly5fytqpVq8LIyAh9+/bFnj17RExHYrl8+TKSkpJgZ2cndhQiIiolLAhQueDg4ICpU6di1qxZuHr1qthxiIhEFRAQgGnTpmHXrl3yNjMzM+zZsweTJ0/mQoLllFQqhbq6Otq1ayd2FCIiKiUsCFC5sWjRIjRo0ABDhw5FRkaG2HGIiERz69Yt9OjRo8B9PXr0wPXr10s5ESkCmUyG9u3bQ0NDQ+woRERUSlgQoHJDQ0MD27ZtQ3x8PObNmyd2HCIi0RgZGeHMmTMF7rt48SIMDAxKORGJLScnBydOnOB0ASKicoYFASpXvvnmG/z4448ICAhAZGSk2HGIiEQxZMgQLFy4EGvWrMGjR4+QlZWFx48fY8OGDViwYAGGDRsmdkQqZRcvXkRycjIXFCQiKmf42MEiKG+PIiorcnJyYG9vj/v37+PSpUt87BYRlTtZWVkYMmQIwsLCIJFI5O2CIGDgwIHYtm0bKlSoIGJCxVFeXuuXL1+OuXPnIikpCerq6mLHISKiUsJXeyp3VFVVsXnzZjRv3hyTJk3Cpk2bxI5ERFSq1NTUsGvXLly9ehVRUVF49eoV9PX10bFjRzRv3lzseCQCqVSK9u3bsxhARFTOsCBA5VK9evXw888/Y/jw4XBxcUH//v3FjkREVOqaNm2Kpk2b5mtPSUmBrq6uCIlIDNnZ2YiMjMTMmTPFjkJERKWMBQEqt9zd3bFv3z589913aN++PYyMjMSORERUKjIyMrBq1SrIZDJkZGTgw+zB3NxcpKWl4dq1a3j79q3IKam0XLhwAampqVw/gIioHOKiglRuSSQSrF+/HhUrVoSnpye4nAYRlRdeXl7w9vbGo0ePEB8fj7t37yItLQ1nzpzBhQsXMHv2bLEjUimSSqXQ0tJC69atxY5CRESlrNQLAufOnUN4eDhev35d2l0T5WNgYIDg4GAcPnwY69atEzsOEVGpCAsLw7Rp03Dp0iX88MMPaN26NWJjY/HPP/+gXr16yM3NLba+IiIi0KZNG2hpacHExASBgYGFLsBmZ2fDysqqwEfh/fXXX2jVqhUqVaqEBg0awNfXF5mZmXmOGTp0KCQSSb4tNDS0OG6tzJBKpejYsSMqVqwodhQiIiplJVoQePLkCezt7fHjjz8CANasWQMrKysMGDAADRs2xLVr14qlny99s5Geno7Zs2ejbt260NLSgrW1NY4cOVIsWUj5ODk5Ydy4cZg+fToSEhLEjkNEVOKePXuG7t27AwCaNWuGM2fOAACMjY0xa9Ys/PHHH8XST0xMDJydnWFubo7w8HC4ubnBy8sLS5cuLdT5/v7+iIuLy9d+9OhR9OvXD40aNcLu3bsxYcIE+Pv7Y9q0aXmOu3jxIlxdXXH69Ok8m4ODQ7HcX1mQlZWFqKgoThcgIiqvhBI0dOhQwcjISDh8+LCQk5MjGBoaCo6OjsKlS5cEGxsbwdnZuch9nD59WlBTUxOGDh0qHDp0SJgzZ44gkUiEJUuWfPQcNzc3QVdXV1i7dq1w9OhRYejQoYKqqqoQGRn5RX03bty4qPFJQaSlpQmNGjUSWrduLWRmZoodh4ioRFWrVk04ePCgIAiCEB8fL6ioqAgpKSmCIAjCiRMnBG1t7WLpx9HRUbCyssrT5uXlJejo6Ahv37795LkXL14UNDU1BUNDQ8HW1jbPPldXV6Fu3bpCdna2vM3b21uoWLGi/G/4u3fvhAoVKggbN24s0j2U9df606dPCwCE06dPix2FiIhEUKIjBI4cOYLAwEB069YN0dHRePr0KSZNmoTmzZvDy8sLJ0+eLHIf8+fPR8uWLbFlyxY4OTnhxx9/xIwZM7B48WK8e/cu3/F3797Ftm3bsHjxYowbNw5dunRBSEgI6tSpg19++aXIeUg5aWlpYevWrbhw4YJ8RAsRUVnVqVMnrF69Gm/fvkXDhg2hra2N3bt3AwBOnz4NPT29IveRkZEBmUyGvn375mkfMGAAUlNTERUV9dFzMzMz4e7ujokTJ8LMzCzf/vT0dGhra0NVVVXeVrVqVWRmZiI1NRUAcPXqVWRnZ6NFixZFvpeyTCqVolKlSmjVqpXYUYiISAQlWhB48+YNatWqBQA4ePAg1NXV5cP01NXVi7yI29e82TAyMkJcXByGDh0qb1NRUUGFChWQnp5epDyk3Nq0aYN58+Zh0aJFiImJETsOEVGJmT9/Pk6fPo2ePXuiQoUKGDduHL777ju0atUKPj4+xfIo1tu3byMzMxONGjXK096gQQMA+OQULT8/P2RlZcHX17fA/ePHj8c///yDwMBAvH79GjExMVi5ciV69OiBKlWqAHg/XQAANm7cCCMjI1SsWBGdOnVCbGxsgdfMyMhASkpKvq2o71UUnUwmQ6dOnaCmpiZ2FCIiEkGJFgQaNWqEkydPIisrC6GhobCzs4OGhgYAYOvWrfneJHypr3mzoa6ujtatW0NPTw+5ubl48OABJk+ejFu3bmHMmDEF9lNe3ySUR7Nnz0br1q0xbNgwvHnzRuw4REQlonnz5rhx44b8aQJLlizBvHnzYGhoCB8fHwQGBha5j+TkZACArq5unnYdHR0AQEpKSoHnxcXFITAwEJs2bYK6unqBxzg4OMDLywszZsxA5cqVYW1tjerVq2P79u3yYz4UBNLS0rBjxw7s2LED6enpsLe3x+XLl/Ndc8mSJdDT08u3vXjx4ovvXVlkZmYiKiqqwEUbiYiofCjRgsDMmTOxYMECVKtWDbdv38bUqVMBAFZWVti6dSumT59epOt/7ZuND5YuXYo6depg1apVGDlyJLp06VLgceXxTUJ5VaFCBWzZsgWPHz/OtzgVEVFZ8d133+HevXvo2rUrgPePYZ09ezYOHDiA+fPnF8tq8597UoGKSv63IOnp6fDw8MDkyZNhZWX10XPHjh2LZcuWwcfHB1KpFMHBwXj16hWcnJzw9u1bAMAPP/yAw4cPY/PmzbCzs0P//v1x9OhRaGtrY9GiRfmuOWvWLCQnJ+fbDAwMvvDOlUdcXBzevn3LBQWJiMqxCiV5cVdXV9SpUwdRUVGwtbVFu3btAAC2trbw8/ODk5NTka7/NW82/svFxQUdOnRAVFQU/Pz88O7dO2zZsiXfcbNmzZIXM/6rbdu2XxaYlELDhg2xYsUKfP/993BxcYGzs7PYkYiIitXWrVsxaNCgEu3jwzoEH+b0f/ChWF/QOgU+Pj7Izc3F3LlzkZ2dDQDy0XjZ2dlQVVXF48eP8euvv2L27NlYuHCh/FwrKys0adIEQUFBmDBhAszMzPKtP6Cvr48OHTrg0qVL+fpWV1cvcESCRCL5kttWKjKZDLq6umjZsqXYUYiISCQlWhAAgA4dOqBDhw7yf2dnZ2PWrFnyOX5F8TVvNv6radOmAAAbGxtkZ2dj/vz5WLRoEerUqZPnuPL4JqG8Gz16NPbt24eRI0fi6tWrqFatmtiRiIiKTfv27SGVSj86Mq44mJqaQlVVFYmJiXnaP/y7cePG+c4JDQ3FvXv3UKlSpXz71NTUEBwcDDMzMwiCkOe9BQBYWFigatWq8kca79y5E5UrV4ajo2Oe4969e8e/6f+fVCpFp06dUKFCib8dJCIiBVWiUways7Ph6+srn9Mnk8lQo0YNVKtWDZ07d0ZSUlKRrv81bzbu3buH33//Pd8CgpaWlgCAx48fFykTlQ0SiQQbN25Ebm4uRo8ezfUiiKhMad68OQIDA9GoUSMMGjQInp6eebaRI0cWuQ8NDQ3Y2NggPDw8z9/QsLAw6OnpFTglYN++fYiLi8uzWVpawtLSEnFxcXBxcUGDBg2gqqqa70lFCQkJePnyJerXrw8A2LBhA8aMGYPMzEz5MY8ePcKpU6c4RB7v10fi74KIiEq0JDxv3jwEBARg1apVAN7P56tatSrmz5+P5cuXY9asWVi/fv1XX/+/bzamT58u/8b+U2827t27h1GjRkFLSwuurq7y9oiICFSsWLHAxxtR+VSjRg389ttv6Nu3L4KDg+Hp6Sl2JCKiYrF7927UrFkTWVlZiIuLy7e/uEbA+fj4oEuXLvKiQ3R0NAICAuDv7w8tLS2kpKQgPj4epqamqFatGpo1a5bvGh/WBWrdurW8bfLkyQgICAAAdO3aFffu3YOvry/q1q2L0aNHAwDmzp2LLl26oHfv3pg0aRJevXoFX19fVK1alWvEADhz5ox8kUUiIirHhBJkYmIiBAQECIIgCPHx8YJEIhFCQkIEQRCErVu3CoaGhkXu4/jx44JEIhEGDBggHDx4UPDx8REkEomwdOlSQRAEITk5WTh9+rTw7NkzQRAEIScnR+jSpYtQtWpVYf369cLRo0eFSZMmCSoqKsLChQu/qO/GjRsXOT8pPk9PT6FSpUrCrVu3xI5CRKR0wsPDhWbNmgkVK1YUTExMhMDAQPk+qVQqABCCg4M/er6tra1ga2ubpy03N1dYsWKFYGZmJlSsWFGoW7euMHr0aPlr/QfHjh0TOnbsKOjq6gr6+vrCt99+K9y7d++L8pfV13pfX19BX19fyM7OFjsKERGJSCIIJTcWWkNDA0ePHkWnTp0QGBgIb29v/PvvvzAwMMCJEyfQvXt3+WrARbF7927Mnz8fCQkJMDY2xvjx4+XVf5lMBnt7ewQHB2P48OEA3q854Ovri7CwMDx+/BgNGzbElClTvniIpIWFBeLj44ucnxRbamoqvvnmGxgZGSEyMhKqqqpiRyIiolJSVl/r7e3toauriz179ogdhYiIRFSiUwZq1qyJO3fuoFOnTti7dy9atmwpf3xPdHQ0atWqVSz99O3bF3379i1wn52dXb753zo6OggMDCyW5yxT2aejo4MtW7bAxsYGS5culT+3m4hIWTk4OHz2mL///rsUkpAY0tPTcfr0afj7+4sdhYiIRFaiiwoOGTIEU6dOhZOTE6KiouRzsCdPnowFCxZg6NChJdk9UbHp0KEDvL29MX/+fJw/f17sOERERZKbmwtBEPJsqampiI2NxbVr12Bubi52RCpBMTExyMjIgJ2dndhRiIhIZCU6QmDhwoXQ1tZGZGQk/P39MXbsWABAXFwcpk2bBh8fn5LsnqhYzZ8/H4cPH8bQoUNx7tw5aGpqih2JiOiryGSyAtuTkpLQvXt3FgTKOJlMhipVqqB58+ZiRyEiIpGV6BoCZV1ZnVdIHxcfH49WrVrhu+++kz89g4ioLNmzZw8mT56MO3fuiB1FIZTF13pbW1tUrVoV4eHhYkchIiKRleiUAQB48eIFvL290a5dO5ibm6Njx46YNWsWnj17VtJdExU7CwsLLF26FKtXr8bRo0fFjkNEVOwEQcDTp0/FjkEl5N27d4iJieF0ASIiAlDCIwQePnwIa2trPH/+HNbW1jA0NMSTJ09w+vRpGBgY4MyZMzA2Ni6p7ktcWfzWgD4vNzcX3bp1Q3x8PK5cuYIqVaqIHYmI6ItERkbma8vJycHDhw/h5+cHQ0NDnDx5UoRkiqesvdb//fff6Ny5My5fvoxmzZqJHYeIiERWomsIzJw5E2pqaoiPj0f9+vXl7bdv34ajoyPmzJmDTZs2lWQEomKnoqKCTZs2oVmzZhg7diz++OMPSCQSsWMRERWanZ0dJBIJBEGQ//368P1A7dq1sXLlShHTUUmSSqUwMDBAkyZNxI5CREQKoEQLAkeOHMHKlSvzFAMAoH79+pg/fz6mT59ekt0TlRhjY2OsW7cO3377LXr16gU3NzexIxERFZpUKs3XJpFIoKuri+bNm0NFpcRnFJJIpFIpbG1t+d+YiIgAlPAaAtnZ2TAwMChwX7Vq1ZCSklKS3ROVqMGDB8PNzQ3jx4/H/fv3xY5DRFRotra2+Oabb/Du3TvY2trC1tYWderUQXR0NFJTU8WORyUkLS0NZ86cgb29vdhRiIhIQZRoQaB58+bYtm1bgfu2bNnCuWuk9NasWQNdXV0MHz4cubm5YschIiqUGzduoEmTJvLHAQPvp/NNnjwZrVu3ZpGzjIqOjkZWVhYLAkREJFeiBYG5c+di27Zt6NmzJ7Zs2YKjR49iy5Yt6NGjB/744w/MmjWrJLsnKnH6+voICQmBVCrlnFsiUhozZsyAsbExoqKi5G0ODg54+PAhqlatihkzZoiYjkqKVCpF9erV0bhxY7GjEBGRgijRpwwA70cCzJw5E//++6+8zdDQEP7+/nB3dy/JrktcWVt5mL7etGnTsGbNGpw9e5YjX4hI4VWpUgXbtm1D9+7d8+3bt28fPD098fz5cxGSKZ6y9Frfvn171K5dGzt37hQ7ChERKYgSX1Fm2LBhePToEeLj4xEVFYX4+Hg8evQIxsbG+O6770q6e6JSsWjRIjRq1AhDhw5FRkaG2HGIiD5JIpEgLS2twH1ZWVnIzMws5URU0t68eYO4uDhOFyAiojxKZYlZiUQCc3NztG/fHubm5pBIJLh69Sp+//330uieqMRpaGhg69atuH79OubNmyd2HCKiT7K1tYWfn1++UQCvXr3C4sWLYWdnJ04wKjFRUVHIzs7mf1siIsqjRB87SFSefPPNN/jxxx/h7e2NHj16wNbWVuxIREQF8vf3R9u2bWFiYgJra2tUr14dz58/R0xMDNTV1bF9+3axI1Ixk8lkMDQ0hJmZmdhRiIhIgfAhtETFaNq0aejUqRPc3d2RnJwsdhwiogI1atQI165dw5gxY+RDyV+/fo3Ro0fjwoULaNSokdgRqZhJpVLY29tDIpGIHYWIiBQIRwgQFSNVVVWEhISgefPmmDhxIkJCQsSORERUoJo1a2LmzJmoVq0aACApKQlPnjxBrVq1RE5GxS0lJQXnzp3DyJEjxY5CREQKhiMEiIpZvXr1sGbNGmzevBmhoaFixyEiyic5ORndu3eHjY2NvC02NhZNmzbFgAED8O7dOxHTUXGLiopCTk4OFxQkIqJ8in2EgIODQ6GOe/DgQXF3TaQwhg0bhr179+L7779H+/btUbNmTbEjERHJeXt748KFC1i9erW8zd7eHmFhYRg/fjwWLFiApUuXipiQipNUKoWxsTEaNGggdhQiIlIwxT5CIDc3F4IgfHarVatWnm8miMoSiUSCDRs2QF1dHZ6enhAEQexIRERye/fuxfLlyzFo0CB5m7q6Ovr27YvFixfjjz/+EDEdFTepVAo7OzuuH0BERPkU+wgBmUxW3JckUkpVq1ZFUFAQunfvjl9++QXjx48XOxIREYD3UwaqVKlS4D4jI6N8jyMk5fX69WtcuHABY8eOFTsKEREpIK4hQFSCnJycMH78eMyYMQM3btwQOw4REQCgRYsW+P333wvc92FhVCobTp48idzcXK4fQEREBeJTBohK2LJly3D06FEMGzYM0dHRUFNTEzsSEZVzs2fPhouLC1q3bo2+ffuievXqeP78Ofbt24e4uDjs27dP7IhUTKRSKWrXrg0TExOxoxARkQLiCAGiEqalpYWtW7fi4sWLWLhwodhxiIjQo0cP7NmzBwAwb948fP/995g7dy4yMzOxZ88edO/eXeSEVFxkMhns7e25fgARERWIBQGiUtCmTRvMmzcPixYtQkxMjNhxiIjg7OyMs2fPIi0tDQ8fPpQ/q75nz55iR6Ni8urVK1y8eJHTBYiI6KNYECAqJbNmzYKVlRWGDh2KN2/eiB2HiAjPnj3D8+fPkZ2djZcvX+Lu3bu4du0a1q9fL3Y0KgaRkZEQBAF2dnZiRyEiIgXFggBRKalQoQK2bNmCJ0+eYNq0aWLHIaJy7NKlS2jatCmMjIxQr149mJiYwMTEBKampmjevDkmTJggdkQqBjKZDPXq1UO9evXEjkJERAqKBQGiUtSgQQOsWLECv/76KxftIiLRzJgxA0lJSQgMDISdnR26deuGNWvWoEePHpBIJHyEcBkhlUo5OoCIiD6JBQGiUjZ69Gg4Oztj1KhRePbsmdhxiKgcio2NxcKFCzFlyhQMHjwYaWlpGDt2LPbt24c+ffpg9erVYkekInrx4gUuX77M9QOIiOiTWBAgKmUSiQQbN26EIAgYPXo0BEEQOxIRlTMZGRlo2LAhAKBRo0a4dOmSfN+IESNw+vRpsaJRMYmMjAQAjhAgIqJPYkGASAQ1atTAb7/9hr179yIoKEjsOERUztSpUwe3b98G8L4gkJKSgrt37wIA1NXV8erVKxHTUXGQSqWoX78+6tSpI3YUIiJSYCwIEImkd+/eGDlyJCZNmoRbt26JHYeIypH+/fvD29sbYWFhqFmzJszNzeHj44MrV65g+fLlMDU1FTsiFZFUKuV0ASIi+iyJwPHKX83CwgLx8fFixyAllpqaihYtWqBatWo4fvw4tLW1xY5EROVAeno6hg0bhrS0NBw8eBBHjhxB3759kZGRAVVVVfzxxx/o16+f2DEVgjK+1j979gw1atTA1q1b4ebmJnYcIiJSYBXEDkBUnuno6GDHjh3o3LkzunXrhgMHDkBPT0/sWERUxmloaGDXrl3IysoCAHTr1g1Xr17FuXPnYGlpyRECSu7EiRMAuH4AERF9HqcMEInMysoKx44dw7Vr19ClSxe8fPlS7EhEVE6oqanJf65fvz4GDhxY7MWAiIgItGnTBlpaWjAxMUFgYGChF1PNzs6GlZVVgR9s//rrL7Rq1QqVKlVCgwYN4Ovri8zMzDzHPH36FG5ubqhatSr09PTg6uqKJ0+eFMdtKTSpVIqGDRvC2NhY7ChERKTgWBAgUgBt27aFVCrF3bt3YWdnh6dPn4odiYioyGJiYuDs7Axzc3OEh4fDzc0NXl5eWLp0aaHO9/f3R1xcXL72o0ePol+/fmjUqBF2796NCRMmwN/fH9OmTZMfk52dje7duyM2Nhbr16/HunXrcOrUKTg6OspHRpRVMpmM6wcQEVGhcA2BIlDGeYWk2K5fv47OnTtDR0cHx48fR61atcSORET01bp164bXr18jNjZW3jZz5kysW7cOT58+haam5kfPvXTpEqytraGnpwczMzPIZDL5viFDhiA6Ohq3bt2CqqoqAGDWrFn46aef8ObNG6ipqWHHjh0YMmQIrl27BgsLCwBAfHw8mjZtii1bthR6br2yvdb/+++/MDIywvbt2+Hq6ip2HCIiUnAcIUCkQBo3boyTJ08iIyMDnTp1kj8WjIhI2WRkZEAmk6Fv37552gcMGIDU1FRERUV99NzMzEy4u7tj4sSJMDMzy7c/PT0d2tra8mIAAFStWhWZmZlITU0FABw5cgRmZmbyYgDw/sN948aNcfDgwaLensL6UDjh+gFERFQYLAgQKRhTU1OcPHkSampq6NSpE27cuCF2JCKiL3b79m1kZmaiUaNGedobNGgAAEhISPjouX5+fsjKyoKvr2+B+8ePH49//vkHgYGBeP36NWJiYrBy5Ur06NEDVapUAfB+xNX/9v2h/4L6zsjIQEpKSr5N2QZSymQymJubw8jISOwoRESkBFgQIFJAtWvXRmRkJKpUqQIbGxtcunRJ7EhERF8kOTkZAKCrq5unXUdHBwCQkpJS4HlxcXEIDAzEpk2boK6uXuAxDg4O8PLywowZM1C5cmVYW1ujevXq2L59e57+/7fvD/0X1PeSJUugp6eXb3vx4kXhblhBSKVSjg4gIqJCY0GASEEZGhpCJpOhTp06sLOzyzMHl4joS6moqEBVVbVQW4UKRX8qcW5u7mfz/K/09HR4eHhg8uTJsLKy+ui5Y8eOxbJly+Dj4wOpVIrg4GC8evUKTk5OePv27Wf7L6jvWbNmITk5Od9mYGDwyftQJI8fP8bNmze5oCARERVa0V/xiajEVK1aFcePH0ePHj3QpUsXHDhwADY2NmLHIiIlNG/ePEgkko/uf/fuHTZs2IDk5ORiWdBUT08PAORz+j/48O38h/3/5ePjg9zcXMydOxfZ2dkAIB+yn52dDVVVVTx+/Bi//vorZs+ejYULF8rPtbKyQpMmTRAUFIQJEyZAT08vX98f+i+ob3V19QJHJHzqd6ZouH4AERF9KRYEiBScnp4eIiIi0Lt3bzg5OeGvv/6Co6Oj2LGISMksWLDgo/tOnz6NESNGIDk5GaNHj0ZgYGCR+zM1NYWqqioSExPztH/4d+PGjfOdExoainv37qFSpUr59qmpqSE4OBhmZmYQBAEdOnTIs9/CwgJVq1bFtWvXAABmZma4cOFCvuskJiZ+cvSBMpNKpbCwsED16tXFjkJEREqCUwaIlIC2tjb2798PBwcHuLi4YM+ePWJHIqIyICMjA9OnT4eNjQ3S09MRERGBDRs2yOf5F4WGhgZsbGwQHh6eZ2G+sLAw6OnpFfihfN++fYiLi8uzWVpawtLSEnFxcXBxcUGDBg2gqqqKkydP5jk3ISEBL1++RP369QEAjo6OuH79ep5HBsbHx+P69etltqgqlUo5XYCIiL4IRwgQKQkNDQ2Eh4fDzc0N/fv3x5YtW/iMaSL6ah9GBdy8eRPfffcdAgMDC/xmvih8fHzQpUsXDBo0CJ6enoiOjkZAQAD8/f2hpaWFlJQUxMfHw9TUFNWqVUOzZs3yXeNDcaJ169bytsmTJyMgIAAA0LVrV9y7dw++vr6oW7cuRo8eDQAYPHgwFi9ejO7du8Pf3x8A4O3tjWbNmmHQoEHFep+K4MGDB7h16xYLAkRE9EU4QoBIiVSsWBE7duyAm5sb3NzcEBQUJHYkIlIyGRkZmDZtGmxsbJCRkYFjx45h/fr1xV4MAN4/DSAsLAwJCQno06cPtm3bhoCAAHh5eQEAzp8/D2traxw4cOCLrhsQEICAgACEh4fDyckJCxYsQNeuXREXFwd9fX0A79cEOHr0KFq1aoXvvvsO48ePh7W1NY4cOVIsiyYqmg/rB9ja2oobhIiIlIpEULYH7CoQCwuLPEMRiUpLbm4uxo8fj/Xr12P16tX44YcfxI5EREogOjoaI0aMQGJiIr7//nsEBARAW1tb7FgKTVle6z09PXH27FlcvnxZ7ChERKREyl6JnKgcUFFRwS+//AJtbW1MnDgRb9++xcyZM8WORUQKbMqUKVizZg10dXXx+++/w8HBAS9fvsTLly8LPL5OnTqlnJCKQiaTwcXFRewYRESkZFgQIFJSEokEAQEBqFSpEry9vfHmzRv4+fkp1SOyiKj0rFq1CgCQlJSEkSNHfvb4nJycko5ExeTevXu4c+cOHzdIRERfjAUBIiUmkUiwYMECaGlpYebMmUhLS8Py5ctZFCCifIKDg8WOQCVEKpVCIpFw/QAiIvpiLAgQlQFeXl7Q1tbGhAkTkJaWhnXr1kFFhWuGEtH/8fDwEDsClRCZTIZvvvkGVapUETsKEREpGRYEiMqI8ePHQ1tbGyNHjsTbt28RHBxcJlfSJiKi/yMIAqRSKfr16yd2FCIiUkL8tEBUhgwfPhyampoYOnQo3r17h+3bt6NixYpixyIiBaCiolLo6UQSiQTZ2dklnIiKw507d3D//n3Y29uLHYWIiJQQCwJEZczgwYOhqamJgQMHom/fvggNDYWmpqbYsYhIZPPmzftkQeDdu3fYsGEDkpOTUatWrVJMRkUhk8kgkUhgY2MjdhQiIlJCLAgQlUG9evXC/v370bt3b/Ts2RN79+5FpUqVxI5FRCJasGDBR/edPn0aI0aMQHJyMkaPHo3AwMDSC0ZFIpVK0bJlS+jr64sdhYiIlBBXHSMqo7p27YojR47g7NmzcHR0xOvXr8WOREQKJiMjA9OnT4eNjQ3S09MRERGBDRs2QEdHR+xoVAgf1g/gdAEiIvpaZaIgEBERgTZt2kBLSwsmJiYIDAyEIAgfPT4jIwOLFy+Gubk5tLW1YWZmBj8/P2RmZpZiaqKS16lTJxw/fhw3btyAg4MDXrx4IXYkIlIQp0+fxjfffIOffvoJI0eOxNWrV9GlSxexY9EXuHXrFh49esSCABERfTWlLwjExMTA2dkZ5ubmCA8Ph5ubG7y8vLB06dKPnjNp0iQsWrQIw4cPx969e+Hp6Ql/f3+MHTu2FJMTlY42bdpAJpPh0aNHsLOzw5MnT8SOREQiysjIwLRp02BjY4OMjAwcO3YM69ev57QiJSSVSqGiooKOHTuKHYWIiJSURPjUV+lKoFu3bnj9+jViY2PlbTNnzsS6devw9OnTfIupvXz5EtWqVcPSpUsxY8YMefvSpUvh7e2NZ8+eoVq1aoXq28LCAvHx8cVzI0Ql7MaNG+jSpQs0NTVx/Phx1KlTR+xIRFTKoqOjMWLECCQmJuL7779HQEAAtLW1xY6l0BT5tX7IkCFITEzEmTNnxI5CRERKSqlHCGRkZEAmk6Fv37552gcMGIDU1FRERUXlOyclJQVjxoxBr1698rSbm5sDAG7fvl1ygYlEZG5ujpMnTyInJwedOnVCYmKi2JGIqBRNmTIFtra2ePHiBX7//Xd4e3vj5cuXuH//foEbKTZBECCTyThdgIiIikSpnzJw+/ZtZGZmolGjRnnaGzRoAABISEhA165d8+wzMTHBL7/8ku9af/31F9TU1PJdC3hfeMjIyMjXruSDK6gcMjExQWRkJLp06YJOnTrh2LFjaNKkidixiKgUrFq1CgCQlJSEkSNHfvb4nJycko5ERXDz5k08efIEdnZ2YkchIiIlptQFgeTkZACArq5unvYPqyOnpKQU6jq7d+9GSEgIJkyYgMqVK+fbv2TJEvj6+uZrNzAw+NLIRKKrVasWTpw4AUdHR9ja2uLo0aNo2bKl2LGIqIQFBweLHYGKkVQqhaqqKtcPICKiIlHqgkBubu4n96uofH5GRHh4OIYMGYKOHTti2bJlBR4za9YsTJ06NV9727ZtCxeUSMHUqFEDUqkUTk5OsLe3x6FDh2BtbS12LCIqQR4eHoU+NikpqQSTUHGQyWRo06YNHxFJRERFotRrCOjp6QEAUlNT87R/GBnwYf/HrFixAgMHDkSHDh1w4MABaGhoFHicuro6dHV1820SiaQY7oJIHFWqVMGxY8fQrFkzdO3aFTKZTOxIRFRKFi1a9NF9O3fuROPGjUsxDX2pD+sHcLoAEREVlVIXBExNTaGqqppvcbQP//7YGxpBEDBx4kRMnToVgwcPxqFDh1hhp3JJV1cXhw8fRvv27dG9e3ccOnRI7EhEVArmzZsHPz+/PG2PHj1Cr1694Orqinr16okTjArl+vXrePr0KRcUJCKiIlPqgoCGhgZsbGwQHh6eZ4G/sLAw6OnpwcrKqsDzZs+ejZ9//hlTp07Ftm3bULFixdKKTKRwtLW1sXfvXjg6OqJ3794IDw8XOxIRlbDffvsNfn5+mD9/PgBg7dq1sLCwwMmTJ7F27VqcPn1a5IT0KTKZDBUqVECHDh3EjkJEREpOIij5Uvl///03unTpgv79+8PT0xPR0dFYtGgR/P394eXlhZSUFMTHx8PU1BTVqlXDxYsXYWlpidatW2P16tX5rmdhYZFvkcKPUeRnExN9qaysLAwbNgyhoaEICQmBm5ub2JGIqATt3LkT7u7uqFWrFu7evYtBgwZhxYoVMDQ0FDuaQlHE1/qBAwfi8ePHOHXqlNhRiIhIySn1ooIA4ODggLCwMMyfPx99+vSBsbExAgICMG3aNADA+fPnYW9vj+DgYAwfPlw+miAuLq7ARdSkUinn5FG5pKamhm3btkFTUxPDhg3D27dvMXr0aLFjEVEJGTx4MCpVqoSBAweiZ8+e2LFjh9iRqBByc3Mhk8nw/fffix2FiIjKAKUfISAmRfzWgKiocnNzMXHiRKxduxYrVqzA5MmTxY5ERMXA09OzwPazZ8/i2rVr6N69O6pXrw4AkEgk+P3330sznsJStNf6q1evolmzZjh27Bg6d+4sdhwiIlJySj9CgIiKl4qKCn7++Wdoa2tjypQpSEtLw5w5c8SORURF9Pfff3/06Th16tTBtWvXcO3aNQDgU3QUmFQqhZqaGh8VS0RExYIFASLKRyKRwN/fH5UqVYKPjw/S0tKwaNEifkggUmJ3794VOwIVA6lUinbt2kFLS0vsKEREVAawIEBEBZJIJJg7dy60tbUxbdo0pKWlYcWKFVBRUeqHkxARKa3c3FycOHECEyZMEDsKERGVESwIENEnTZ06FVpaWhg7dizevn2L9evXQ1VVVexYRETlzpUrV/Dq1SsufkxERMWGBQEi+qwxY8ZAS0sLI0aMwOXLl+Hm5oZ+/fqhVq1aYkcjIio3pFIp1NXVuX4AEREVG479JaJCcXd3x6FDh2BgYIDp06ejdu3a6NChA1asWIH79++LHY+IqMyTyWSwtraGhoaG2FGIiKiMYEGAiArN0dERBw4cwLNnz7B582YYGBjA29sbdevWRdu2bREYGIg7d+6IHZOIqMzJycnBiRMnOF2AiIiKFQsCRPTF9PX1MWzYMOzZswfPnz/Htm3bYGxsjLlz56J+/fpo3bo1/P39kZiYKHZUIqIy4dKlS3j9+jXs7e3FjkJERGUICwJEVCS6uroYMmQIwsPD8fz5c+zcuRMmJibw8/NDw4YN0bJlSyxatAgJCQliRyUiUloymQwaGhpo27at2FGIiKgMYUGAiIpNpUqVMGjQIOzatQvPnz9HaGgozM3NsWTJEpibm6NZs2bw8/NDfHy82FGJiJSKVCpF+/btoa6uLnYUIiIqQ1gQIKISoa2tjf79+2PHjh14/vw5du/ejW+++QaBgYFo0qQJLCwsMG/ePFy5cgWCIIgdl4hIYWVnZyMyMpLTBYiIqNixIEBEJU5TUxN9+vTB1q1b8ezZM+zduxdt2rTB6tWr0bx5c5ibm2POnDm4cOECiwNEZUxERATatGkDLS0tmJiYIDAwsND/P8/OzoaVlVWehfTu3r0LiUTy0W3EiBHyY4cOHVrgMaGhocV9myXq4sWLSElJ4YKCRERU7CqIHYCIyhcNDQ24uLjAxcUFmZmZOH78OHbt2oV169Zh8eLFMDU1xYABAzBgwAC0atUKEolE7MhE9JViYmLg7OyMwYMHY+HChYiKioKXlxeys7Ph7e392fP9/f0RFxcHW1tbeZuRkRFOnz6d79i1a9di586dGDlypLzt4sWLcHV1xcSJE/Mc26hRoyLcVemTSqXQ0tKClZWV2FGIiKiMkQj8Ou6rWVhYcC40UTHJysqCVCpFaGgodu/ejRcvXqBevXry4oCVlRWLA0RKplu3bnj9+jViY2PlbTNnzsS6devw9OlTaGpqfvTcS5cuwdraGnp6ejAzM4NMJvvosefOnYO1tTUWL16M6dOnAwDS09Oho6OD9evX5ykSfClFeK3v0aMHsrOzERERIWoOIiIqezhlgIgUgpqaGhwdHfHrr7/iyZMnOHbsGJycnLB582a0a9cOdevWxZQpU3Dq1Cnk5uaKHZeIPiMjIwMymQx9+/bN0z5gwACkpqYiKirqo+dmZmbC3d0dEydOhJmZ2Sf7EQQB48ePh4WFBaZMmSJvv3r1KrKzs9GiRYsi3YfYsrOzcfLkSU4XICKiEsGCABEpnAoVKqBz585Yt24dHj9+DJlMhl69euGPP/5Ax44dUbt2bUycOBGRkZHIyckROy4RFeD27dvIzMzMNzy/QYMGAPDJR5H6+fkhKysLvr6+n+1n586diI2NxcqVK6Gqqipvv3jxIgBg48aNMDIyQsWKFdGpU6c8oxX+KyMjAykpKfk2sQdSnjt3Dm/evOGCgkREVCJYECAihaaqqgpbW1usWbMGjx49wsmTJzFw4ECEh4fD1tYWtWrVwvjx4yGVSpGdnS12XCL6/5KTkwEAurq6edp1dHQAACkpKQWeFxcXh8DAQGzatKlQj9gLCAhAhw4d8n2D/qEgkJaWhh07dmDHjh1IT0+Hvb09Ll++nO86S5YsgZ6eXr7txYsXn81QkqRSKbS1tdG6dWtRcxARUdnEggARKQ0VFRV07NgRK1euxP379xEdHY0hQ4Zg//79cHBwQM2aNfH999/j6NGjyMrKEjsuUbn2uak9Kir534Kkp6fDw8MDkydPLtQCetHR0Th//jxmzJiRb98PP/yAw4cPY/PmzbCzs0P//v1x9OhRaGtrY9GiRfmOnzVrFpKTk/NtBgYGn81RkmQyGTp27Ag1NTVRcxARUdnEggARKSUVFRVYW1tj+fLluHv3LmJjYzF8+HAcPXoUjo6OMDIywowZM3D//n2xoxKVS3p6egCA1NTUPO0fRgZ82P9fPj4+yM3Nxdy5c5GdnY3s7GwIggBBEOQ//1doaCgqV66MHj165LuWmZkZunXrlqdNX18fHTp0wKVLl/Idr66uDl1d3XybmIuZZmVlISoqitMFiIioxLAgQERKTyKRwMrKCsuWLcOtW7dw7tw5DB8+HBs3bkT9+vUxePBgxMTEiB2TqFwxNTWFqqoqEhMT87R/+Hfjxo3znRMaGoqEhARUqlQJampqUFNTQ2RkJCIjI6GmpoaQkJA8x+/fvx99+vQp8NvznTt3Frgq/7t371CtWrWi3FqpiYuLQ1paGgsCRERUYlgQIKIyRSKRwNLSEoGBgXjw4AFWrVqF8+fPw9raGtbW1vjzzz+51gBRKdDQ0ICNjQ3Cw8PzfLMfFhYGPT29AqcE7Nu3D3FxcXk2S0tLWFpaIi4uDi4uLvJjX716hX/++QcdOnQosP8NGzZgzJgxyMzMlLc9evQIp06dUpoP2DKZDDo6OrC0tBQ7ChERlVEsCBBRmVWpUiWMHz8eCQkJ2Lt3LzQ1NTF48GCYmppi+fLl8kXPiKhk+Pj4IDY2FoMGDcKhQ4cwd+5cBAQEYPbs2dDS0kJKSgpiYmLw/PlzAECzZs3QunXrPJuOjg50dHTQunVrVK1aVX7tK1euAAAsLCwK7Hvu3Lm4d+8eevfujcOHD2P79u1wcHBA1apVMW3atJK/+WIglUrRqVMnVKhQQewoRERURrEgQERlnoqKClxcXPD333/jwoULsLOzw6xZs1CrVi1MmjQJt27dEjsiUZnk4OCAsLAwJCQkoE+fPti2bRsCAgLg5eUFAPLROwcOHPjiaz99+hQAULly5QL329vbIyIiAm/evMHgwYMxfvx4WFpa4uTJkwWuX6BoMjMzlWo0AxERKSeJIPYDdpWYhYUF4uPjxY5BRF/hyZMn+OWXX7B+/Xq8fPkSvXv3xpQpU9CpUydRFxEjIsUi1mt9VFQUOnXqhLi4OD5ykIiISgxHCBBRuWRkZISFCxfi/v372LBhA27evAlbW1u0bt0aW7duzTPvmIiotEmlUujp6aFly5ZiRyEiojKMBQEiKtc0NTUxevRoXL16FYcPH0a1atUwbNgwmJiYYPHixXj58qXYEYmoHJLJZLCxsYGqqqrYUYiIqAxjQYCICO+fTtCtWzccPnwY165dQ8+ePbFw4ULUrl0bY8aMwY0bN8SOSETlREZGBqKjo2FnZyd2FCIiKuNYECAi+h8WFhb49ddfcf/+fcyePRt79uxB48aN0aNHDxw9ehRceoWISlJMTAzS09O5oCAREZU4FgSIiD6iWrVq8PHxwd27d7Fp0yY8fvwYjo6OaN68OX7//Xekp6eLHZGIyiCZTIbKlSvjm2++ETsKERGVcSwIEBF9hrq6Ojw8PHDhwgX8/fffMDExwejRo1GnTh0sWLBA/vgzIqLiIJVKYWNjAxUVvk0jIqKSxVcaIqJCkkgksLe3x969e5GQkIBBgwYhICAAderUgaenJ65cuSJ2RCJScu/evcPp06c5XYCIiEoFCwJERF+hYcOGWLNmDR4+fIiFCxfi6NGjaN68Obp06YIDBw4gNzdX7IhEpIRiYmKQmZnJggAREZUKFgSIiIqgcuXK8PLywu3bt7Fjxw6kpqbC2dkZFhYWWLduHdLS0sSOSERKRCqVomrVqmjatKnYUYiIqBxgQYCIqBioqanh22+/RUxMDE6dOoVmzZphwoQJqF27NmbNmoVHjx6JHZGIlIBUKoWtrS3XDyAiolLBVxsiomIkkUjQvn177Nq1C4mJiRg+fDjWrl2LevXqYejQoTh37pzYEYlIQb19+xaxsbGcLkBERKWGBQEiohJiYmKCn376CQ8fPkRAQACio6PRunVr2NjYYPfu3cjJyRE7IhEpkOjoaGRlZcHOzk7sKEREVE6wIEBEVMJ0dXUxefJk/PPPPwgLC4MgCOjXrx8aNWqEVatWITU1VeyIRKQApFIpqlWrhiZNmogdhYiIygkWBIiISomqqir69euHkydPIi4uDu3atcP06dNhbGyM0aNH4/Tp0xAEQeyYRCQSmUwGOzs7SCQSsaMQEVE5wYIAEZEIWrdujW3btuHOnTuYMmUKIiIi0L59e1hYWGDZsmV48uSJ2BGJqBS9efMGZ86c4XQBIiIqVSwIEBGJqFatWvD19cWdO3dw9OhRWFpaYt68eahduzZcXFywe/duZGZmih2TiErYqVOnkJ2dzQUFiYioVLEgQESkAFRUVNClSxds27YN//77L9asWYOnT5+iX79+MDY2xpQpU3DlyhWxYxJRCZHJZKhRowbMzc3FjkJEROUICwJERApGX18fY8aMwZkzZ3DlyhW4u7tj27ZtaN68OVq3bo1ffvkFSUlJYsckomIklUq5fgAREZU6FgSIiBRY06ZNsXz5cjx69Ai7d++GsbExJk6cCCMjI7i6uiIiIoKPLyRScqmpqTh79iynCxARUaljQYCISAmoqamhT58+2LNnDx4+fIgff/wRly5dQrdu3VCvXj3MnTsXt27dEjsmEX2FqKgo5OTksCBARESljgUBIiIlY2hoiOnTp+PatWuIiYlBz549sXr1ajRo0AB2dnbYvHkz0tLSxI5JRIUklUphZGSEhg0bih2FiIjKGRYEiIiUlEQiQdu2bbF+/Xo8efIEW7duhaqqKjw8PGBkZIRRo0YhOjoagiCIHZWIPkEqlcLe3p7rBxARUaljQYCIqAzQ0tKCm5sbjh8/jtu3b2Pq1Kk4duwYOnTogMaNG2Pp0qV4/Pix2DGJ6H8kJyfj/PnznC5ARESiYEGAiKiMMTExwYIFC3D79m0cO3YMrVu3xoIFC1C7dm04OzsjLCwMmZmZYsckIgAnT55Ebm4u7OzsxI5CRETlEAsCRERllIqKCjp37oytW7fiyZMn+OWXX/D8+XMMGDAAxsbGmDx5Mi5duiR2TKJyTSqVolatWjA1NRU7ChERlUMsCBARlQP6+vr4/vvvERsbi6tXr2L48OHYsWMHWrRogVatWmHt2rV49eqV2DGJyh2ZTMb1A4iISDQsCBARlTNNmjRBQEAAHj58iD179qB27dqYPHkyjIyMMHjwYBw5cgQ5OTlixyQq85KSknDhwgVOFyAiItGwIEBEVE6pqamhV69e+Ouvv/Dw4UMsXrwY165dg5OTE+rVqwcfHx8kJiaKHZOozIqMjIQgCFxQkIiIRMOCABERoUaNGpg2bRquXLmCM2fOwNnZGWvWrEHDhg1ha2uLTZs24c2bN2LHJCpTZDIZ6tatCxMTE7GjEBFROcWCABERyUkkErRp0wbr1q3DkydPsG3bNqipqWHEiBEwMjLCkCFD8Ntvv+Gff/6BIAhixyVSalKplNMFiIhIVCwIEBFRgTQ1NTFkyBAcO3YMd+/exYwZM5CYmIgxY8agUaNGMDY2xpAhQ7BhwwYkJCSwQED0BV6+fIlLly5xugAREYlKIvAd3FezsLBAfHy82DGIiEpVSkoKTp06hRMnTkAmk+Hs2bPIycmBoaEhbG1tYWtrCzs7O5ibm3PldFJ6JfVav3v3bvTr1w93795F3bp1i/36REREhVEmRghERESgTZs20NLSgomJCQIDAwv9TdWFCxegpqaGu3fvlmxIIqIyQldXF927d4e/vz9iYmKQlJSEw4cPY/jw4bh//z4mTpwICwsLGBoaYtCgQVi7di2uXbvGEQRE/yGVSmFiYsJiABERiaqC2AGKKiYmBs7Ozhg8eDAWLlyIqKgoeHl5ITs7G97e3p889+rVq+jZsyeys7NLKS0RUdmjo6ODbt26oVu3bgCAtLQ0REdHQyaT4cSJE5gyZQqysrJgYGAgHz1ga2uLJk2aQEWlTNSlib6YVCrldAEiIhKd0r8Tmz9/Plq2bIktW7bAyckJP/74I2bMmIHFixfj3bt3BZ6TmZmJ5cuXo23btsjIyCjlxEREZZu2tja6du2KRYsWISoqCq9fv8axY8cwZswYPHv2DFOnTkXz5s1RvXp19OvXD6tXr8alS5eQm5srdnQqAUUZxZednQ0rK6s8C+/dvXsXEonko9uIESPkxz59+hRubm6oWrUq9PT04OrqiidPnhT3LX6x58+f4+rVq1xQkIiIRKfUBYGMjAzIZDL07ds3T/uAAQOQmpqKqKioAs87ePAgfH19MXv2bCxdurQ0ohIRlVtaWlro3LkzFi5ciMjISCQnJ+Pvv//G+PHj8erVK8yYMQMtWrSAgYEB+vTpg5UrV+LChQvIyckROzoV0YdRfObm5ggPD4ebmxu8vLwK/drr7++PuLi4PG1GRkY4ffp0vm3o0KFQU1PDyJEjAbwvJnTv3h2xsbFYv3491q1bh1OnTsHR0RFZWVnFfq9f4sSJEwDAEQJERCQ+QYnFx8cLAISwsLA87a9evRIACD///HOB5z18+FB4+fKlIAiCEBwcLAAQ7ty589F+0tPTheTk5Hybubl5sd0LEVF59fbtW0EqlQoLFiwQ7OzsBHV1dQGAoK+vL7i4uAjLly8Xzp49K2RnZ4sdlb6Qo6OjYGVllafNy8tL0NHREd6+ffvJcy9evChoamoKhoaGgq2t7SePPXv2rKCmpiYEBATI27Zv3y4AEK5duyZvu3btmiCRSIStW7cW+h4aN25c6GMLa9y4cUKDBg2K/bpERKXh6dOngqWlpZCZmSkIgiCcP39esLKyEjQ1NYXWrVsLZ8+eLdR1li1bJtStWzdP26tXrwRXV1dBW1tbMDY2FlatWpVn/+bNm4VGjRoJOjo6Qp8+fYQnT54UOve7d+8ET09PQU9PTzA0NBQCAwMLdd6dO3cEbW1tQSqVytsyMzMFLy8vwcjISDAwMBCmTZsmZGVl5Ts3PT1daNKkSZ5zr1+/Ltja2gq5ubmFzl6SlHqEQHJyMoD3C1z9l46ODoD3K2EXxNjYGFWqVCl0P0uWLIGenl6+7cWLF1+ZnIiIPtDU1ISdnR3mz58PqVSK169f48SJE5g6dSrS0tIwZ84ctG7dGlWrVoWzszMCAwMRFxfH9V8U3NeO4gPeT+1zd3fHxIkTYWZm9sl+BEHA+PHjYWFhgSlTpsjbjxw5AjMzM1hYWMjbLCws/l97dx4XVb3/D/w1wjCssoaAdgVBBb1qppIK7oYLaqVmq4LmVtrDNDW3UtMCk0fmLleNMjVL5dpyDYQEc4HccEvxpnjNFBc0FdkE5v37wy/za5oBTGc4jPN6Ph7zsPmcM+e8GHPeh/d8zjkICQnB9u3bH/CnMo309HSeLkBEFmvq1KkYP3481Go1CgoK0LdvX3Tq1AmHDh1Cx44dERkZiYKCgiq3kZOTgzlz5hiMv/zyyzh37hwyMzPxySef4J133kFycjKAe5/rw4cPx5tvvon9+/fD2dkZffr0ue9TDqdMmYKDBw9i586dWLFiBebOnYstW7ZU+7rXX3/d4Od577338Pnnn2Pt2rVITk7Gjz/+iEmTJumtU1xcjJdeegm//PKL3nhwcDAaNmyIzz///L5ym53SHYmHsXfvXgEgKSkpeuOlpaUCQGJiYqrdBmcIEBHVbsXFxbJ7926ZP3++9OzZUxwdHQWAuLi4SJ8+fWTBggWSmZlptDNPynnQWXwiIjNnzpSQkBApLi6WLl26VDlD4MsvvxQAet++iIiEhoZK//79DdYfMGCAtGnTxmC8pmr95cuXBYBs2LDBpNslIqoJ586dEzc3NykuLhYRkbVr10pAQIDu226tVitBQUGSkJBQ5XaefvppCQsL05shcPToUbGxsZGzZ8/qxsaNGyfvvvuuiIhERkbKsGHDdMsKCwvFw8NDkpKSqs19584dsbe316sV8+bNq3YG2vr16yUsLEyvzmi1WnFxcZFPP/1Ut15mZqao1WrJz88XkXsz0lq1aiUtW7Y0WqMyMzMlKCioVswSsOgZAq6urgCA/Px8vfGKmQEVyx+WRqNB3bp1DR68vzYRkflpNBqEh4dj5syZSElJwR9//IG9e/di+vTpKC8vx9y5c9G+fXu4u7ujd+/eiI2NRUZGRqUXlqWa8aCz+A4cOIC4uDh89tln0Gg01e5n4cKFCAsLM/jG/datWwb7rti/sX3X1GzA9PR0AOAMASKySPHx8ejVq5fu8zkzMxPh4eG634tUKhXCwsKQkZFR6TbWrVuHwsJC3TVfKqSnp6NVq1Zo1KiRbmzZsmV4//33AdybVfDUU0/pljk4OCAoKKjKfVU4evQoSktL0bFjR91YeHg4fv7550pnGFy/fh1Tp05FfHy83vi1a9eQn5+vl6Vly5YoLS3FwYMHAdy7Vky3bt0qzRYaGoo7d+4gJSWl2uzmZtG3HQwMDISNjQ3OnDmjN17xPCQkRIlYRERkRnZ2dujYsSM6duyI6dOno7S0FIcOHdLd5vCDDz7A9OnToVKp8I9//APBwcEIDg5G06ZNdX/6+vqyqWtm1U3hNHbLyeLiYkRFReGtt95CaGhotfvYt28fDh8+jG3btv2t/Rvb9/Tp0w2mewLQO+AzhfT0dDRp0gR+fn4m3S4RWb7CwkJkZ2fX+H6Dg4Ph6Oh4X+smJSVh/Pjxuue5ublo3ry53jr16tXDiRMnjL7+2rVreOedd5Cammpw0dicnBzd3WiWL18OjUaDiRMnYsyYMbrtXrx4Ube+VqvFxYsX76txm5ubCy8vL9jZ2enlLC4uxvXr1/HYY48ZvGbSpEmIiooy+Pk8PDygVqtx8eJF3WlpFy5cAABdltdff73KPCqVCj169EBSUhIiIiKqzW9OFt0QsLe3R+fOnZGYmIjJkyfrDu62bt0KV1fX+zqYICIiy6ZWq9G+fXu0b98e06ZNQ1lZGbKysnDixAmcPn0a2dnZSEpKwvLly3XXHXBxcTFoEgQHByMoKAj29vYK/0SPhgeZxTdr1ixotVq8++67ur8r+b9bFJaVlcHGxkavkbNlyxa4u7ujb9++Rvf/131X7N/YvjUajdEZCaZuHKWlpfHuAkRkVHZ2Ntq0aVPj+z106BCefPLJatcrKyvDsWPH9L50LSwsNPjs1Gg0ld7afeLEiYiOjkbz5s0NGgJ37txBamoqysrKsHnzZhw/fhzjxo2Dl5cXBg0ahBdeeAEzZsxAv3790LZtWyxYsABXrlzB3bt3q81eWU4ARrOmpqZiz549Rhsbtra2GDhwIGbMmIGQkBC4uLhg8uTJsLW1va8sFZo1a4YdO3bc9/rmYtENAeDewUPPnj0xZMgQjBgxAvv27cPChQsRGxsLR0dH3L59GydPnkRgYKDRzg8RET1abG1t0a5dO7Rr105vvLS0FDk5ObomQXZ2Nk6fPo3t27fjxo0bAO59c+zv72+0WeDt7c1ZBX/Dg8zi27JlC86fPw9nZ2eDZWq1GgkJCYiOjtaNff/993j22WehVqsN1m/atCmysrIMxs+cOaPYFwaXLl3C6dOnMXfuXEX2T0S1W3BwMA4dOqTIfu/HjRs3oNVq4eXlpRuzt7c3+IW6pKTE6IyD5ORkZGRkYPXq1Ua3b2tri/LycmzYsAFOTk5o27Ytjh49ivj4eAwaNAijRo3C8ePH0alTJwD3LlLbt29fo6eH/VVlOQEYZC0qKsKYMWOwYsUKODg4GN3ekiVL8OKLL+Lxxx+Hk5MTZs2ahZ9//vm+slTw9PTE1atX73t9c7H4hkD37t2xdetWzJ49G88++yzq16+PhQsX4u233wYAHD58GN26dTM4iCAiIuuiVqvRtGlTNG3aFAMGDNBblpeXp9ckyM7Oxvfff4/Fixfrpp67uroaPf0gKChIbwoi3fMgs/i+++47gwO2iqmi8fHxCAgI0I3fuHEDv/76K9555x2j+4+IiMDGjRtx8uRJ3ZTOkydP4tSpU5g1a5ZJfsa/a9euXQCALl26KLJ/IqrdHB0d7+ubeqVUfI6Xl5frxurXr4/Lly/rrXf58mX4+voavH7Tpk24cOGC7kvasrIy3L17F87Ozvjhhx/g6+uLBg0awMnJSfeapk2b6u4yYGNjg+XLl2PhwoUoLi6Gh4cHQkND8fTTT1ebvX79+sjLy0NZWRlsbW11OR0cHODm5qa37v79+5GTk4NBgwbpjffp0wdRUVFYtWoVvL29sXPnTty4cQP29vYQEUyfPh3+/v7VZqmg1WqNnsJW0yy+IQAAzz33nMFtjSp07dpVN93QmOjoaDYKiIisnJeXF8LDwxEeHq43XlJSgrNnz+qaBBV/btu2TXfRPBsbGwQEBBhtFnh5eVn1rIK/O4uvRYsWBtuouAhh27Zt9caPHz8OAHq3FfyzF154AR9++CH69OmD2NhYAMC0adPQokULDBkyxJQ/5n1LS0tDSEgIfHx8FNk/EdHD8PT0hI2NDa5fv64ba9++PWJjYyEiUKlUEBHs3bsXM2fONHj9ggUL9MYTExOxZMkSpKeno379+igsLERsbCxu3bqlO7Xr1KlTul+yFy1ahJKSEkybNg2Ojo7Izc1FVlYWPv3002qzP/HEE1Cr1bqLIALAnj170K5dO4NfykNDQ/Hrr7/qjTVu3Bhr1qzRNR+GDh2KoUOH6s7/37x5M7y9vSutScbk5eXVinrwSDQEiIiIzEGj0aBZs2YGBV5EcPXqVb0mQXZ2NhITE3Hu3DldI9rDw8Po6QeNGjUyOs39UWPOWXxXrlwBALi7uxtdrtFokJKSggkTJmD06NFQq9WIiIjAokWLdN8O1bS0tDTFLx5FRPSg6tSpg1atWuHYsWO6X6oHDx6MadOm4a233sKYMWMQHx+PgoICXeO1qKgIt27dgo+PD7y9veHt7a3bnre3N2xtbREUFAQA6NmzJ5o2bYqoqCjExsbi6NGjWLNmDTZt2gQACAgIwPDhw/HUU0/B29sbo0ePRmRkJP75z38CuHcNgqKiIqOniTs6OiIqKgpjx45FQkICLl68iLi4OCQkJOjWuXz5MlxdXXV3L/ir+vXr6/J7enpi5syZ8PPzQ15eHsaPH4/p06f/rW/8jx07VjtmhCh4y0OLFxISonQEIiKqZYqKiuT48eOyefNmmTdvnrz66qvStm1bcXFxEQACQGxtbaVp06byzDPPyNSpU+XixYtKx6ZKmKrWX7hwQQDI119/bZLtEREpYcaMGfLSSy/pjf3888/SunVrsbe3l9DQUDl8+LBuWUJCglT2K2dCQoI0bNhQb+z333+X/v37i4ODgzz++OOycuVKveUffvih+Pr6ipubm0RHR8vt27d1y2bPnm2wvT8rKCiQYcOGiZOTk/j5+cmiRYv0lgOQhIQEo68FIGlpabrn+fn5MnToUHF1dZX69etLTExMpfv962tFRLRarfj5+cnOnTsrfV1NUYlUMZ+eqtSsWTOcPHlS6RhERGQBRAS5ubl6swoq/ty1axcaNmyodEQywlS1fu/evRgyZAiOHDnCixwTkcU6e/Ys2rRpg0uXLt33rQprUkRERK24cn91du3ahVGjRiE7O1vx6wjwlAEiIqIaoFKp4OfnBz8/P3Tv3l3pOFTDwsLC8Pvvv1v1NSWIyPIFBgYiMjISGzZswKhRo5SOo2fDhg0ICwtTOsZ9iY+Px9SpUxVvBgAAZwg8BM4QICIierSx1hMR6cvNzUWfPn2wf//+WnWXndLSUou4Ps+pU6cwatQo7N69u1Y0idkQeAg8SCAiInq0sdYTEdGjTPk5CkRERERERERU49gQICIiIiIiIrJCbAgQERERERERWSE2BIiIiIiIiIisEBsCRERERERERFaIDQEiIiIiIiIiK8SGABEREREREZEVYkOAiIiIiIiIyAqxIUBERERERERkhdgQICIiIiIiIrJCKhERpUNYqrp166JBgwYPvR0RQV5eHry8vKBSqUyQzHyY1fQsJSfArOZgKTkBZjUHc+R0d3fH3r17TbItYq1nVtOxlKyWkhNgVnOwlJyAdWc1Za1nQ6AWuH37NlxdXXHr1i3UrVtX6ThVYlbTs5ScALOag6XkBJjVHCwlJz08S/q7ZlbzsJSslpITYFZzsJScALOaCk8ZICIiIiIiIrJCbAgQERERERERWSE2BIiIiIiIiIisEBsCRERERERERFaIDYFaQKPRYPbs2dBoNEpHqRazmp6l5ASY1RwsJSfArOZgKTnp4VnS3zWzmoelZLWUnACzmoOl5ASY1VR4lwEiIiIiIiIiK8QZAkRERERERERWiA0BIiIiIiIiIivEhgARERERERGRFWJDQGE7duxAu3bt4OjoiICAAMTFxaG2X9bh999/h5ubG9LT05WOYkCr1WLVqlVo2bIlnJ2d0ahRI0ycOBG3b99WOpoBrVaLuLg4NG7cGA4ODmjVqhU2bNigdKz7MnDgQPj7+ysdw6ji4mKo1WqoVCq9h7Ozs9LRDGRmZqJbt25wcnJCvXr1EBUVhatXryodS096errBe/nnx9y5c5WOaGD16tVo3rw5nJycEBISguXLl9fKz9WKz4CgoCDY29sjJCQEy5YtUzoWmYml1fvaXOsB1vuawFpvOrW93rPWm49F1HohxWRkZIharZZXX31VfvjhB5k5c6aoVCqJiYlROlqlfvvtNwkJCREAkpaWpnQcAzExMWJjYyPTpk2TlJQUWb58uXh4eEjPnj1Fq9UqHU/PzJkzRa1WS0xMjKSmpsqkSZMEgGzcuFHpaFX64osvBIA0bNhQ6ShGHThwQADI+vXrJSMjQ/fYv3+/0tH0HDx4UOzt7aVfv36SnJwsCQkJ4uPjIx06dFA6mp5bt27pvY8Vjx49ekjdunXl9OnTSkfUs3r1agEgb775pqSmpsrs2bNFpVJJXFyc0tEMvPXWWwJAxo4dK8nJybJixQrx9PSUSZMmKR2NTMzS6n1tr/UirPfmxlpvOpZQ71nrzccSaj0bAgqKiIiQ0NBQvbGpU6eKi4uLFBYWKpTKuPLycklISBBPT0/x8PColQcJ5eXl4ubmJm+88Ybe+KZNmwSAHDhwQKFkhgoKCsTJyUkmT56sN96lSxdp3769Qqmqd/HiRXF3d5cGDRrU2oOE1atXi62trRQXFysdpUrdu3eXDh06SHl5uW5s69at0qBBA8nJyVEwWfW++eYbASCbN29WOoqBDh06SHh4uN7Yiy++KP7+/golMu7atWtiY2MjI0eO1Bv/7rvvpE6dOnLq1CmFkpE5WEq9t4RaL8J6b26s9aZlqfWetf7hWUqt5ykDCikpKUF6ejqee+45vfHBgwcjPz8fe/bsUSiZcceOHcPYsWMxbNgwfPHFF0rHMer27dsYOnQoXn75Zb3x4OBgAMDZs2eViGWURqPBvn378Pbbb+uN29nZobi4WKFU1Rs5ciQiIiLQo0cPpaNU6siRIwgODq6V93mtcP36daSnp+ONN95AnTr//2N44MCBuHDhAgICAhRMV7WioiK8+eabiIyMxODBg5WOY6C4uBh169bVG/P09MT169cVSmTcf//7X5SXl6N///564926dYNWq0VSUpJCycjULKneW0KtB1jvzY213nQstd6z1puGpdR6NgQUkpOTg7t376JJkyZ640FBQQCA06dPKxGrUv/4xz9w5swZfPzxx3B0dFQ6jlFubm5YsmQJwsLC9Ma3bdsGAGjevLkCqYyzsbFBy5Yt4ePjAxHBlStXEBsbi9TUVLzxxhtKxzNqzZo1OHToUO077+kvjhw5AltbW0RERMDJyQkeHh4YM2YM8vPzlY6mc+zYMWi1Wjz22GN45ZVX4OLiAmdnZwwbNgw3b95UOl6VFi9ejIsXL+KTTz5ROopREyZMQHJyMtavX49bt24hOTkZn3/+OYYOHap0ND1eXl4AgPPnz+uNV/wik5OTU+OZyDwsqd5bQq0HWO/NibXetCy13rPWm4bF1HqlpyhYq4yMDAEgKSkpeuOlpaUCQD744AOFklUvLS2t1k4j/KvMzEyxt7eX/v37Kx2lUhs3bhQAAkAiIyNr1fTRCv/73//ExcVFtmzZIiIiUVFRtXIaoVarFRcXF3F2dpZly5bJrl27JC4uTlxcXCQ8PFxvup6SvvrqKwEgfn5+8tprr0lqaqqsXLlS3NzcJCwsrNad/1qhpKREfHx85JVXXlE6SqVKSkokOjpa928KgPTq1Uvu3r2rdDQD4eHh4u7uLomJiXLz5k05fPiwtG3bVjQajYwYMULpeGQillrvLanWi7DemwJrvelZYr1nrTctS6j1bAgoZO/evVUeINTWCw2JWM5Bwp49e8TNzU1CQkIkLy9P6TiVOnPmjOzatUuWLl0qbm5u0rlz51pVILRarXTv3l1eeOEF3VhtPUgoLy+XtLQ0OXHihN74+vXrBYBs375doWT6Ki7W9NcD1y+//FIASHJyskLJqrZhwwYBIEeOHFE6SqV69+4tzs7O8tFHH0l6erosXbpUPD095ZlnnqlV/65ERC5fvizPPPOM7mDGzc1N/vWvf4mfn5+MHz9e6XhkIpZa7y2l1ouw3psCa715WGK9Z603LUuo9bbmnX9AlXF1dQUAg6lNFbfLqVhOD+arr75CdHQ0mjRpgqSkJHh6eiodqVKBgYEIDAxE586dUbduXURFRWH37t3o3Lmz0tEAAMuXL8exY8dw/PhxlJWVAYDuti5lZWWoU6eO3nlxSqpTpw66du1qMB4ZGQkAOHr0KPr06VPDqQy5uLgAAPr166c33rt3bwBAVlYWIiIiajxXdbZs2YLmzZujVatWSkcxat++fUhKSsLq1asxcuRIAECXLl3QqFEjREZG4j//+Y/Be66kevXqYdu2bbh58yYuXbqEwMBA2NjYYOzYsfDw8FA6HpkI6715sd6bBmu9eVhivWetNy1LqPW141+2Far4n+HMmTN64xXPQ0JClIj1SIiLi8NLL72EDh064KeffoKvr6/SkQxcu3YN69atM7gH7ZNPPgkAuHTpkhKxjNqyZQvy8vLg6+sLtVoNtVqNdevW4fz581Cr1Xj//feVjqhz6dIlrF69Gr/99pveeFFREQDgscceUyKWgcaNGwO4d7GxPystLQUAODg41Him6pSWliI5ORlDhgxROkqlKs7R++t5xRUH27/88kuNZ6rKpk2bcOzYMbi5uaFZs2bQaDQ4cuQItFqt7rOALB/rvfmw3psOa715WFq9Z603PUuo9WwIKMTe3h6dO3dGYmKirgMLAFu3boWrqytCQ0MVTGe54uPjMWXKFAwZMgRJSUm19puXoqIiREVFYe3atXrjO3bsAAC0bNlSiVhGxcfH48CBA3qPfv36wdfXFwcOHMDo0aOVjqhTVlaG0aNHIz4+Xm/8q6++go2NDTp16qRQMn0hISHw9/fHpk2b9P79f/vttwBQa3L+2fHjx1FYWGhQgGuTiiuM7969W2987969AIBGjRrVeKaqzJ8/HzExMXpjixYtgqurq9Fvv8gysd6bB+u9abHWm4el1XvWetOziFqv5PkK1u7HH38UlUolgwcPlu3bt8usWbNEpVLJggULlI5Wpdp6XmFubq44ODiIv7+/7N69WzIyMvQeV69eVTqinhEjRoi9vb0sXLhQUlNTZfbs2aLRaOS1115TOlq1aut5hSIiw4cPF7VaLfPmzZPU1FSZM2eO2NnZyYQJE5SOpmfz5s2iUqlkyJAhkpKSIosXLxZnZ2cZNGiQ0tGM+uyzzwSAXLp0SekoVRo0aJA4OTlJbGyspKWlybJly8TLy0vatGkjpaWlSsfTEx8fLyqVSubPny87d+6U0aNHCwBZuXKl0tHIxCyx3tfWWi/Cel9TWOtNw5LqPWu96VlCrWdDQGGJiYnSokULsbOzk4CAAImLi1M6UrVq60HC2rVr9a42+tdHQkKC0hH1lJSUyPz586Vx48ZiZ2cngYGBsmDBglp1ddzK1OaDhOLiYpk3b540adJENBqNBAYGSmxsbK18X7/77jtp166daDQa8fX1lcmTJ0txcbHSsYxasGCBAJCioiKlo1SppKRE3n33XfH39xc7OzsJCgqSKVOmSH5+vtLRjPrkk08kMDBQHB0dpXXr1rJx40alI5GZWFq9r621XoT1vqaw1puOpdR71nrzqO21XiXyp/krRERERERERGQVeA0BIiIiIiIiIivEhgARERERERGRFWJDgIiIiIiIiMgKsSFAREREREREZIXYECAiIiIiIiKyQmwIEBEREREREVkhNgSIiIiIiIiIrBAbAkRERERERERWiA0BIiIiIiIiIivEhgARERERERGRFWJDgIiIiIiIiMgKsSFAREREREREZIXYECAiIiIiIiKyQmwIEFGloqOjoVKpKn34+PjUeCaVSoU5c+bU+H6JiIgeRaz1RNbNVukARFS7+fj44N///rfRZXZ2djWchoiIiEyNtZ7IerEhQERV0mg0aN++vdIxiIiIyExY64msF08ZIKKH1rVrV0RHR+PDDz9EvXr14OrqimeffRbnz5/XW+/gwYPo3bs3PD09UbduXfTv3x+//PKL3jq5ubmIioqCt7c3XFxc0KVLF2RkZOitc/v2bYwcORIeHh5wcXHB888/jytXruiWnz17FgMGDICnpyccHR3RoUMHbN++3XxvABER0SOOtZ7o0cSGABFVq6yszOhDRHTrfPPNN0hISMDSpUuxatUqZGVloWvXrigsLAQApKWloWPHjhARJCQkYM2aNbhw4QI6duyI7OxsAMCdO3cQFhaGtLQ0fPTRR0hMTISDgwMiIiLw66+/6va1ePFi3L17F5s3b0ZMTAy+/fZbjBs3DgCg1WrRr18/FBQU4IsvvsA333wDT09PDBgwAGfOnKnBd42IiMhysNYTWSkhIqpEVFSUAKj0sXDhQhER6dKli6jVajl79qzutYcPHxYAsnLlShERCQ0NlWbNmklZWZlunT/++EM8PDzk+eefFxGRpUuXikqlkqysLN06BQUF0qRJE1m9erWIiACQp556Si/nq6++Ku7u7iIikpubKwBkw4YNuuU3b96UiRMnyokTJ0z47hAREVk+1noi68ZrCBBRlXx9ffHtt98aXfb444/r/js8PByNGjXSPW/dujUaNWqEXbt2YejQoThw4ABmz54NGxsb3Tpubm7o37+/borfnj17EBAQgCeeeEK3jqOjI06fPq23306dOuk9DwgIwM2bNwEA9erVQ7NmzTBq1CgkJyejV69e6NOnDz7++OMH+vmJiIgedaz1RNaLDQEiqpKdnR3atm1b7Xr169c3GPP29saNGzdw8+ZNiIjRWxf5+PjoCvz169fh7e1d7b6cnJz0ntepU0c3pVGlUiElJQXz589HYmIi1q1bB7Vajeeeew6rVq2Cu7t7tdsnIiKyJqz1RNaL1xAgIpPIy8szGLty5Qq8vb3h5uYGlUqFy5cvG6yTm5sLLy8vAPe+Rbh27ZrBOvv27cOpU6fuO4ufnx9WrFiB3NxcZGVlYerUqdi6dStmzZr1N34iIiIi+jPWeqJHDxsCRGQSe/bswfXr13XPDx06hHPnzqFHjx5wcnJC27Zt8fXXX6O8vFy3zq1bt/D9998jPDwcwL3pgTk5OXpXIy4uLsbAgQOxdu3a+8qRkZGBevXq4cCBA1CpVHjiiScwf/58tGjRwuBKyERERHT/WOuJHj08ZYCIqlRSUoLMzMxKl7ds2RIAUFBQgN69e2PWrFnIz8/HjBkz0KJFC7z88ssAgJiYGPTq1Qt9+/bFuHHjcPfuXcTExKCkpATvvfceAGD48OFYsmQJBgwYgPfffx9eXl66qwxXXFm4Oq1bt4ajoyOGDh2KOXPmwMfHB6mpqThy5AgmTJjwkO8GERHRo4e1nsh6sSFARFW6fPkyOnToUOnyrKwsAPc6/t27d8eIESMAAAMGDEBcXBzs7OwAAD169EBqairee+89vPjii9BoNOjcuTPWrVuH5s2bAwBcXFzw008/YcqUKRg/fjy0Wi3at2+P9PR0BAQE3Fdee3t77NixA9OmTcOECRNw8+ZNNG7cGPHx8YiOjn6Id4KIiOjRxFpPZL1UIn+6uSgR0QPo2rUrACA9PV3RHERERGQerPVEjyZeQ4CIiIiIiIjICrEhQERERERERGSFeMoAERERERERkRXiDAEiIiIiIiIiK8SGABEREREREZEVYkOAiIiIiIiIyAqxIUBERERERERkhdgQICIiIiIiIrJCbAgQERERERERWSE2BIiIiIiIiIisEBsCRERERERERFaIDQEiIiIiIiIiK8SGABEREREREZEVYkOAiIiIiIiIyAqxIUBERERERERkhdgQICIiIiIiIrJCbAgQERERERERWSE2BIiIiIiIiIisEBsCRERERERERFaIDQEiIiIiIiIiK8SGABEREREREZEV+n8VKlfwnu7HJQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(6, 2), dpi=200)\n",
    "n_epochs = 10\n",
    "colormap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "\n",
    "# plot\n",
    "color = \"k\"  \n",
    "\n",
    "axs[0].plot(\n",
    "    np.arange(n_epochs),\n",
    "    np.mean(losses, axis=1),\n",
    "    label=\"Random embedding layer\",\n",
    "    color=color,\n",
    ")\n",
    "axs[0].set_xticks(np.arange(n_epochs))\n",
    "# axs[0].set_ylim(top=0.05)\n",
    "axs[0].set_xlabel(\"Epochs\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(\n",
    "    np.arange(n_epochs),\n",
    "    knn_accuracies[:, 0],\n",
    "    label=f\"({knn_accuracies[0, 0]:.3f}, {knn_accuracies[-1, 0]:.3f})\",\n",
    "    color=color,\n",
    ")\n",
    "\n",
    "axs[1].set_xticks(np.arange(n_epochs))\n",
    "# axs[1].set_ylim(0.2, 0.65)\n",
    "axs[1].set_xlabel(\"Epochs\")\n",
    "axs[1].set_ylabel(\"kNN accuracy [AV]\")\n",
    "axs[1].legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "fig.savefig(\n",
    "    figures_path\n",
    "    / \"loss_and_knn_accuracy_training_embeddR_run_3_medrxiv_v1.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set \n",
    "10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model_random = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model_random.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "CPU times: user 49.1 ms, sys: 4.86 ms, total: 54 ms\n",
      "Wall time: 169 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Extract the embedding layer\n",
    "embedding_layer = model_random.embeddings.word_embeddings\n",
    "# new model\n",
    "model = EmbeddingOnlyModel(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3b08f3fffe4c79a0f49a99ac8c4290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2112349c9f2947d2b45add917b4ee523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d4dfc59fad4b0f9a6cbe2e45c274e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71da87aa29c4335ae9eb63d58212e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753f1163a35a47f9a3d726eac0be2069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec04210c02b4779a740f5046368cf73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce332f5e8d04329a6472367d65adb11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9196da83f145b79d808a2ca4d646b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58d408ee53d49db8b6036f14b22ec3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9148b4114ab34148a5022c06f4fc2523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0c8640ed764e25984e57d1325e6dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c1b36db2410458b89e2bc82223df411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f61b164af15453490187a480c18fdee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1baa4d63ecff4dfba815dc1af056834b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce19a02340fe412ea2210975aa32326f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82fb4b4bfa246a9b857538509a3c1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aeae4a81f9b4ca7a988b7aeea01cf6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5903d4fc65c4c1abcc6b0d2612ec5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5dd724abf04799ab06a76a527f58f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26cf85bf4b124587857173976ca4b8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5834386231c6457495261b16eb214d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb468c91194a47bf80d0e0dd59fb00f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7247cde998483c92a432970cf9ed2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920a7acdeb8b4dd7b186a4f6093ca54f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1efad9b6de437489a28bb4621d9d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de564329517f4075bab5c8cfbbd85793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9cfb0ea817f467da979574a05ba764a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599226cc4277466dab6a126e83939ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87699e13a8f4c26a4ecf5fdac507b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f5782dca814ab3b52bbcac8b160496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 17min 17s, sys: 2min 7s, total: 19min 24s\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    dataset[\"test\"][\"labels\"],\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences_train), tokenizer, device, n_cons_sntcs=2, seed=42\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split_embedding_layer(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_random_bert\") / Path(\n",
    "    f\"updated_dataset/embedding_layer_experiment/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(\n",
    "    variables_path / saving_path / \"losses_run3_10_epochs_train_test_split\",\n",
    "    losses,\n",
    ")\n",
    "np.save(\n",
    "    variables_path\n",
    "    / saving_path\n",
    "    / \"knn_accuracies_run3_10_epochs_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune SBERT (crops)\n",
    "Run 1, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"SBERT\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  SBERT\n",
      "Running on device: cuda\n",
      "sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5d1372579e424fb637352b10a58a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b68367b1f4a4a6c91c6ddcf8183fe6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 10min 50s, sys: 1min 20s, total: 12min 10s\n",
      "Wall time: 6min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(dataset[\"test\"][\"sentences\"]),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    dataset[\"test\"][\"sentences\"],\n",
    "    tokenizer,\n",
    "    np.ones(len(dataset[\"test\"]), dtype=bool),\n",
    "    labels_acc=dataset[\"test\"][\"labels\"],\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run1\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run1\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.54107649, 0.50141643, 0.54220963])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit\n",
    "450 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"reddit\"\n",
    "dataset_path = \"mteb/reddit-clustering-p2p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['sentences', 'labels'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(\n",
    "    np.hstack(dataset.data[\"test\"].to_pandas().sentences.to_numpy())\n",
    ")\n",
    "labels = list(np.hstack(dataset.data[\"test\"].to_pandas().labels.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "459399"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(459399, 320065)\n",
      "CPU times: user 29.7 s, sys: 754 ms, total: 30.5 s\n",
      "Wall time: 30.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "tfidf_features = vectorizer.fit_transform(sentences)\n",
    "print(tfidf_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4605.07 MiB, increment: 698.91 MiB\n",
      "CPU times: user 2min 28s, sys: 1.28 s, total: 2min 30s\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=100, random_state=42, algorithm=\"arpack\")\n",
    "svd_data = svd.fit_transform(tfidf_features)\n",
    "\n",
    "# # save results\n",
    "# np.save(variables_path / \"updated_dataset\" / \"svd_data\", svd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 6265.70 MiB, increment: 827.57 MiB\n",
      "CPU times: user 1d 1h 32min 16s, sys: 20.1 s, total: 1d 1h 32min 36s\n",
      "Wall time: 53min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "knn_accuracies = knn_accuracy(\n",
    "    [tfidf_features, svd_data, normalize(svd_data, axis=1)],\n",
    "    labels,\n",
    ")\n",
    "np.save(\n",
    "    variables_path\n",
    "    / \"updated_dataset\"\n",
    "    / f\"knn_accuracy_tfidf_svd_l2_{dataset_name}\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19553766 0.47033087 0.49457989]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "    \"SimCSE\",\n",
    "    \"SBERT\",\n",
    "    \"SPECTER\",\n",
    "    \"SciNCL\",\n",
    "]\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "    \"princeton-nlp/unsup-simcse-bert-base-uncased\",\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    \"allenai/specter\",\n",
    "    \"malteos/scincl\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  SPECTER\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/.pyenv/versions/miniconda3-latest/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3720f9a001434ed692a81d5c0874891e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPECTER: [0.55200261 0.5762081  0.5685677 ]\n",
      "----------------------------\n",
      "Model:  SciNCL\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ea9abc267f48dfa6e1c15cbd5d3de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SciNCL: [0.57276883 0.59333914 0.59129299]\n",
      "----------------------------\n",
      "CPU times: user 2h 37min 50s, sys: 1h 44min 44s, total: 4h 22min 34s\n",
      "Wall time: 1h 58min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, model_name in enumerate(model_names):\n",
    "    # fix random seeds\n",
    "    fix_all_seeds()\n",
    "\n",
    "    # set up model\n",
    "    print(\"Model: \", model_names[i])\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Running on device: {}\".format(device))\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "    model = AutoModel.from_pretrained(model_paths[i])\n",
    "\n",
    "    # evaluation\n",
    "    model.to(device)\n",
    "\n",
    "    ## get embeddings\n",
    "    embedding_cls, embedding_sep, embedding_av = generate_embeddings(\n",
    "        sentences,\n",
    "        tokenizer,\n",
    "        model,\n",
    "        device,\n",
    "        batch_size=256,\n",
    "    )\n",
    "\n",
    "    ## run knn\n",
    "    knn_accuracies_baseline = knn_accuracy(\n",
    "        [\n",
    "            embedding_av,\n",
    "            embedding_cls,\n",
    "            embedding_sep,\n",
    "        ],\n",
    "        labels,\n",
    "    )\n",
    "    print(f\"{model_name}: {knn_accuracies_baseline}\")\n",
    "\n",
    "    # save\n",
    "    saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "        f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    "    )\n",
    "    (variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    np.save(\n",
    "        variables_path / saving_path / \"knn_accuracies_baseline\",\n",
    "        knn_accuracies_baseline,\n",
    "    )\n",
    "\n",
    "    model = None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune MPNet (crops)\n",
    "Run 1, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.weight', 'mpnet.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b04727a87241578af4385f57a24667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512c439081a844789f288172168deef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 2h 38min 46s, sys: 2h 3min 37s, total: 4h 42min 24s\n",
      "Wall time: 2h 23min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    sentences,\n",
    "    tokenizer,\n",
    "    np.ones(len(sentences), dtype=bool),\n",
    "    labels_acc=labels,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run1\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run1\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.71963431, 0.71332172, 0.64860688])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set\n",
    "Only MPNet, crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d24b2a20de04dfc9d3656492c1077e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4057 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffaa0d94ad174d3988ef6ffa98fb87a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01244db103e445479d16cb9a90e9b83f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 28min 39s, sys: 22min 25s, total: 3h 51min 5s\n",
      "Wall time: 2h 13min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    sentences,\n",
    "    labels,\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences_train), tokenizer, device, n_cons_sntcs=2, seed=42\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run1_train_test_split\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run1_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7184153243360906]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune MPNet (dropout)\n",
    "Run 2, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.weight', 'mpnet.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef3c3fb65344f65aecba494be73ef98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bbb5c1e52084a21bb2bb603f6732072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 2h 38min 27s, sys: 2h 2min 19s, total: 4h 40min 46s\n",
      "Wall time: 2h 23min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "training_dataset = SameSentencePairDataset(\n",
    "    pd.Series(sentences),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    sentences,\n",
    "    tokenizer,\n",
    "    np.ones(len(sentences), dtype=bool),\n",
    "    labels_acc=labels,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run2\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run2\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.57799303, 0.644101  , 0.59044406])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set\n",
    "Only MPNet, Dropout, eval only for labels secondary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e65deba49b4d9f9f715548394bc56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4057 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea60f780d564aedb043fa614c0f34d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22b89c811e74a2488a62a4c098a7960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 28min 58s, sys: 23min 51s, total: 3h 52min 49s\n",
      "Wall time: 2h 13min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    sentences,\n",
    "    labels,\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = SameSentencePairDataset(\n",
    "    pd.Series(sentences_train),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run2_train_test_split\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run2_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5957553330430997]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune random BERT (crops)\n",
    "Run 5, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  random_bert\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d14d34416348058b96e7591a974700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f67f285a204ab89ba5d5661e54aacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c59c91b18b440db8ca2ee662be79914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66dfb0b14e604fddbf61d41e62afb3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a7137a5a894994a224e0e62b01fb5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d8da2d84ba4433391fbe3a5ac7fb673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4881dbb2695f4115871855664459cdec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "model_name = \"random_bert\"\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "## randomly initialized model\n",
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model = BertModel(configuration)\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "\n",
    "\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    sentences,\n",
    "    tokenizer,\n",
    "    np.ones(len(sentences), dtype=bool),\n",
    "    labels_acc=labels,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run5\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run5\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.43744014, 0.43920331, 0.35953418]), array([0.51343056, 0.50361341, 0.43702656]), array([0.5526121 , 0.53615586, 0.53032216]), array([0.57046147, 0.55794515, 0.55439704]), array([0.58313017, 0.56743579, 0.57154985]), array([0.59767088, 0.57688289, 0.58402264]), array([0.60635612, 0.59164127, 0.59730083]), array([0.61251633, 0.59212016, 0.59978232]), array([0.61961254, 0.59760557, 0.60459295]), array([0.61819765, 0.59786678, 0.60430997])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set \n",
    "RandomBERT, Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  random_bert\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d072cc6b194440d2962497d3de337472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28862702b87545eeab0bcb624692dae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c183f57ce34eeb8376525c312d7057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28fe02fcffa4d9588f59605bf5fd32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1741a52a5186432eb5d0b5984ace2f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "462814c5c908423aa4016b380485e793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2272af01f84c819b40d06235e40b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96762a290274343996922c948f951ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d813d77b55d4baebb8225ad76fa966f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc788966b2a843b08e2c637b291bb969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf35ca7edd143b5abd1705566b4c884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5e57a44f6d4b8dbc6d1bb0b18e7871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855ba71d14824f8887eada47e81a9be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76017e556d6c460b8bfe2efba61838d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76b66fcb26d40c58047db8c9ce828c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4eb4c039124eb1be2ac2a4a5e32d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9f0e83fa4b440aa90ab31a5a9693d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98332b814a7e43e49fbf2b11d60afacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b90f1377d949038d92f22f54061d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08152ac0310d43c0b3c457cab075fa31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac4762003b54e998fa5a42d637fae6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c73e692b051426a907261ab913f78be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ee49f0d7cc4aa98e8ccaa778353d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06702d5aa1f6491586f4989af0b15804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74d1897b4bf4586bb02e688ee3d5bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d50f3e248442c18cad16bfad0c7aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa749e57dee4df8a7a05bd9667188b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437d59de78ef4294a97bc04e8252dae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a314cf786c4f70b14d41fb76f3600c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f219bb1ece948bcb38ebb673d1df543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23h 23min 58s, sys: 2h 33min 5s, total: 1d 1h 57min 3s\n",
      "Wall time: 18h 19min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "model_name = \"random_bert\"\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "## randomly initialized model\n",
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model = BertModel(configuration)\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    sentences,\n",
    "    labels,\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences_train), tokenizer, device, n_cons_sntcs=2, seed=42\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run5_train_test_split\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run5_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4498476273400087, 0.49029168480626906, 0.5272747061384414, 0.5448628646060079, 0.5565302568567697, 0.571767522855899, 0.5833043099695254, 0.5887679582063561, 0.5914018284719199, 0.5937962559860688]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune random embedding layer (not module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 3, crop augmentations 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model_random = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model_random.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "CPU times: user 59.7 ms, sys: 40.8 ms, total: 100 ms\n",
      "Wall time: 227 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Extract the embedding layer\n",
    "embedding_layer = model_random.embeddings.word_embeddings\n",
    "# new model\n",
    "model = EmbeddingOnlyModel(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca1a8875870428fa58f672bc7ab6684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86fe9630e7e4d438463cdffa1263d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 1h 18min 17s, sys: 14min 21s, total: 1h 32min 38s\n",
      "Wall time: 8min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_embedding_layer(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    sentences,\n",
    "    tokenizer,\n",
    "    np.ones(len(sentences), dtype=bool),\n",
    "    labels_acc=labels,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=5e-1,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_random_bert\") / Path(\n",
    "    f\"updated_dataset/embedding_layer_experiment/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run3\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run3\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 3, crop augmentations 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model_random = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model_random.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "CPU times: user 51.4 ms, sys: 15 ms, total: 66.4 ms\n",
      "Wall time: 200 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Extract the embedding layer\n",
    "embedding_layer = model_random.embeddings.word_embeddings\n",
    "# new model\n",
    "model = EmbeddingOnlyModel(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb53c1b37933465badc48670abce124d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a829dd341c4853a2529cd8fafbb668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad2571f4b4545f68619d66ed0e8228c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69cff660fb7466ebe46491ad6a4ca02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3530c438aa647b48ac11df0d536da40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5522a5f53e6c44f89d7161795dff362a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222d82b40d3d4438823c36f45d47528a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105725f10dcd44b6ad80e4cd5a0d7737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "045e532df0ec4e26ad49e2d76bcad63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d02a5fc72d4328baca0f41ce42bd0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60f7c41140546ad9226f1b7d3951c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947d55bfe5f241c28130488f13c7a327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f99b1dee454565b86339cbb1c48861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6fd0f6df884e50892fdadeae7b24af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3707b2c3860a4394a5d53b614033505c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365b86c6d6db43e9acf0f30ec6de6f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0e82215bc24b278a90d83064fb2941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3a4812d48a48f29c20e604d7ceed00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5525de587664b64ad92a1c050ec40c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1a70c222c248589bbb71fc8d8bdebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 11h 17min 28s, sys: 1h 25min 18s, total: 12h 42min 47s\n",
      "Wall time: 1h 6min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_embedding_layer(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    sentences,\n",
    "    tokenizer,\n",
    "    np.ones(len(sentences), dtype=bool),\n",
    "    labels_acc=labels,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=5e-1,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_random_bert\") / Path(\n",
    "    f\"updated_dataset/embedding_layer_experiment/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run3_10_epochs\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run3_10_epochs\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracies = np.vstack(knn_accuracies) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(6, 2), dpi=200)\n",
    "n_epochs = 10\n",
    "colormap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "# plot\n",
    "color = \"k\"  \n",
    "\n",
    "axs[0].plot(\n",
    "    np.arange(n_epochs),\n",
    "    np.mean(losses, axis=1),\n",
    "    label=\"Random embedding layer\",\n",
    "    color=color,\n",
    ")\n",
    "axs[0].set_xticks(np.arange(n_epochs))\n",
    "# axs[0].set_ylim(top=0.05)\n",
    "axs[0].set_xlabel(\"Epochs\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(\n",
    "    np.arange(n_epochs),\n",
    "    knn_accuracies[:, 0],\n",
    "    label=f\"({knn_accuracies[0, 0]:.3f}, {knn_accuracies[-1, 0]:.3f})\",\n",
    "    color=color,\n",
    ")\n",
    "\n",
    "axs[1].set_xticks(np.arange(n_epochs))\n",
    "# axs[1].set_ylim(0.2, 0.65)\n",
    "axs[1].set_xlabel(\"Epochs\")\n",
    "axs[1].set_ylabel(\"kNN accuracy [AV]\")\n",
    "axs[1].legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "fig.savefig(\n",
    "    figures_path\n",
    "    / f\"loss_and_knn_accuracy_training_embeddR_run_3_{dataset_name}_v1.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set \n",
    "10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model_random = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model_random.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "CPU times: user 61.4 ms, sys: 63.1 ms, total: 125 ms\n",
      "Wall time: 258 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Extract the embedding layer\n",
    "embedding_layer = model_random.embeddings.word_embeddings\n",
    "# new model\n",
    "model = EmbeddingOnlyModel(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7af6a9ecf84a1d893e5bf6b8182361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "416288ea37514ba4a537cceed12c4421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fccb5a17d9a4d6c952a929cd6d3ee2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281edf4116a6420eb60f81adb0530c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeee1aad2fe44a6ebd3e039f1910306e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9275a1dda1e64927887138e274bda56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d899976e0fd041279015cbce1564405f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f68621bc4343e6919989077d68223a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf729e8290d492886580726b84f7518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbc885afa4e480285c4826a2c48fe93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca48fdbc76e49e59b266bf2d17df93f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105ff8ecb76047f4a485d2f2c7c808fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 55min 56s, sys: 12min 17s, total: 1h 8min 13s\n",
      "Wall time: 17min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    sentences,\n",
    "    labels,\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences_train), tokenizer, device, n_cons_sntcs=2, seed=42\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split_embedding_layer(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_random_bert\") / Path(\n",
    "    f\"updated_dataset/embedding_layer_experiment/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(\n",
    "    variables_path / saving_path / \"losses_run3_10_epochs_train_test_split\",\n",
    "    losses,\n",
    ")\n",
    "np.save(\n",
    "    variables_path\n",
    "    / saving_path\n",
    "    / \"knn_accuracies_run3_10_epochs_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5016978667827601]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune SBERT (crops)\n",
    "Run 1, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"SBERT\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  SBERT\n",
      "Running on device: cuda\n",
      "sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2f435ee8534e1ebc32232e250ed98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a64d8ad4b74f248ad470c3fefe77a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 4h 5min 4s, sys: 24min 40s, total: 4h 29min 44s\n",
      "Wall time: 2h 21min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    sentences,\n",
    "    tokenizer,\n",
    "    np.ones(len(sentences), dtype=bool),\n",
    "    labels_acc=labels,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run1\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run1\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.75339573, 0.76123204, 0.72357423])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stackexchange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"stackexchange\"\n",
    "dataset_path = \"mteb/stackexchange-clustering-p2p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['sentences', 'labels'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(\n",
    "    np.hstack(dataset.data[\"test\"].to_pandas().sentences.to_numpy())\n",
    ")\n",
    "labels = list(np.hstack(dataset.data[\"test\"].to_pandas().labels.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 120133)\n",
      "CPU times: user 5.92 s, sys: 226 ms, total: 6.15 s\n",
      "Wall time: 6.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "tfidf_features = vectorizer.fit_transform(sentences)\n",
    "print(tfidf_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 5883.33 MiB, increment: 174.39 MiB\n",
      "CPU times: user 32.9 s, sys: 480 ms, total: 33.4 s\n",
      "Wall time: 33.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=100, random_state=42, algorithm=\"arpack\")\n",
    "svd_data = svd.fit_transform(tfidf_features)\n",
    "\n",
    "# # save results\n",
    "# np.save(variables_path / \"updated_dataset\" / \"svd_data\", svd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 5933.61 MiB, increment: 50.39 MiB\n",
      "CPU times: user 50min 44s, sys: 5.82 s, total: 50min 50s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "knn_accuracies = knn_accuracy(\n",
    "    [tfidf_features, svd_data, normalize(svd_data, axis=1)],\n",
    "    labels,\n",
    ")\n",
    "np.save(\n",
    "    variables_path\n",
    "    / \"updated_dataset\"\n",
    "    / f\"knn_accuracy_tfidf_svd_l2_{dataset_name}\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47533333 0.45866667 0.45613333]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "    \"SimCSE\",\n",
    "    \"SBERT\",\n",
    "    \"SPECTER\",\n",
    "    \"SciNCL\",\n",
    "]\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "    \"princeton-nlp/unsup-simcse-bert-base-uncased\",\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    \"allenai/specter\",\n",
    "    \"malteos/scincl\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  SPECTER\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f4a4535ff04ff6a62c21d1a7ec9470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPECTER: [0.41453333 0.4552     0.4464    ]\n",
      "----------------------------\n",
      "Model:  SciNCL\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0e66e60e114a3badd8fe2a0e4f5c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SciNCL: [0.42933333 0.47626667 0.46786667]\n",
      "----------------------------\n",
      "CPU times: user 12min 44s, sys: 17min 42s, total: 30min 26s\n",
      "Wall time: 19min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, model_name in enumerate(model_names):\n",
    "    # fix random seeds\n",
    "    fix_all_seeds()\n",
    "\n",
    "    # set up model\n",
    "    print(\"Model: \", model_names[i])\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Running on device: {}\".format(device))\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "    model = AutoModel.from_pretrained(model_paths[i])\n",
    "\n",
    "    # evaluation\n",
    "    model.to(device)\n",
    "\n",
    "    ## get embeddings\n",
    "    embedding_cls, embedding_sep, embedding_av = generate_embeddings(\n",
    "        sentences,\n",
    "        tokenizer,\n",
    "        model,\n",
    "        device,\n",
    "        batch_size=256,\n",
    "    )\n",
    "\n",
    "    ## run knn\n",
    "    knn_accuracies_baseline = knn_accuracy(\n",
    "        [\n",
    "            embedding_av,\n",
    "            embedding_cls,\n",
    "            embedding_sep,\n",
    "        ],\n",
    "        labels,\n",
    "    )\n",
    "    print(f\"{model_name}: {knn_accuracies_baseline}\")\n",
    "\n",
    "    # save\n",
    "    saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "        f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    "    )\n",
    "    (variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    np.save(\n",
    "        variables_path / saving_path / \"knn_accuracies_baseline\",\n",
    "        knn_accuracies_baseline,\n",
    "    )\n",
    "\n",
    "    model = None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune MPNet (crops)\n",
    "Run 1, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.weight', 'mpnet.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb4571617f042c799d42e728467b6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ae56e5ee894c87a7910b20141d5adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    sentences,\n",
    "    tokenizer,\n",
    "    np.ones(len(sentences), dtype=bool),\n",
    "    labels_acc=labels,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run1\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run1\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.45613333, 0.4596    , 0.4144    ])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set\n",
    "Only MPNet, crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2119f62529c4a32ad85fb9e5248e6ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d6761bd89f496795482b90bbd02ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e5ab456f794a98a2b6d6afdda66052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34min 9s, sys: 4min 36s, total: 38min 45s\n",
      "Wall time: 24min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    sentences,\n",
    "    labels,\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences_train), tokenizer, device, n_cons_sntcs=2, seed=42\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run1_train_test_split\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run1_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4512]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune MPNet (dropout)\n",
    "Run 2, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.weight', 'mpnet.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d854b2dae444e87b193039d8234b4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dfe36e8e42d4f85aad205bb3d55d28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 21min 17s, sys: 22min 49s, total: 44min 6s\n",
      "Wall time: 26min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "training_dataset = SameSentencePairDataset(\n",
    "    pd.Series(sentences),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    sentences,\n",
    "    tokenizer,\n",
    "    np.ones(len(sentences), dtype=bool),\n",
    "    labels_acc=labels,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run2\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run2\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.41573333, 0.4216    , 0.41053333])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set\n",
    "Only MPNet, Dropout, eval only for labels secondary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"MPNet\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"microsoft/mpnet-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  MPNet\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/mpnet-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b2f1ba6b1746df897e2f1b81061bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a877d65ba54f485683d11661497e9d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4bde1393e2c48d99ee882ea65e1091c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33min 57s, sys: 5min 1s, total: 38min 59s\n",
      "Wall time: 24min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    sentences,\n",
    "    labels,\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = SameSentencePairDataset(\n",
    "    pd.Series(sentences_train),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run2_train_test_split\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run2_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4126666666666667]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune random BERT (crops)\n",
    "Run 5, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  random_bert\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17704a7295745308b94d3815d24e52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec57783265914d92840427fb3022cfdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8c4d333833459f988b66b4df442ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2429fde2c3c9493fa3cd6b88698da38e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f9b76f220b44baad7b92c2695a88e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5cad38e5b7a4345b882577e60eb4c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50cdc473f0a4188aa05e58dbe255df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbf62b8ecb5446697410b62597dde10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569732988d764345941e29974d4cf1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "model_name = \"random_bert\"\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "## randomly initialized model\n",
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model = BertModel(configuration)\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    sentences,\n",
    "    tokenizer,\n",
    "    np.ones(len(sentences), dtype=bool),\n",
    "    labels_acc=labels,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run5\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run5\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.4088    , 0.41453333, 0.32093333])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set\n",
    "RandomBERT, Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  random_bert\n",
      "Running on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee624907907546a58eaa989c4c2e9c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae7e406da544c4a81d0435ddce7719d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0adb80d994fe47fa9c406b8e7674bb55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555849f510334eecbef80226505fe2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efaccec030084cdcb0c3894cb5767998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9adcbbc16abb4a52a984d92d76a1149a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1985a4f5b69b44b295970929a4a65c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa52f78be174c8c94be2fb0bc79c38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0571564e444b59b36ee9a0672c0dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66eb98d7d92540088c47331846deaea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a177a7829ed7477ba4973590b3937967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38b2f7c4f4749bd906cc48347fd5cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e53d88304e4841895a61cd49a164a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1684e0f981574247a3c9d28b77e10981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd144c3a2be47e3b27ff5027c127e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e721d9bd9643b2b585efe36edbe000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81919c635d794ee6acd2ce5870926be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1956e2dde0314d0abc9b4d0623e043da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2135971e0414776ad4fdd17f107cdf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d46c9b7381453982731db8b37afa6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd16b0e7e1d4461a200b23b160fefff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7542a0e683b7442a91253eff30464868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af551ce17cf4c37b8ded27c44ae102e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5657281c5710402785fe9a21dfe877c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c200b1c99e7d49bd9d0d80f5a7d64e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600c010553e94b5cbcd3fd485957ccc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd9f3f63e9f4470954fc4fb58548629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f5b33e320a43208c4d589d3f7d1220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282f2d4d3b6247ebb0453a1029bd259d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c715baf69f0f4f2eabf236235607e444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4h 12s, sys: 29min 55s, total: 4h 30min 7s\n",
      "Wall time: 3h 27min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "model_name = \"random_bert\"\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "## randomly initialized model\n",
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model = BertModel(configuration)\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    sentences,\n",
    "    labels,\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences_train), tokenizer, device, n_cons_sntcs=2, seed=42\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run5_train_test_split\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run5_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4136, 0.4232, 0.4328, 0.43733333333333335, 0.4436, 0.44666666666666666, 0.4454666666666667, 0.4461333333333333, 0.4532, 0.4518666666666667]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune random embedding layer (not module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 3, crop augmentations, 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model_random = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model_random.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "CPU times: user 41.9 ms, sys: 9 ms, total: 50.9 ms\n",
      "Wall time: 163 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Extract the embedding layer\n",
    "embedding_layer = model_random.embeddings.word_embeddings\n",
    "# new model\n",
    "model = EmbeddingOnlyModel(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b416bcc251254c10aca09f921c8ad2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ebf445fb554cc2ba45f19e7510e733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 8min 56s, sys: 2min 45s, total: 11min 41s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_embedding_layer(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    sentences,\n",
    "    tokenizer,\n",
    "    np.ones(len(sentences), dtype=bool),\n",
    "    labels_acc=labels,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=5e-1,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_random_bert\") / Path(\n",
    "    f\"updated_dataset/embedding_layer_experiment/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run3\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run3\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 3, crop augmentations, 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model_random = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model_random.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "CPU times: user 47.5 ms, sys: 14.8 ms, total: 62.3 ms\n",
      "Wall time: 177 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Extract the embedding layer\n",
    "embedding_layer = model_random.embeddings.word_embeddings\n",
    "# new model\n",
    "model = EmbeddingOnlyModel(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c8e8a40c034ea383b6e9daef89a3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b33424f48d4276a1e5aedb8a58a3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd080d9fe2d4af399bf77856add0eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27030b26b2bc4061bad8b902f935d377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21068cada12b4e94bce9578c5afb8db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e21d51b41c459bb64e5af0ac595b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebdb4ac9c3d4a6b9ebbe831974d7692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebcd036e3042451cb172b20e17889901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717e852196ba47bbafda8e03970fddab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdeaa9ee7d2439ab2eef71a78364d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa92a5643ca41d4a982bf0c10c837d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde5f04fd80a48bb9da821b34abb302b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4115b3f828d4958a562f61dc4087a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bbcc71883d34a6080c98cd3a5e2c5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8b73f4b67c49bb82125d8444722436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9db605e6a16472e8dd829473976333f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd83aef9c1c64068846ef93f7c89dcf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bca8f6e2a9433f9774ce3402d5bb6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f32f0f586b44dd86f7ec3123af4c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a61533cc508468db5818173307a6471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 1h 6min 33s, sys: 14min 53s, total: 1h 21min 26s\n",
      "Wall time: 11min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_embedding_layer(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    sentences,\n",
    "    tokenizer,\n",
    "    np.ones(len(sentences), dtype=bool),\n",
    "    labels_acc=labels,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=5e-1,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_random_bert\") / Path(\n",
    "    f\"updated_dataset/embedding_layer_experiment/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run3_10_epochs\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run3_10_epochs\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracies = np.vstack(knn_accuracies)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(6, 2), dpi=200)\n",
    "n_epochs = 10\n",
    "colormap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "# plot\n",
    "color = \"k\" \n",
    "\n",
    "axs[0].plot(\n",
    "    np.arange(n_epochs),\n",
    "    np.mean(losses, axis=1),\n",
    "    label=\"Random embedding layer\",\n",
    "    color=color,\n",
    ")\n",
    "axs[0].set_xticks(np.arange(n_epochs))\n",
    "# axs[0].set_ylim(top=0.05)\n",
    "axs[0].set_xlabel(\"Epochs\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(\n",
    "    np.arange(n_epochs),\n",
    "    knn_accuracies[:, 0],\n",
    "    label=f\"({knn_accuracies[0, 0]:.3f}, {knn_accuracies[-1, 0]:.3f})\",\n",
    "    color=color,\n",
    ")\n",
    "\n",
    "axs[1].set_xticks(np.arange(n_epochs))\n",
    "# axs[1].set_ylim(0.2, 0.65)\n",
    "axs[1].set_xlabel(\"Epochs\")\n",
    "axs[1].set_ylabel(\"kNN accuracy [AV]\")\n",
    "axs[1].legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "fig.savefig(\n",
    "    figures_path\n",
    "    / f\"loss_and_knn_accuracy_training_embeddR_run_3_{dataset_name}_v1.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training only on train set \n",
    "10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = BertConfig()\n",
    "\n",
    "# Initializing a model (with random weights) from the bert-base-uncased style configuration\n",
    "model_random = BertModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model_random.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "CPU times: user 49.8 ms, sys: 4.85 ms, total: 54.7 ms\n",
      "Wall time: 168 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Extract the embedding layer\n",
    "embedding_layer = model_random.embeddings.word_embeddings\n",
    "# new model\n",
    "model = EmbeddingOnlyModel(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c641316c7a846ffb182cfb9cafde4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb46938ffe84c139830a7cec5afa1a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6219786d675468d848df83953ddaeac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ac1070387847d0a1c8100890527caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb9fd0daaf548caa77a30253b3b08e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1974097ff4496ba885992b3da8a5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cc6f79859748bb869c4829f95aecd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c8caac747d4deea69db737853b440f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34507c0def7d47cbac7128d1ee316806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3934bac2183046449cf1078bf0f7fa11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2810dd9907404ef083deed18a8a6378a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4b66347a99431982f9e53a440aa3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca005fec8b04ec394b1f95a6af0763c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aac21d231d94efe8776b6d1c73ab6cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670444320a154e049e37c673fcf8a5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003be52bfe9844ceb1837396ca43649e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef92e573bfb4e9f80cae5c6c6989034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b32e9411c1845d6b91f4d1c0a91ae5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130e294daf894038950b1c39ece486a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb58ad7b4874463a77c55df32aba48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af26626a408d4449ae9f8bb245ac5fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690388827a0643549801c5f5c3bf4c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741f27b5efff4affbd37559fd7553b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f93bb24959f4239833cfc932c89c400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6326111d3c264e05903fe406b0b3905c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ff113eb49246cc9e079f68507f2f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8bcd3ec92a41b480f1b30c30c180c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6086317a21bc46e79363f5cee9df1efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d587f5789074b9ba5383ec454236d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7fca11ee4f04df98c3b2cc4a85181d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 50min 52s, sys: 11min 42s, total: 1h 2min 34s\n",
      "Wall time: 10min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data\n",
    "# split the data in train and test before dataset and loader\n",
    "random_state = np.random.seed(42)\n",
    "(\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    ") = train_test_split(\n",
    "    sentences,\n",
    "    labels,\n",
    "    test_size=0.1,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# only do a dataset and loader from the training set\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences_train), tokenizer, device, n_cons_sntcs=2, seed=42\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop_train_test_split_embedding_layer(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    sentences_train,\n",
    "    sentences_test,\n",
    "    labels_train,\n",
    "    labels_test,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=10,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_random_bert\") / Path(\n",
    "    f\"updated_dataset/embedding_layer_experiment/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(\n",
    "    variables_path / saving_path / \"losses_run3_10_epochs_train_test_split\",\n",
    "    losses,\n",
    ")\n",
    "np.save(\n",
    "    variables_path\n",
    "    / saving_path\n",
    "    / \"knn_accuracies_run3_10_epochs_train_test_split\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune SBERT (crops)\n",
    "Run 1, crop augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"SBERT\",\n",
    "]\n",
    "\n",
    "\n",
    "model_paths = [\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  SBERT\n",
      "Running on device: cuda\n",
      "sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821ad6acd3ad4f97ab6c90db8e20b027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a1ed2a4aec43cebc53303b949fccc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "CPU times: user 37min 19s, sys: 4min 41s, total: 42min\n",
      "Wall time: 26min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seeds\n",
    "fix_all_seeds()\n",
    "\n",
    "# set up model\n",
    "i = 0\n",
    "model_name = model_names[i]\n",
    "\n",
    "print(\"Model: \", model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device: {}\".format(device))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[i])\n",
    "model = AutoModel.from_pretrained(model_paths[i])\n",
    "print(model_paths[i])\n",
    "\n",
    "# data\n",
    "training_dataset = MultOverlappingSentencesPairDataset(\n",
    "    pd.Series(sentences),\n",
    "    tokenizer,\n",
    "    device,\n",
    ")\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(42)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, batch_size=64, shuffle=True, generator=gen\n",
    ")\n",
    "\n",
    "# training\n",
    "losses, knn_accuracies = train_loop(\n",
    "    model,\n",
    "    training_loader,\n",
    "    device,\n",
    "    sentences,\n",
    "    tokenizer,\n",
    "    np.ones(len(sentences), dtype=bool),\n",
    "    labels_acc=labels,\n",
    "    optimized_rep=\"av\",\n",
    "    n_epochs=1,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "# save\n",
    "saving_path = Path(\"embeddings_\" + model_name.lower()) / Path(\n",
    "    f\"updated_dataset/mteb_datasets/{dataset_name}\"\n",
    ")\n",
    "(variables_path / saving_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(variables_path / saving_path / \"losses_run1\", losses)\n",
    "np.save(\n",
    "    variables_path / saving_path / \"knn_accuracies_run1\",\n",
    "    knn_accuracies,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.51      , 0.5036    , 0.47773333])]\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
