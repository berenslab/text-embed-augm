{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2875705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import adapters\n",
    "from adapters import AutoAdapterModel\n",
    "import gc\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from openTSNE import TSNE, affinity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import memory_profiler\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from pathlib import Path\n",
    "import distro\n",
    "\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08fdbffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.1+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old one '1.8.1+cu111'\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc676833",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from text_embeddings_src.model_stuff import train_loop, train_loop_batches_eval\n",
    "from text_embeddings_src.data_stuff import (\n",
    "    SentencePairDataset,\n",
    "    MultOverlappingSentencesPairDataset,\n",
    ")\n",
    "from text_embeddings_src.metrics import knn_accuracy\n",
    "from text_embeddings_src.embeddings import generate_embeddings\n",
    "from text_embeddings_src.dim_red import run_tsne_simple\n",
    "from text_embeddings_src.plotting import plot_tsne_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4187e547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(line_length=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56c5fc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_path = Path(\"../../results/variables\")\n",
    "# variables_pubmed_path = Path(\"../../pubmed-landscape/results/variables\")\n",
    "figures_path = Path(\"../../results/figures/updated_dataset\")\n",
    "data_path = Path(\"../../data\")\n",
    "berenslab_data_path = Path(\"/gpfs01/berens/data/data/pubmed_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "186e2693",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"../matplotlib_style.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13cb5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d23bc34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Rita González-Márquez\n",
      "\n",
      "Last updated: 2024-03-12 03:38:05CET\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.5\n",
      "IPython version      : 8.18.1\n",
      "\n",
      "openTSNE: 1.0.0\n",
      "\n",
      "Compiler    : GCC 11.2.0\n",
      "OS          : Linux\n",
      "Release     : 3.10.0-1160.el7.x86_64\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 64\n",
      "Architecture: 64bit\n",
      "\n",
      "Hostname: rgonzalesmarquez_GPU0-llm_gber7\n",
      "\n",
      "matplotlib     : 3.8.2\n",
      "scipy          : 1.11.4\n",
      "distro         : 1.8.0\n",
      "sklearn        : 1.3.2\n",
      "memory_profiler: 0.61.0\n",
      "jupyter_black  : 0.3.4\n",
      "numpy          : 1.26.2\n",
      "black          : 23.11.0\n",
      "openTSNE       : 1.0.0\n",
      "pandas         : 2.1.3\n",
      "torch          : 2.1.1\n",
      "adapters       : 0.1.0\n",
      "\n",
      "Watermark: 2.4.3\n",
      "\n",
      "Ubuntu 22.04.3 LTS\n"
     ]
    }
   ],
   "source": [
    "%watermark -a 'Rita González-Márquez' -t -d -tz -u -v -iv -w -m -h -p transformers -p openTSNE\n",
    "print(distro.name(pretty=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c9d1e7",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e7cc29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 289 ms, sys: 78.5 ms, total: 368 ms\n",
      "Wall time: 275 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iclr2024 = pd.read_parquet(\n",
    "    data_path / \"iclr2024.parquet.gzip\",\n",
    "    # index=False,\n",
    "    engine=\"pyarrow\",\n",
    "    # compression=\"gzip\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e808f181",
   "metadata": {},
   "outputs": [],
   "source": [
    "iclr2024.keywords = iclr2024.keywords.transform(lambda x: list(x))\n",
    "iclr2024.scores = iclr2024.scores.transform(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fcb00db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>decision</th>\n",
       "      <th>scores</th>\n",
       "      <th>keywords</th>\n",
       "      <th>gender-first</th>\n",
       "      <th>gender-last</th>\n",
       "      <th>t-SNE x</th>\n",
       "      <th>t-SNE y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>S1VaB4cex</td>\n",
       "      <td>FractalNet: Ultra-Deep Neural Networks without...</td>\n",
       "      <td>We introduce a design strategy for neural netw...</td>\n",
       "      <td>Gustav Larsson, Michael Maire, Gregory Shakhna...</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[5, 7, 6, 6]</td>\n",
       "      <td>[]</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>-28.117955</td>\n",
       "      <td>-20.418127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>H1W1UN9gg</td>\n",
       "      <td>Deep Information Propagation</td>\n",
       "      <td>We study the behavior of untrained neural netw...</td>\n",
       "      <td>Samuel S. Schoenholz, Justin Gilmer, Surya Gan...</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[8, 9, 8]</td>\n",
       "      <td>[theory, deep learning]</td>\n",
       "      <td>male</td>\n",
       "      <td>None</td>\n",
       "      <td>-32.466820</td>\n",
       "      <td>-10.791123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>r1GKzP5xx</td>\n",
       "      <td>Recurrent Normalization Propagation</td>\n",
       "      <td>We propose a LSTM parametrization  that preser...</td>\n",
       "      <td>César Laurent, Nicolas Ballas, Pascal Vincent</td>\n",
       "      <td>Invite to Workshop Track</td>\n",
       "      <td>[4, 6, 6]</td>\n",
       "      <td>[deep learning, optimization]</td>\n",
       "      <td>None</td>\n",
       "      <td>male</td>\n",
       "      <td>3.504240</td>\n",
       "      <td>19.946053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>S1J0E-71l</td>\n",
       "      <td>Surprisal-Driven Feedback in Recurrent Networks</td>\n",
       "      <td>Recurrent neural nets are widely used for pred...</td>\n",
       "      <td>K, a, m, i, l,  , R, o, c, k, i</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[3, 4, 3]</td>\n",
       "      <td>[unsupervised learning, applications, deep lea...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.553473</td>\n",
       "      <td>16.037763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>SJGCiw5gl</td>\n",
       "      <td>Pruning Convolutional Neural Networks for Reso...</td>\n",
       "      <td>We propose a new formulation for pruning convo...</td>\n",
       "      <td>Pavlo Molchanov, Stephen Tyree, Tero Karras, T...</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 7, 9]</td>\n",
       "      <td>[deep learning, transfer learning]</td>\n",
       "      <td>None</td>\n",
       "      <td>male</td>\n",
       "      <td>-25.827705</td>\n",
       "      <td>-37.891772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24342</th>\n",
       "      <td>7299</td>\n",
       "      <td>2024</td>\n",
       "      <td>1bbPQShCT2</td>\n",
       "      <td>I-PHYRE: Interactive Physical Reasoning</td>\n",
       "      <td>Current evaluation protocols predominantly ass...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[intuitive physics, physical reasoning]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>43.137120</td>\n",
       "      <td>44.316133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24343</th>\n",
       "      <td>7300</td>\n",
       "      <td>2024</td>\n",
       "      <td>Ny150AblPu</td>\n",
       "      <td>EXPOSING TEXT-IMAGE INCONSISTENCY USING DIFFUS...</td>\n",
       "      <td>In the battle against widespread online misinf...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[mis-contextualization, media forensic]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>59.742172</td>\n",
       "      <td>-22.673627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24344</th>\n",
       "      <td>7301</td>\n",
       "      <td>2024</td>\n",
       "      <td>ZGBOfAQrMl</td>\n",
       "      <td>Video Super-Resolution Transformer with Masked...</td>\n",
       "      <td>Recently, Vision Transformer has achieved grea...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[video super-resolution, adaptive, memory and ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>57.933273</td>\n",
       "      <td>-3.932825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24345</th>\n",
       "      <td>7302</td>\n",
       "      <td>2024</td>\n",
       "      <td>J2kRjUAOLh</td>\n",
       "      <td>Contrastive Predict-and-Search for Mixed Integ...</td>\n",
       "      <td>Mixed integer linear programs  (MILP) are flex...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[mixed integer programs; contrastive learning]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-11.437999</td>\n",
       "      <td>21.289523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24346</th>\n",
       "      <td>7303</td>\n",
       "      <td>2024</td>\n",
       "      <td>U0P622bfUN</td>\n",
       "      <td>Federated Generative Learning with Foundation ...</td>\n",
       "      <td>Existing federated learning solutions focus on...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[federated learning, non-iid data]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-65.112587</td>\n",
       "      <td>18.746354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24347 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  year          id  \\\n",
       "0          0  2017   S1VaB4cex   \n",
       "1          1  2017   H1W1UN9gg   \n",
       "2          2  2017   r1GKzP5xx   \n",
       "3          3  2017   S1J0E-71l   \n",
       "4          4  2017   SJGCiw5gl   \n",
       "...      ...   ...         ...   \n",
       "24342   7299  2024  1bbPQShCT2   \n",
       "24343   7300  2024  Ny150AblPu   \n",
       "24344   7301  2024  ZGBOfAQrMl   \n",
       "24345   7302  2024  J2kRjUAOLh   \n",
       "24346   7303  2024  U0P622bfUN   \n",
       "\n",
       "                                                   title  \\\n",
       "0      FractalNet: Ultra-Deep Neural Networks without...   \n",
       "1                           Deep Information Propagation   \n",
       "2                    Recurrent Normalization Propagation   \n",
       "3        Surprisal-Driven Feedback in Recurrent Networks   \n",
       "4      Pruning Convolutional Neural Networks for Reso...   \n",
       "...                                                  ...   \n",
       "24342            I-PHYRE: Interactive Physical Reasoning   \n",
       "24343  EXPOSING TEXT-IMAGE INCONSISTENCY USING DIFFUS...   \n",
       "24344  Video Super-Resolution Transformer with Masked...   \n",
       "24345  Contrastive Predict-and-Search for Mixed Integ...   \n",
       "24346  Federated Generative Learning with Foundation ...   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      We introduce a design strategy for neural netw...   \n",
       "1      We study the behavior of untrained neural netw...   \n",
       "2      We propose a LSTM parametrization  that preser...   \n",
       "3      Recurrent neural nets are widely used for pred...   \n",
       "4      We propose a new formulation for pruning convo...   \n",
       "...                                                  ...   \n",
       "24342  Current evaluation protocols predominantly ass...   \n",
       "24343  In the battle against widespread online misinf...   \n",
       "24344  Recently, Vision Transformer has achieved grea...   \n",
       "24345  Mixed integer linear programs  (MILP) are flex...   \n",
       "24346  Existing federated learning solutions focus on...   \n",
       "\n",
       "                                                 authors  \\\n",
       "0      Gustav Larsson, Michael Maire, Gregory Shakhna...   \n",
       "1      Samuel S. Schoenholz, Justin Gilmer, Surya Gan...   \n",
       "2          César Laurent, Nicolas Ballas, Pascal Vincent   \n",
       "3                        K, a, m, i, l,  , R, o, c, k, i   \n",
       "4      Pavlo Molchanov, Stephen Tyree, Tero Karras, T...   \n",
       "...                                                  ...   \n",
       "24342                                                      \n",
       "24343                                                      \n",
       "24344                                                      \n",
       "24345                                                      \n",
       "24346                                                      \n",
       "\n",
       "                       decision        scores  \\\n",
       "0               Accept (Poster)  [5, 7, 6, 6]   \n",
       "1               Accept (Poster)     [8, 9, 8]   \n",
       "2      Invite to Workshop Track     [4, 6, 6]   \n",
       "3                        Reject     [3, 4, 3]   \n",
       "4               Accept (Poster)     [6, 7, 9]   \n",
       "...                         ...           ...   \n",
       "24342                                      []   \n",
       "24343                                      []   \n",
       "24344                                      []   \n",
       "24345                                      []   \n",
       "24346                                      []   \n",
       "\n",
       "                                                keywords gender-first  \\\n",
       "0                                                     []         male   \n",
       "1                                [theory, deep learning]         male   \n",
       "2                          [deep learning, optimization]         None   \n",
       "3      [unsupervised learning, applications, deep lea...         None   \n",
       "4                     [deep learning, transfer learning]         None   \n",
       "...                                                  ...          ...   \n",
       "24342            [intuitive physics, physical reasoning]         None   \n",
       "24343            [mis-contextualization, media forensic]         None   \n",
       "24344  [video super-resolution, adaptive, memory and ...         None   \n",
       "24345     [mixed integer programs; contrastive learning]         None   \n",
       "24346                 [federated learning, non-iid data]         None   \n",
       "\n",
       "      gender-last    t-SNE x    t-SNE y  \n",
       "0            male -28.117955 -20.418127  \n",
       "1            None -32.466820 -10.791123  \n",
       "2            male   3.504240  19.946053  \n",
       "3            None   4.553473  16.037763  \n",
       "4            male -25.827705 -37.891772  \n",
       "...           ...        ...        ...  \n",
       "24342        None  43.137120  44.316133  \n",
       "24343        None  59.742172 -22.673627  \n",
       "24344        None  57.933273  -3.932825  \n",
       "24345        None -11.437999  21.289523  \n",
       "24346        None -65.112587  18.746354  \n",
       "\n",
       "[24347 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9d4b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_iclr = np.load(variables_path / \"updated_dataset\" / \"labels_iclr.npy\")\n",
    "colors_iclr = np.load(variables_path / \"updated_dataset\" / \"colors_iclr.npy\")\n",
    "\n",
    "pickle_in = open(\n",
    "    variables_path / \"updated_dataset\" / \"dict_label_to_color.pkl\", \"rb\"\n",
    ")\n",
    "dict_label_to_color = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "591e1734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['unlabeled', 'unlabeled', 'optimization', ..., 'unlabeled',\n",
       "       'unlabeled', 'federated learning'], dtype='<U34')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "print(len(np.unique(labels_iclr)))\n",
    "labels_iclr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5ad9070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles_abstracts_together = [\n",
    "#     iclr2024.title[i] + \". \" + iclr2024.abstract[i]\n",
    "#     for i in range(len(iclr2024))\n",
    "# ]\n",
    "# print(len(titles_abstracts_together))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b192e532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(titles_abstracts_together).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8c6d216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "saving_path = Path(\"embeddings_\" + \"mpnet\") / Path(\"updated_dataset\")\n",
    "embedding_av = np.load(\n",
    "    variables_path / saving_path / \"embedding_abstracts_only_av.npy\"\n",
    ")\n",
    "\n",
    "embedding_asbtracts_only_av_after_training_av_1_epoch = np.load(\n",
    "    variables_path\n",
    "    / saving_path\n",
    "    / \"embedding_asbtracts_only_av_after_training_av_1_epoch.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4666e2-d228-45de-b5c5-28f88a21d9c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba3521bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def knn_accuracy_whitening_scores(X, y, ntest=500, rs=42):\n",
    "    \"\"\"Calculates kNN accuracy of raw, centered and whitened data.\n",
    "    It calculates it for to distance metrics: cosine and euclidean.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : list of array-like\n",
    "        List with the different datasets for which to calculate the kNN accuracy.\n",
    "    y : array-like\n",
    "        Array with labels (colors).\n",
    "    ntest : int, default=500\n",
    "        Subset size for the kNN calculation\n",
    "    rs : int, default=42\n",
    "        Random seed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    scores : array of floates of shape (3,2)\n",
    "        List with the kNN accuracy for the different distance metrics and versions of the data.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    n = X.shape[0]\n",
    "    Xcentered = X - np.mean(X, axis=0)\n",
    "    Xwhitened = PCA(whiten=True).fit_transform(X)\n",
    "\n",
    "    scores = np.zeros((3, 2))\n",
    "    np.random.seed(rs)\n",
    "    test = np.random.choice(n, size=ntest, replace=False)\n",
    "    train = np.setdiff1d(np.arange(n), test)\n",
    "\n",
    "    for i, X_to_use in enumerate([X, Xcentered, Xwhitened]):\n",
    "        for j, metric in enumerate([\"euclidean\", \"cosine\"]):\n",
    "            knn = KNeighborsClassifier(\n",
    "                n_neighbors=10, algorithm=\"brute\", metric=metric\n",
    "            ).fit(X_to_use[train], y[train])\n",
    "\n",
    "            scores[i, j] = knn.score(X_to_use[test], y[test])\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0230b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(knn_accs):\n",
    "    print([\"euclidean\", \"cosine\"])\n",
    "    print(\n",
    "        \"Raw:      \",\n",
    "        round(knn_accs[0, 0], 3) * 100,\n",
    "        round(knn_accs[0, 1], 3) * 100,\n",
    "    )\n",
    "    print(\n",
    "        \"Centered: \",\n",
    "        round(knn_accs[1, 0], 3) * 100,\n",
    "        round(knn_accs[1, 1], 3) * 100,\n",
    "    )\n",
    "    print(\n",
    "        \"Whitened: \",\n",
    "        round(knn_accs[2, 0], 3) * 100,\n",
    "        round(knn_accs[2, 1], 3) * 100,\n",
    "    )\n",
    "    print(\"---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9cd4545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12997,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1300"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(labels_iclr[labels_iclr != \"unlabeled\"].shape)\n",
    "round(0.1 * labels_iclr[labels_iclr != \"unlabeled\"].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59886217-8dba-4d20-9965-8f143affbbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 1min 12s, total: 2min 18s\n",
      "Wall time: 5.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn_accuracy_before_training_centered_and_whitened = (\n",
    "    knn_accuracy_whitening_scores(\n",
    "        embedding_av[labels_iclr != \"unlabeled\"],\n",
    "        labels_iclr[labels_iclr != \"unlabeled\"],\n",
    "        ntest=round(0.1 * labels_iclr[labels_iclr != \"unlabeled\"].shape[0]),\n",
    "        rs=42,\n",
    "    )\n",
    ")\n",
    "knn_accuracy_before_training_centered_and_whitened_rs23 = (\n",
    "    knn_accuracy_whitening_scores(\n",
    "        embedding_av[labels_iclr != \"unlabeled\"],\n",
    "        labels_iclr[labels_iclr != \"unlabeled\"],\n",
    "        ntest=round(0.1 * labels_iclr[labels_iclr != \"unlabeled\"].shape[0]),\n",
    "        rs=23,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cafc7797-f407-4795-88df-4faf0b477a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['euclidean', 'cosine']\n",
      "Raw:       37.4 39.6\n",
      "Centered:  37.4 37.0\n",
      "Whitened:  17.599999999999998 46.9\n",
      "---------------\n",
      "['euclidean', 'cosine']\n",
      "Raw:       39.800000000000004 41.6\n",
      "Centered:  39.800000000000004 37.9\n",
      "Whitened:  20.0 49.4\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# rs=23\n",
    "print_table(knn_accuracy_before_training_centered_and_whitened)\n",
    "print_table(knn_accuracy_before_training_centered_and_whitened_rs23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76a4ea5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 1min 22s, total: 2min 30s\n",
      "Wall time: 5.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn_accuracy_after_training_centered_and_whitened = (\n",
    "    knn_accuracy_whitening_scores(\n",
    "        embedding_asbtracts_only_av_after_training_av_1_epoch[\n",
    "            labels_iclr != \"unlabeled\"\n",
    "        ],\n",
    "        labels_iclr[labels_iclr != \"unlabeled\"],\n",
    "        ntest=round(0.1 * labels_iclr[labels_iclr != \"unlabeled\"].shape[0]),\n",
    "        rs=42,\n",
    "    )\n",
    ")\n",
    "knn_accuracy_after_training_centered_and_whitened_rs23 = (\n",
    "    knn_accuracy_whitening_scores(\n",
    "        embedding_asbtracts_only_av_after_training_av_1_epoch[\n",
    "            labels_iclr != \"unlabeled\"\n",
    "        ],\n",
    "        labels_iclr[labels_iclr != \"unlabeled\"],\n",
    "        ntest=round(0.1 * labels_iclr[labels_iclr != \"unlabeled\"].shape[0]),\n",
    "        rs=23,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca9db77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['euclidean', 'cosine']\n",
      "Raw:       58.699999999999996 59.3\n",
      "Centered:  58.699999999999996 58.9\n",
      "Whitened:  36.199999999999996 56.49999999999999\n",
      "---------------\n",
      "['euclidean', 'cosine']\n",
      "Raw:       60.6 60.199999999999996\n",
      "Centered:  60.6 59.5\n",
      "Whitened:  38.2 57.099999999999994\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# rs=23\n",
    "print_table(knn_accuracy_after_training_centered_and_whitened)\n",
    "print_table(knn_accuracy_after_training_centered_and_whitened_rs23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ddcb5",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd981a58",
   "metadata": {},
   "source": [
    "### SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49b57039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "saving_path = Path(\"embeddings_\" + \"sbert\") / Path(\"updated_dataset\")\n",
    "embedding_av_sbert = np.load(\n",
    "    variables_path / saving_path / \"embedding_abstracts_only_av.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f6d1208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 10s, sys: 1min 29s, total: 2min 39s\n",
      "Wall time: 5.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn_accuracy_sbert_before_training_centered_and_whitened = (\n",
    "    knn_accuracy_whitening_scores(\n",
    "        embedding_av_sbert[labels_iclr != \"unlabeled\"],\n",
    "        labels_iclr[labels_iclr != \"unlabeled\"],\n",
    "        ntest=round(0.1 * labels_iclr[labels_iclr != \"unlabeled\"].shape[0]),\n",
    "        rs=42,\n",
    "    )\n",
    ")\n",
    "knn_accuracy_sbert_before_training_centered_and_whitened_rs23 = (\n",
    "    knn_accuracy_whitening_scores(\n",
    "        embedding_av_sbert[labels_iclr != \"unlabeled\"],\n",
    "        labels_iclr[labels_iclr != \"unlabeled\"],\n",
    "        ntest=round(0.1 * labels_iclr[labels_iclr != \"unlabeled\"].shape[0]),\n",
    "        rs=23,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "630b22ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['euclidean', 'cosine']\n",
      "Raw:       63.3 62.4\n",
      "Centered:  63.3 62.7\n",
      "Whitened:  46.7 57.099999999999994\n",
      "---------------\n",
      "['euclidean', 'cosine']\n",
      "Raw:       63.2 63.2\n",
      "Centered:  63.2 61.8\n",
      "Whitened:  50.0 58.199999999999996\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# rs=23\n",
    "print_table(knn_accuracy_sbert_before_training_centered_and_whitened)\n",
    "print_table(knn_accuracy_sbert_before_training_centered_and_whitened_rs23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6f485ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1254666\n",
      "4.802613\n",
      "2.1115158\n"
     ]
    }
   ],
   "source": [
    "# Not normalized\n",
    "print(np.linalg.norm(embedding_av_sbert[0]))\n",
    "print(np.linalg.norm(embedding_av[0]))\n",
    "print(np.linalg.norm(embedding_asbtracts_only_av_after_training_av_1_epoch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d95c750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
